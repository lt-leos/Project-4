[
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "unicode_literals",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "with_statement",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "tzinfo",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "tzinfo",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "warn",
        "importPath": "warnings",
        "description": "warnings",
        "isExtraImport": true,
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "warn",
        "importPath": "warnings",
        "description": "warnings",
        "isExtraImport": true,
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "warn",
        "importPath": "warnings",
        "description": "warnings",
        "isExtraImport": true,
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "warn",
        "importPath": "warnings",
        "description": "warnings",
        "isExtraImport": true,
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "calendar",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "calendar",
        "description": "calendar",
        "detail": "calendar",
        "documentation": {}
    },
    {
        "label": "monthrange",
        "importPath": "calendar",
        "description": "calendar",
        "isExtraImport": true,
        "detail": "calendar",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "UnsupportedOperation",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "six",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "six",
        "description": "six",
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "integer_types",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "text_type",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "assertRaisesRegex",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "PY2",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "PY2",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "PY2",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "PY2",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "string_types",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "text_type",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "advance_iterator",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "integer_types",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "six",
        "description": "six",
        "isExtraImport": true,
        "detail": "six",
        "documentation": {}
    },
    {
        "label": "Decimal",
        "importPath": "decimal",
        "description": "decimal",
        "isExtraImport": true,
        "detail": "decimal",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "zoneinfo",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "tz",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "utils",
        "importPath": "dateutil",
        "description": "dateutil",
        "isExtraImport": true,
        "detail": "dateutil",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "partial",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "given",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "assume",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "strategies",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "given",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "assume",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "given",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "strategies",
        "importPath": "hypothesis",
        "description": "hypothesis",
        "isExtraImport": true,
        "detail": "hypothesis",
        "documentation": {}
    },
    {
        "label": "isoparse",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "parserinfo",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "isoparser",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "isoparse",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "parserinfo",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "ParserError",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "UnknownTimezoneWarning",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "dateutil.parser",
        "description": "dateutil.parser",
        "isExtraImport": true,
        "detail": "dateutil.parser",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "integers",
        "importPath": "hypothesis.strategies",
        "description": "hypothesis.strategies",
        "isExtraImport": true,
        "detail": "hypothesis.strategies",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_call",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_output",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "easter",
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "isExtraImport": true,
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "EASTER_WESTERN",
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "isExtraImport": true,
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "EASTER_ORTHODOX",
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "isExtraImport": true,
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "EASTER_JULIAN",
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "isExtraImport": true,
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "_ymd",
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "isExtraImport": true,
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "UTC",
        "importPath": "dateutil.tz",
        "description": "dateutil.tz",
        "isExtraImport": true,
        "detail": "dateutil.tz",
        "documentation": {}
    },
    {
        "label": "tzoffset",
        "importPath": "dateutil.tz",
        "description": "dateutil.tz",
        "isExtraImport": true,
        "detail": "dateutil.tz",
        "documentation": {}
    },
    {
        "label": "UTC",
        "importPath": "dateutil.tz",
        "description": "dateutil.tz",
        "isExtraImport": true,
        "detail": "dateutil.tz",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "relativedelta",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "MO",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "TU",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "WE",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "FR",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "SU",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "relativedelta",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "SU",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "TH",
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "isExtraImport": true,
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "rrule",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "rruleset",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "rrulestr",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "YEARLY",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "MONTHLY",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "WEEKLY",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "DAILY",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "HOURLY",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "MINUTELY",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "SECONDLY",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "MO",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "TU",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "WE",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "TH",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "FR",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "SA",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "SU",
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "isExtraImport": true,
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "freeze_time",
        "importPath": "freezegun",
        "description": "freezegun",
        "isExtraImport": true,
        "detail": "freezegun",
        "documentation": {}
    },
    {
        "label": "freeze_time",
        "importPath": "freezegun",
        "description": "freezegun",
        "isExtraImport": true,
        "detail": "freezegun",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "gc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gc",
        "description": "gc",
        "detail": "gc",
        "documentation": {}
    },
    {
        "label": "weakref",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "weakref",
        "description": "weakref",
        "detail": "weakref",
        "documentation": {}
    },
    {
        "label": "within_delta",
        "importPath": "dateutil.utils",
        "description": "dateutil.utils",
        "isExtraImport": true,
        "detail": "dateutil.utils",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "_thread",
        "importPath": "six.moves",
        "description": "six.moves",
        "isExtraImport": true,
        "detail": "six.moves",
        "documentation": {}
    },
    {
        "label": "_thread",
        "importPath": "six.moves",
        "description": "six.moves",
        "isExtraImport": true,
        "detail": "six.moves",
        "documentation": {}
    },
    {
        "label": "winreg",
        "importPath": "six.moves",
        "description": "six.moves",
        "isExtraImport": true,
        "detail": "six.moves",
        "documentation": {}
    },
    {
        "label": "_thread",
        "importPath": "six.moves",
        "description": "six.moves",
        "isExtraImport": true,
        "detail": "six.moves",
        "documentation": {}
    },
    {
        "label": "range",
        "importPath": "six.moves",
        "description": "six.moves",
        "isExtraImport": true,
        "detail": "six.moves",
        "documentation": {}
    },
    {
        "label": "struct",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "struct",
        "description": "struct",
        "detail": "struct",
        "documentation": {}
    },
    {
        "label": "bisect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bisect",
        "description": "bisect",
        "detail": "bisect",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "TarFile",
        "importPath": "tarfile",
        "description": "tarfile",
        "isExtraImport": true,
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "METADATA_FN",
        "importPath": "dateutil.zoneinfo",
        "description": "dateutil.zoneinfo",
        "isExtraImport": true,
        "detail": "dateutil.zoneinfo",
        "documentation": {}
    },
    {
        "label": "ZONEFILENAME",
        "importPath": "dateutil.zoneinfo",
        "description": "dateutil.zoneinfo",
        "isExtraImport": true,
        "detail": "dateutil.zoneinfo",
        "documentation": {}
    },
    {
        "label": "operator",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "operator",
        "description": "operator",
        "detail": "operator",
        "documentation": {}
    },
    {
        "label": "copysign",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "integer_types",
        "importPath": "six.six",
        "description": "six.six",
        "isExtraImport": true,
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "heapq",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "heapq",
        "description": "heapq",
        "detail": "heapq",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "ClosedPoolError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "ConnectTimeoutError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "HTTPError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "InvalidHeader",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "LocationValueError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "MaxRetryError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "NewConnectionError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "ProtocolError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "ProxyError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "ReadTimeoutError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "ResponseError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "SSLError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "HTTPError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "DecodeError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "LocationParseError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "ProtocolError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "ReadTimeoutError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "SSLError",
        "importPath": "urllib3.exceptions",
        "description": "urllib3.exceptions",
        "isExtraImport": true,
        "detail": "urllib3.exceptions",
        "documentation": {}
    },
    {
        "label": "PoolManager",
        "importPath": "urllib3.poolmanager",
        "description": "urllib3.poolmanager",
        "isExtraImport": true,
        "detail": "urllib3.poolmanager",
        "documentation": {}
    },
    {
        "label": "proxy_from_url",
        "importPath": "urllib3.poolmanager",
        "description": "urllib3.poolmanager",
        "isExtraImport": true,
        "detail": "urllib3.poolmanager",
        "documentation": {}
    },
    {
        "label": "Timeout",
        "importPath": "urllib3.util",
        "description": "urllib3.util",
        "isExtraImport": true,
        "detail": "urllib3.util",
        "documentation": {}
    },
    {
        "label": "parse_url",
        "importPath": "urllib3.util",
        "description": "urllib3.util",
        "isExtraImport": true,
        "detail": "urllib3.util",
        "documentation": {}
    },
    {
        "label": "parse_url",
        "importPath": "urllib3.util",
        "description": "urllib3.util",
        "isExtraImport": true,
        "detail": "urllib3.util",
        "documentation": {}
    },
    {
        "label": "make_headers",
        "importPath": "urllib3.util",
        "description": "urllib3.util",
        "isExtraImport": true,
        "detail": "urllib3.util",
        "documentation": {}
    },
    {
        "label": "parse_url",
        "importPath": "urllib3.util",
        "description": "urllib3.util",
        "isExtraImport": true,
        "detail": "urllib3.util",
        "documentation": {}
    },
    {
        "label": "Retry",
        "importPath": "urllib3.util.retry",
        "description": "urllib3.util.retry",
        "isExtraImport": true,
        "detail": "urllib3.util.retry",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "where",
        "importPath": "certifi",
        "description": "certifi",
        "isExtraImport": true,
        "detail": "certifi",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Mapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "MutableMapping",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "cookiejar",
        "importPath": "http",
        "description": "http",
        "isExtraImport": true,
        "detail": "http",
        "documentation": {}
    },
    {
        "label": "Morsel",
        "importPath": "http.cookies",
        "description": "http.cookies",
        "isExtraImport": true,
        "detail": "http.cookies",
        "documentation": {}
    },
    {
        "label": "quote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "quote_plus",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "unquote_plus",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urldefrag",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlencode",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urljoin",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlsplit",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlunparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "getproxies",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "getproxies_environment",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "parse_http_list",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "proxy_bypass",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "proxy_bypass_environment",
        "importPath": "urllib.request",
        "description": "urllib.request",
        "isExtraImport": true,
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "ssl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ssl",
        "description": "ssl",
        "detail": "ssl",
        "documentation": {}
    },
    {
        "label": "idna",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "idna",
        "description": "idna",
        "detail": "idna",
        "documentation": {}
    },
    {
        "label": "urllib3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib3",
        "description": "urllib3",
        "detail": "urllib3",
        "documentation": {}
    },
    {
        "label": "encodings.idna",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "encodings.idna",
        "description": "encodings.idna",
        "detail": "encodings.idna",
        "documentation": {}
    },
    {
        "label": "RequestField",
        "importPath": "urllib3.fields",
        "description": "urllib3.fields",
        "isExtraImport": true,
        "detail": "urllib3.fields",
        "documentation": {}
    },
    {
        "label": "encode_multipart_formdata",
        "importPath": "urllib3.filepost",
        "description": "urllib3.filepost",
        "isExtraImport": true,
        "detail": "urllib3.filepost",
        "documentation": {}
    },
    {
        "label": "codecs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "codecs",
        "description": "codecs",
        "detail": "codecs",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "abc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "abc",
        "description": "abc",
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "_timelex",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class _timelex(object):\n    # Fractional seconds are sometimes split by a comma\n    _split_decimal = re.compile(\"([.,])\")\n    def __init__(self, instream):\n        if isinstance(instream, (bytes, bytearray)):\n            instream = instream.decode()\n        if isinstance(instream, text_type):\n            instream = StringIO(instream)\n        elif getattr(instream, 'read', None) is None:\n            raise TypeError('Parser must be a string or character stream, not '",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "_resultbase",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class _resultbase(object):\n    def __init__(self):\n        for attr in self.__slots__:\n            setattr(self, attr, None)\n    def _repr(self, classname):\n        l = []\n        for attr in self.__slots__:\n            value = getattr(self, attr)\n            if value is not None:\n                l.append(\"%s=%s\" % (attr, repr(value)))",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "parserinfo",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class parserinfo(object):\n    \"\"\"\n    Class which handles what inputs are accepted. Subclass this to customize\n    the language and acceptable values for each parameter.\n    :param dayfirst:\n        Whether to interpret the first value in an ambiguous 3-integer date\n        (e.g. 01/05/09) as the day (``True``) or month (``False``). If\n        ``yearfirst`` is set to ``True``, this distinguishes between YDM\n        and YMD. Default is ``False``.\n    :param yearfirst:",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "_ymd",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class _ymd(list):\n    def __init__(self, *args, **kwargs):\n        super(self.__class__, self).__init__(*args, **kwargs)\n        self.century_specified = False\n        self.dstridx = None\n        self.mstridx = None\n        self.ystridx = None\n    @property\n    def has_year(self):\n        return self.ystridx is not None",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class parser(object):\n    def __init__(self, info=None):\n        self.info = info or parserinfo()\n    def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n        \"\"\"\n        Parse the date/time string into a :class:`datetime.datetime` object.\n        :param timestr:\n            Any date/time string using the supported formats.\n        :param default:",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "_tzparser",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class _tzparser(object):\n    class _result(_resultbase):\n        __slots__ = [\"stdabbr\", \"stdoffset\", \"dstabbr\", \"dstoffset\",\n                     \"start\", \"end\"]\n        class _attr(_resultbase):\n            __slots__ = [\"month\", \"week\", \"weekday\",\n                         \"yday\", \"jyday\", \"day\", \"time\"]\n        def __repr__(self):\n            return self._repr(\"\")\n        def __init__(self):",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "ParserError",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class ParserError(ValueError):\n    \"\"\"Exception subclass used for any failure to parse a datetime string.\n    This is a subclass of :py:exc:`ValueError`, and should be raised any time\n    earlier versions of ``dateutil`` would have raised ``ValueError``.\n    .. versionadded:: 2.8.1\n    \"\"\"\n    def __str__(self):\n        try:\n            return self.args[0] % self.args[1:]\n        except (TypeError, IndexError):",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "UnknownTimezoneWarning",
        "kind": 6,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "class UnknownTimezoneWarning(RuntimeWarning):\n    \"\"\"Raised when the parser finds a timezone it cannot parse into a tzinfo.\n    .. versionadded:: 2.7.0\n    \"\"\"\n# vim:ts=4:sw=4:et",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "def parse(timestr, parserinfo=None, **kwargs):\n    \"\"\"\n    Parse a string in one of the supported formats, using the\n    ``parserinfo`` parameters.\n    :param timestr:\n        A string containing a date/time stamp.\n    :param parserinfo:\n        A :class:`parserinfo` object containing parameters for the parser.\n        If ``None``, the default arguments to the :class:`parserinfo`\n        constructor are used.",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "__all__ = [\"parse\", \"parserinfo\", \"ParserError\"]\n# TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth\n# making public and/or figuring out if there is something we can\n# take off their plate.\nclass _timelex(object):\n    # Fractional seconds are sometimes split by a comma\n    _split_decimal = re.compile(\"([.,])\")\n    def __init__(self, instream):\n        if isinstance(instream, (bytes, bytearray)):\n            instream = instream.decode()",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "DEFAULTPARSER",
        "kind": 5,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "DEFAULTPARSER = parser()\ndef parse(timestr, parserinfo=None, **kwargs):\n    \"\"\"\n    Parse a string in one of the supported formats, using the\n    ``parserinfo`` parameters.\n    :param timestr:\n        A string containing a date/time stamp.\n    :param parserinfo:\n        A :class:`parserinfo` object containing parameters for the parser.\n        If ``None``, the default arguments to the :class:`parserinfo`",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "DEFAULTTZPARSER",
        "kind": 5,
        "importPath": "dateutil.parser._parser",
        "description": "dateutil.parser._parser",
        "peekOfCode": "DEFAULTTZPARSER = _tzparser()\ndef _parsetz(tzstr):\n    return DEFAULTTZPARSER.parse(tzstr)\nclass ParserError(ValueError):\n    \"\"\"Exception subclass used for any failure to parse a datetime string.\n    This is a subclass of :py:exc:`ValueError`, and should be raised any time\n    earlier versions of ``dateutil`` would have raised ``ValueError``.\n    .. versionadded:: 2.8.1\n    \"\"\"\n    def __str__(self):",
        "detail": "dateutil.parser._parser",
        "documentation": {}
    },
    {
        "label": "isoparser",
        "kind": 6,
        "importPath": "dateutil.parser.isoparser",
        "description": "dateutil.parser.isoparser",
        "peekOfCode": "class isoparser(object):\n    def __init__(self, sep=None):\n        \"\"\"\n        :param sep:\n            A single character that separates date and time portions. If\n            ``None``, the parser will accept any single character.\n            For strict ISO-8601 adherence, pass ``'T'``.\n        \"\"\"\n        if sep is not None:\n            if (len(sep) != 1 or ord(sep) >= 128 or sep in '0123456789'):",
        "detail": "dateutil.parser.isoparser",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dateutil.parser.isoparser",
        "description": "dateutil.parser.isoparser",
        "peekOfCode": "__all__ = [\"isoparse\", \"isoparser\"]\ndef _takes_ascii(f):\n    @wraps(f)\n    def func(self, str_in, *args, **kwargs):\n        # If it's a stream, read the whole thing\n        str_in = getattr(str_in, 'read', lambda: str_in)()\n        # If it's unicode, turn it into bytes, since ISO-8601 only covers ASCII\n        if isinstance(str_in, six.text_type):\n            # ASCII is the same in UTF-8\n            try:",
        "detail": "dateutil.parser.isoparser",
        "documentation": {}
    },
    {
        "label": "DEFAULT_ISOPARSER",
        "kind": 5,
        "importPath": "dateutil.parser.isoparser",
        "description": "dateutil.parser.isoparser",
        "peekOfCode": "DEFAULT_ISOPARSER = isoparser()\nisoparse = DEFAULT_ISOPARSER.isoparse",
        "detail": "dateutil.parser.isoparser",
        "documentation": {}
    },
    {
        "label": "isoparse",
        "kind": 5,
        "importPath": "dateutil.parser.isoparser",
        "description": "dateutil.parser.isoparser",
        "peekOfCode": "isoparse = DEFAULT_ISOPARSER.isoparse",
        "detail": "dateutil.parser.isoparser",
        "documentation": {}
    },
    {
        "label": "test_timespec_auto",
        "kind": 2,
        "importPath": "dateutil.test.property.test_isoparse_prop",
        "description": "dateutil.test.property.test_isoparse_prop",
        "peekOfCode": "def test_timespec_auto(dt, sep):\n    if dt.tzinfo is not None:\n        # Assume offset has no sub-second components\n        assume(dt.utcoffset().total_seconds() % 60 == 0)\n    sep = str(sep)          # Python 2.7 requires bytes\n    dtstr = dt.isoformat(sep=sep)\n    dt_rt = isoparse(dtstr)\n    assert dt_rt == dt",
        "detail": "dateutil.test.property.test_isoparse_prop",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE_STRATEGY",
        "kind": 5,
        "importPath": "dateutil.test.property.test_isoparse_prop",
        "description": "dateutil.test.property.test_isoparse_prop",
        "peekOfCode": "TIME_ZONE_STRATEGY = st.sampled_from([None, tz.UTC] +\n    [tz.gettz(zname) for zname in ('US/Eastern', 'US/Pacific',\n                                   'Australia/Sydney', 'Europe/London')])\nASCII_STRATEGY = st.characters(max_codepoint=127)\n@pytest.mark.isoparser\n@given(dt=st.datetimes(timezones=TIME_ZONE_STRATEGY), sep=ASCII_STRATEGY)\ndef test_timespec_auto(dt, sep):\n    if dt.tzinfo is not None:\n        # Assume offset has no sub-second components\n        assume(dt.utcoffset().total_seconds() % 60 == 0)",
        "detail": "dateutil.test.property.test_isoparse_prop",
        "documentation": {}
    },
    {
        "label": "ASCII_STRATEGY",
        "kind": 5,
        "importPath": "dateutil.test.property.test_isoparse_prop",
        "description": "dateutil.test.property.test_isoparse_prop",
        "peekOfCode": "ASCII_STRATEGY = st.characters(max_codepoint=127)\n@pytest.mark.isoparser\n@given(dt=st.datetimes(timezones=TIME_ZONE_STRATEGY), sep=ASCII_STRATEGY)\ndef test_timespec_auto(dt, sep):\n    if dt.tzinfo is not None:\n        # Assume offset has no sub-second components\n        assume(dt.utcoffset().total_seconds() % 60 == 0)\n    sep = str(sep)          # Python 2.7 requires bytes\n    dtstr = dt.isoformat(sep=sep)\n    dt_rt = isoparse(dtstr)",
        "detail": "dateutil.test.property.test_isoparse_prop",
        "documentation": {}
    },
    {
        "label": "test_convertyear",
        "kind": 2,
        "importPath": "dateutil.test.property.test_parser_prop",
        "description": "dateutil.test.property.test_parser_prop",
        "peekOfCode": "def test_convertyear(n):\n    assert n == parserinfo().convertyear(n)\n@pytest.mark.parserinfo\n@given(integers(min_value=-50,\n                max_value=49))\ndef test_convertyear_no_specified_century(n):\n    p = parserinfo()\n    new_year = p._year + n\n    result = p.convertyear(new_year % 100, century_specified=False)\n    assert result == new_year",
        "detail": "dateutil.test.property.test_parser_prop",
        "documentation": {}
    },
    {
        "label": "test_convertyear_no_specified_century",
        "kind": 2,
        "importPath": "dateutil.test.property.test_parser_prop",
        "description": "dateutil.test.property.test_parser_prop",
        "peekOfCode": "def test_convertyear_no_specified_century(n):\n    p = parserinfo()\n    new_year = p._year + n\n    result = p.convertyear(new_year % 100, century_specified=False)\n    assert result == new_year",
        "detail": "dateutil.test.property.test_parser_prop",
        "documentation": {}
    },
    {
        "label": "test_gettz_returns_local",
        "kind": 2,
        "importPath": "dateutil.test.property.test_tz_prop",
        "description": "dateutil.test.property.test_tz_prop",
        "peekOfCode": "def test_gettz_returns_local(gettz_arg, dt):\n    act_tz = tz.gettz(gettz_arg)\n    if isinstance(act_tz, tz.tzlocal):\n        return\n    dt_act = dt.astimezone(tz.gettz(gettz_arg))\n    if six.PY2:\n        dt_exp = dt.astimezone(tz.tzlocal())\n    else:\n        dt_exp = dt.astimezone()\n    assert dt_act == dt_exp",
        "detail": "dateutil.test.property.test_tz_prop",
        "documentation": {}
    },
    {
        "label": "EPOCHALYPSE",
        "kind": 5,
        "importPath": "dateutil.test.property.test_tz_prop",
        "description": "dateutil.test.property.test_tz_prop",
        "peekOfCode": "EPOCHALYPSE = datetime.fromtimestamp(2147483647)\nNEGATIVE_EPOCHALYPSE = datetime.fromtimestamp(0) - timedelta(seconds=2147483648)\n@pytest.mark.gettz\n@pytest.mark.parametrize(\"gettz_arg\", [None, \"\"])\n# TODO: Remove bounds when GH #590 is resolved\n@given(\n    dt=st.datetimes(\n        min_value=NEGATIVE_EPOCHALYPSE, max_value=EPOCHALYPSE, timezones=st.just(tz.UTC),\n    )\n)",
        "detail": "dateutil.test.property.test_tz_prop",
        "documentation": {}
    },
    {
        "label": "NEGATIVE_EPOCHALYPSE",
        "kind": 5,
        "importPath": "dateutil.test.property.test_tz_prop",
        "description": "dateutil.test.property.test_tz_prop",
        "peekOfCode": "NEGATIVE_EPOCHALYPSE = datetime.fromtimestamp(0) - timedelta(seconds=2147483648)\n@pytest.mark.gettz\n@pytest.mark.parametrize(\"gettz_arg\", [None, \"\"])\n# TODO: Remove bounds when GH #590 is resolved\n@given(\n    dt=st.datetimes(\n        min_value=NEGATIVE_EPOCHALYPSE, max_value=EPOCHALYPSE, timezones=st.just(tz.UTC),\n    )\n)\ndef test_gettz_returns_local(gettz_arg, dt):",
        "detail": "dateutil.test.property.test_tz_prop",
        "documentation": {}
    },
    {
        "label": "PicklableMixin",
        "kind": 6,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "class PicklableMixin(object):\n    def _get_nobj_bytes(self, obj, dump_kwargs, load_kwargs):\n        \"\"\"\n        Pickle and unpickle an object using ``pickle.dumps`` / ``pickle.loads``\n        \"\"\"\n        pkl = pickle.dumps(obj, **dump_kwargs)\n        return pickle.loads(pkl, **load_kwargs)\n    def _get_nobj_file(self, obj, dump_kwargs, load_kwargs):\n        \"\"\"\n        Pickle and unpickle an object using ``pickle.dump`` / ``pickle.load`` on",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "TZContextBase",
        "kind": 6,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "class TZContextBase(object):\n    \"\"\"\n    Base class for a context manager which allows changing of time zones.\n    Subclasses may define a guard variable to either block or or allow time\n    zone changes by redefining ``_guard_var_name`` and ``_guard_allows_change``.\n    The default is that the guard variable must be affirmatively set.\n    Subclasses must define ``get_current_tz`` and ``set_current_tz``.\n    \"\"\"\n    _guard_var_name = \"DATEUTIL_MAY_CHANGE_TZ\"\n    _guard_allows_change = True",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "TZEnvContext",
        "kind": 6,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "class TZEnvContext(TZContextBase):\n    \"\"\"\n    Context manager that temporarily sets the `TZ` variable (for use on\n    *nix-like systems). Because the effect is local to the shell anyway, this\n    will apply *unless* a guard is set.\n    If you do not want the TZ environment variable set, you may set the\n    ``DATEUTIL_MAY_NOT_CHANGE_TZ_VAR`` variable to a truthy value.\n    \"\"\"\n    _guard_var_name = \"DATEUTIL_MAY_NOT_CHANGE_TZ_VAR\"\n    _guard_allows_change = False",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "TZWinContext",
        "kind": 6,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "class TZWinContext(TZContextBase):\n    \"\"\"\n    Context manager for changing local time zone on Windows.\n    Because the effect of this is system-wide and global, it may have\n    unintended side effect. Set the ``DATEUTIL_MAY_CHANGE_TZ`` environment\n    variable to a truthy value before using this context manager.\n    \"\"\"\n    def get_current_tz(self):\n        p = subprocess.Popen(['tzutil', '/g'], stdout=subprocess.PIPE)\n        ctzname, err = p.communicate()",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "NotAValueClass",
        "kind": 6,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "class NotAValueClass(object):\n    \"\"\"\n    A class analogous to NaN that has operations defined for any type.\n    \"\"\"\n    def _op(self, other):\n        return self             # Operation with NotAValue returns NotAValue\n    def _cmp(self, other):\n        return False\n    __add__ = __radd__ = _op\n    __sub__ = __rsub__ = _op",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "ComparesEqualClass",
        "kind": 6,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "class ComparesEqualClass(object):\n    \"\"\"\n    A class that is always equal to whatever you compare it to.\n    \"\"\"\n    def __eq__(self, other):\n        return True\n    def __ne__(self, other):\n        return False\n    def __le__(self, other):\n        return True",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "UnsetTzClass",
        "kind": 6,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "class UnsetTzClass(object):\n    \"\"\" Sentinel class for unset time zone variable \"\"\"\n    pass\nUnsetTz = UnsetTzClass()",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "NotAValue",
        "kind": 5,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "NotAValue = NotAValueClass()\nclass ComparesEqualClass(object):\n    \"\"\"\n    A class that is always equal to whatever you compare it to.\n    \"\"\"\n    def __eq__(self, other):\n        return True\n    def __ne__(self, other):\n        return False\n    def __le__(self, other):",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "ComparesEqual",
        "kind": 5,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "ComparesEqual = ComparesEqualClass()\nclass UnsetTzClass(object):\n    \"\"\" Sentinel class for unset time zone variable \"\"\"\n    pass\nUnsetTz = UnsetTzClass()",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "UnsetTz",
        "kind": 5,
        "importPath": "dateutil.test._common",
        "description": "dateutil.test._common",
        "peekOfCode": "UnsetTz = UnsetTzClass()",
        "detail": "dateutil.test._common",
        "documentation": {}
    },
    {
        "label": "pytest_collection_modifyitems",
        "kind": 2,
        "importPath": "dateutil.test.conftest",
        "description": "dateutil.test.conftest",
        "peekOfCode": "def pytest_collection_modifyitems(items):\n    for item in items:\n        marker_getter = getattr(item, 'get_closest_marker', None)\n        # Python 3.3 support\n        if marker_getter is None:\n            marker_getter = item.get_marker\n        marker = marker_getter('xfail')\n        # Need to query the args because conditional xfail tests still have\n        # the xfail mark even if they are not expected to fail\n        if marker and (not marker.args or marker.args[0]):",
        "detail": "dateutil.test.conftest",
        "documentation": {}
    },
    {
        "label": "set_tzpath",
        "kind": 2,
        "importPath": "dateutil.test.conftest",
        "description": "dateutil.test.conftest",
        "peekOfCode": "def set_tzpath():\n    \"\"\"\n    Sets the TZPATH variable if it's specified in an environment variable.\n    \"\"\"\n    tzpath = os.environ.get('DATEUTIL_TZPATH', None)\n    if tzpath is None:\n        return\n    path_components = tzpath.split(':')\n    print(\"Setting TZPATH to {}\".format(path_components))\n    from dateutil import tz",
        "detail": "dateutil.test.conftest",
        "documentation": {}
    },
    {
        "label": "test_easter_western",
        "kind": 2,
        "importPath": "dateutil.test.test_easter",
        "description": "dateutil.test.test_easter",
        "peekOfCode": "def test_easter_western(easter_date):\n    assert easter_date == easter(easter_date.year, EASTER_WESTERN)\n@pytest.mark.parametrize(\"easter_date\", orthodox_easter_dates)\ndef test_easter_orthodox(easter_date):\n    assert easter_date == easter(easter_date.year, EASTER_ORTHODOX)\n@pytest.mark.parametrize(\"easter_date\", julian_easter_dates)\ndef test_easter_julian(easter_date):\n    assert easter_date == easter(easter_date.year, EASTER_JULIAN)\ndef test_easter_bad_method():\n    with pytest.raises(ValueError):",
        "detail": "dateutil.test.test_easter",
        "documentation": {}
    },
    {
        "label": "test_easter_orthodox",
        "kind": 2,
        "importPath": "dateutil.test.test_easter",
        "description": "dateutil.test.test_easter",
        "peekOfCode": "def test_easter_orthodox(easter_date):\n    assert easter_date == easter(easter_date.year, EASTER_ORTHODOX)\n@pytest.mark.parametrize(\"easter_date\", julian_easter_dates)\ndef test_easter_julian(easter_date):\n    assert easter_date == easter(easter_date.year, EASTER_JULIAN)\ndef test_easter_bad_method():\n    with pytest.raises(ValueError):\n        easter(1975, 4)",
        "detail": "dateutil.test.test_easter",
        "documentation": {}
    },
    {
        "label": "test_easter_julian",
        "kind": 2,
        "importPath": "dateutil.test.test_easter",
        "description": "dateutil.test.test_easter",
        "peekOfCode": "def test_easter_julian(easter_date):\n    assert easter_date == easter(easter_date.year, EASTER_JULIAN)\ndef test_easter_bad_method():\n    with pytest.raises(ValueError):\n        easter(1975, 4)",
        "detail": "dateutil.test.test_easter",
        "documentation": {}
    },
    {
        "label": "test_easter_bad_method",
        "kind": 2,
        "importPath": "dateutil.test.test_easter",
        "description": "dateutil.test.test_easter",
        "peekOfCode": "def test_easter_bad_method():\n    with pytest.raises(ValueError):\n        easter(1975, 4)",
        "detail": "dateutil.test.test_easter",
        "documentation": {}
    },
    {
        "label": "western_easter_dates",
        "kind": 5,
        "importPath": "dateutil.test.test_easter",
        "description": "dateutil.test.test_easter",
        "peekOfCode": "western_easter_dates = [\n    date(1990, 4, 15), date(1991, 3, 31), date(1992, 4, 19), date(1993, 4, 11),\n    date(1994, 4,  3), date(1995, 4, 16), date(1996, 4,  7), date(1997, 3, 30),\n    date(1998, 4, 12), date(1999, 4,  4),\n    date(2000, 4, 23), date(2001, 4, 15), date(2002, 3, 31), date(2003, 4, 20),\n    date(2004, 4, 11), date(2005, 3, 27), date(2006, 4, 16), date(2007, 4,  8),\n    date(2008, 3, 23), date(2009, 4, 12),\n    date(2010, 4,  4), date(2011, 4, 24), date(2012, 4,  8), date(2013, 3, 31),\n    date(2014, 4, 20), date(2015, 4,  5), date(2016, 3, 27), date(2017, 4, 16),\n    date(2018, 4,  1), date(2019, 4, 21),",
        "detail": "dateutil.test.test_easter",
        "documentation": {}
    },
    {
        "label": "orthodox_easter_dates",
        "kind": 5,
        "importPath": "dateutil.test.test_easter",
        "description": "dateutil.test.test_easter",
        "peekOfCode": "orthodox_easter_dates = [\n    date(1990, 4, 15), date(1991, 4,  7), date(1992, 4, 26), date(1993, 4, 18),\n    date(1994, 5,  1), date(1995, 4, 23), date(1996, 4, 14), date(1997, 4, 27),\n    date(1998, 4, 19), date(1999, 4, 11),\n    date(2000, 4, 30), date(2001, 4, 15), date(2002, 5,  5), date(2003, 4, 27),\n    date(2004, 4, 11), date(2005, 5,  1), date(2006, 4, 23), date(2007, 4,  8),\n    date(2008, 4, 27), date(2009, 4, 19),\n    date(2010, 4,  4), date(2011, 4, 24), date(2012, 4, 15), date(2013, 5,  5),\n    date(2014, 4, 20), date(2015, 4, 12), date(2016, 5,  1), date(2017, 4, 16),\n    date(2018, 4,  8), date(2019, 4, 28),",
        "detail": "dateutil.test.test_easter",
        "documentation": {}
    },
    {
        "label": "julian_easter_dates",
        "kind": 5,
        "importPath": "dateutil.test.test_easter",
        "description": "dateutil.test.test_easter",
        "peekOfCode": "julian_easter_dates = [\n    date( 326, 4,  3), date( 375, 4,  5), date( 492, 4,  5), date( 552, 3, 31),\n    date( 562, 4,  9), date( 569, 4, 21), date( 597, 4, 14), date( 621, 4, 19),\n    date( 636, 3, 31), date( 655, 3, 29), date( 700, 4, 11), date( 725, 4,  8),\n    date( 750, 3, 29), date( 782, 4,  7), date( 835, 4, 18), date( 849, 4, 14),\n    date( 867, 3, 30), date( 890, 4, 12), date( 922, 4, 21), date( 934, 4,  6),\n    date(1049, 3, 26), date(1058, 4, 19), date(1113, 4,  6), date(1119, 3, 30),\n    date(1242, 4, 20), date(1255, 3, 28), date(1257, 4,  8), date(1258, 3, 24),\n    date(1261, 4, 24), date(1278, 4, 17), date(1333, 4,  4), date(1351, 4, 17),\n    date(1371, 4,  6), date(1391, 3, 26), date(1402, 3, 26), date(1412, 4,  3),",
        "detail": "dateutil.test.test_easter",
        "documentation": {}
    },
    {
        "label": "test_imported_modules",
        "kind": 2,
        "importPath": "dateutil.test.test_import_star",
        "description": "dateutil.test.test_import_star",
        "peekOfCode": "def test_imported_modules():\n    \"\"\" Test that `from dateutil import *` adds modules in __all__ locally \"\"\"\n    import dateutil.easter\n    import dateutil.parser\n    import dateutil.relativedelta\n    import dateutil.rrule\n    import dateutil.tz\n    import dateutil.utils\n    import dateutil.zoneinfo\n    assert dateutil.easter == new_locals.pop(\"easter\")",
        "detail": "dateutil.test.test_import_star",
        "documentation": {}
    },
    {
        "label": "prev_locals",
        "kind": 5,
        "importPath": "dateutil.test.test_import_star",
        "description": "dateutil.test.test_import_star",
        "peekOfCode": "prev_locals = list(locals())\nfrom dateutil import *\nnew_locals = {name:value for name,value in locals().items()\n              if name not in prev_locals}\nnew_locals.pop('prev_locals')\n@pytest.mark.import_star\ndef test_imported_modules():\n    \"\"\" Test that `from dateutil import *` adds modules in __all__ locally \"\"\"\n    import dateutil.easter\n    import dateutil.parser",
        "detail": "dateutil.test.test_import_star",
        "documentation": {}
    },
    {
        "label": "new_locals",
        "kind": 5,
        "importPath": "dateutil.test.test_import_star",
        "description": "dateutil.test.test_import_star",
        "peekOfCode": "new_locals = {name:value for name,value in locals().items()\n              if name not in prev_locals}\nnew_locals.pop('prev_locals')\n@pytest.mark.import_star\ndef test_imported_modules():\n    \"\"\" Test that `from dateutil import *` adds modules in __all__ locally \"\"\"\n    import dateutil.easter\n    import dateutil.parser\n    import dateutil.relativedelta\n    import dateutil.rrule",
        "detail": "dateutil.test.test_import_star",
        "documentation": {}
    },
    {
        "label": "test_import_version_str",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_version_str():\n    \"\"\" Test that dateutil.__version__ can be imported\"\"\"\n    from dateutil import __version__\ndef test_import_version_root():\n    import dateutil\n    assert hasattr(dateutil, '__version__')\n# Test that dateutil.easter-related imports work properly\ndef test_import_easter_direct():\n    import dateutil.easter\ndef test_import_easter_from():",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_version_root",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_version_root():\n    import dateutil\n    assert hasattr(dateutil, '__version__')\n# Test that dateutil.easter-related imports work properly\ndef test_import_easter_direct():\n    import dateutil.easter\ndef test_import_easter_from():\n    from dateutil import easter\ndef test_import_easter_start():\n    from dateutil.easter import easter",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_easter_direct",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_easter_direct():\n    import dateutil.easter\ndef test_import_easter_from():\n    from dateutil import easter\ndef test_import_easter_start():\n    from dateutil.easter import easter\n#  Test that dateutil.parser-related imports work properly\ndef test_import_parser_direct():\n    import dateutil.parser\ndef test_import_parser_from():",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_easter_from",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_easter_from():\n    from dateutil import easter\ndef test_import_easter_start():\n    from dateutil.easter import easter\n#  Test that dateutil.parser-related imports work properly\ndef test_import_parser_direct():\n    import dateutil.parser\ndef test_import_parser_from():\n    from dateutil import parser\ndef test_import_parser_all():",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_easter_start",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_easter_start():\n    from dateutil.easter import easter\n#  Test that dateutil.parser-related imports work properly\ndef test_import_parser_direct():\n    import dateutil.parser\ndef test_import_parser_from():\n    from dateutil import parser\ndef test_import_parser_all():\n    # All interface\n    from dateutil.parser import parse",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_parser_direct",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_parser_direct():\n    import dateutil.parser\ndef test_import_parser_from():\n    from dateutil import parser\ndef test_import_parser_all():\n    # All interface\n    from dateutil.parser import parse\n    from dateutil.parser import parserinfo\n    # Other public classes\n    from dateutil.parser import parser",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_parser_from",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_parser_from():\n    from dateutil import parser\ndef test_import_parser_all():\n    # All interface\n    from dateutil.parser import parse\n    from dateutil.parser import parserinfo\n    # Other public classes\n    from dateutil.parser import parser\n    for var in (parse, parserinfo, parser):\n        assert var is not None",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_parser_all",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_parser_all():\n    # All interface\n    from dateutil.parser import parse\n    from dateutil.parser import parserinfo\n    # Other public classes\n    from dateutil.parser import parser\n    for var in (parse, parserinfo, parser):\n        assert var is not None\n# Test that dateutil.relativedelta-related imports work properly\ndef test_import_relative_delta_direct():",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_relative_delta_direct",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_relative_delta_direct():\n    import dateutil.relativedelta\ndef test_import_relative_delta_from():\n    from dateutil import relativedelta\ndef test_import_relative_delta_all():\n    from dateutil.relativedelta import relativedelta\n    from dateutil.relativedelta import MO, TU, WE, TH, FR, SA, SU\n    for var in (relativedelta, MO, TU, WE, TH, FR, SA, SU):\n        assert var is not None\n    # In the public interface but not in all",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_relative_delta_from",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_relative_delta_from():\n    from dateutil import relativedelta\ndef test_import_relative_delta_all():\n    from dateutil.relativedelta import relativedelta\n    from dateutil.relativedelta import MO, TU, WE, TH, FR, SA, SU\n    for var in (relativedelta, MO, TU, WE, TH, FR, SA, SU):\n        assert var is not None\n    # In the public interface but not in all\n    from dateutil.relativedelta import weekday\n    assert weekday is not  None",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_relative_delta_all",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_relative_delta_all():\n    from dateutil.relativedelta import relativedelta\n    from dateutil.relativedelta import MO, TU, WE, TH, FR, SA, SU\n    for var in (relativedelta, MO, TU, WE, TH, FR, SA, SU):\n        assert var is not None\n    # In the public interface but not in all\n    from dateutil.relativedelta import weekday\n    assert weekday is not  None\n# Test that dateutil.rrule related imports work properly\ndef test_import_rrule_direct():",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_rrule_direct",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_rrule_direct():\n    import dateutil.rrule\ndef test_import_rrule_from():\n    from dateutil import rrule\ndef test_import_rrule_all():\n    from dateutil.rrule import rrule\n    from dateutil.rrule import rruleset\n    from dateutil.rrule import rrulestr\n    from dateutil.rrule import YEARLY, MONTHLY, WEEKLY, DAILY\n    from dateutil.rrule import HOURLY, MINUTELY, SECONDLY",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_rrule_from",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_rrule_from():\n    from dateutil import rrule\ndef test_import_rrule_all():\n    from dateutil.rrule import rrule\n    from dateutil.rrule import rruleset\n    from dateutil.rrule import rrulestr\n    from dateutil.rrule import YEARLY, MONTHLY, WEEKLY, DAILY\n    from dateutil.rrule import HOURLY, MINUTELY, SECONDLY\n    from dateutil.rrule import MO, TU, WE, TH, FR, SA, SU\n    rr_all = (rrule, rruleset, rrulestr,",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_rrule_all",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_rrule_all():\n    from dateutil.rrule import rrule\n    from dateutil.rrule import rruleset\n    from dateutil.rrule import rrulestr\n    from dateutil.rrule import YEARLY, MONTHLY, WEEKLY, DAILY\n    from dateutil.rrule import HOURLY, MINUTELY, SECONDLY\n    from dateutil.rrule import MO, TU, WE, TH, FR, SA, SU\n    rr_all = (rrule, rruleset, rrulestr,\n              YEARLY, MONTHLY, WEEKLY, DAILY,\n              HOURLY, MINUTELY, SECONDLY,",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_tztest_direct",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_tztest_direct():\n    import dateutil.tz\ndef test_import_tz_from():\n    from dateutil import tz\ndef test_import_tz_all():\n    from dateutil.tz import tzutc\n    from dateutil.tz import tzoffset\n    from dateutil.tz import tzlocal\n    from dateutil.tz import tzfile\n    from dateutil.tz import tzrange",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_tz_from",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_tz_from():\n    from dateutil import tz\ndef test_import_tz_all():\n    from dateutil.tz import tzutc\n    from dateutil.tz import tzoffset\n    from dateutil.tz import tzlocal\n    from dateutil.tz import tzfile\n    from dateutil.tz import tzrange\n    from dateutil.tz import tzstr\n    from dateutil.tz import tzical",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_tz_all",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_tz_all():\n    from dateutil.tz import tzutc\n    from dateutil.tz import tzoffset\n    from dateutil.tz import tzlocal\n    from dateutil.tz import tzfile\n    from dateutil.tz import tzrange\n    from dateutil.tz import tzstr\n    from dateutil.tz import tzical\n    from dateutil.tz import gettz\n    from dateutil.tz import tzwin",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_tz_windows_direct",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_tz_windows_direct():\n    import dateutil.tzwin\n@pytest.mark.skipif(not HOST_IS_WINDOWS, reason=\"Requires Windows\")\ndef test_import_tz_windows_from():\n    from dateutil import tzwin\n@pytest.mark.skipif(not HOST_IS_WINDOWS, reason=\"Requires Windows\")\ndef test_import_tz_windows_star():\n    from dateutil.tzwin import tzwin\n    from dateutil.tzwin import tzwinlocal\n    tzwin_all = [tzwin, tzwinlocal]",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_tz_windows_from",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_tz_windows_from():\n    from dateutil import tzwin\n@pytest.mark.skipif(not HOST_IS_WINDOWS, reason=\"Requires Windows\")\ndef test_import_tz_windows_star():\n    from dateutil.tzwin import tzwin\n    from dateutil.tzwin import tzwinlocal\n    tzwin_all = [tzwin, tzwinlocal]\n    for var in tzwin_all:\n        assert var is not None\n# Test imports of Zone Info",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_tz_windows_star",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_tz_windows_star():\n    from dateutil.tzwin import tzwin\n    from dateutil.tzwin import tzwinlocal\n    tzwin_all = [tzwin, tzwinlocal]\n    for var in tzwin_all:\n        assert var is not None\n# Test imports of Zone Info\ndef test_import_zone_info_direct():\n    import dateutil.zoneinfo\ndef test_import_zone_info_from():",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_zone_info_direct",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_zone_info_direct():\n    import dateutil.zoneinfo\ndef test_import_zone_info_from():\n    from dateutil import zoneinfo\ndef test_import_zone_info_star():\n    from dateutil.zoneinfo import gettz\n    from dateutil.zoneinfo import gettz_db_metadata\n    from dateutil.zoneinfo import rebuild\n    zi_all = (gettz, gettz_db_metadata, rebuild)\n    for var in zi_all:",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_zone_info_from",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_zone_info_from():\n    from dateutil import zoneinfo\ndef test_import_zone_info_star():\n    from dateutil.zoneinfo import gettz\n    from dateutil.zoneinfo import gettz_db_metadata\n    from dateutil.zoneinfo import rebuild\n    zi_all = (gettz, gettz_db_metadata, rebuild)\n    for var in zi_all:\n        assert var is not None",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_import_zone_info_star",
        "kind": 2,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "def test_import_zone_info_star():\n    from dateutil.zoneinfo import gettz\n    from dateutil.zoneinfo import gettz_db_metadata\n    from dateutil.zoneinfo import rebuild\n    zi_all = (gettz, gettz_db_metadata, rebuild)\n    for var in zi_all:\n        assert var is not None",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "HOST_IS_WINDOWS",
        "kind": 5,
        "importPath": "dateutil.test.test_imports",
        "description": "dateutil.test.test_imports",
        "peekOfCode": "HOST_IS_WINDOWS = sys.platform.startswith('win')\ndef test_import_version_str():\n    \"\"\" Test that dateutil.__version__ can be imported\"\"\"\n    from dateutil import __version__\ndef test_import_version_root():\n    import dateutil\n    assert hasattr(dateutil, '__version__')\n# Test that dateutil.easter-related imports work properly\ndef test_import_easter_direct():\n    import dateutil.easter",
        "detail": "dateutil.test.test_imports",
        "documentation": {}
    },
    {
        "label": "test_YMD_could_be_day",
        "kind": 2,
        "importPath": "dateutil.test.test_internals",
        "description": "dateutil.test.test_internals",
        "peekOfCode": "def test_YMD_could_be_day():\n    ymd = _ymd('foo bar 124 baz')\n    ymd.append(2, 'M')\n    assert ymd.has_month\n    assert not ymd.has_year\n    assert ymd.could_be_day(4)\n    assert not ymd.could_be_day(-6)\n    assert not ymd.could_be_day(32)\n    # Assumes leap year\n    assert ymd.could_be_day(29)",
        "detail": "dateutil.test.test_internals",
        "documentation": {}
    },
    {
        "label": "test_parser_private_warns",
        "kind": 2,
        "importPath": "dateutil.test.test_internals",
        "description": "dateutil.test.test_internals",
        "peekOfCode": "def test_parser_private_warns():\n    from dateutil.parser import _timelex, _tzparser\n    from dateutil.parser import _parsetz\n    with pytest.warns(DeprecationWarning):\n        _tzparser()\n    with pytest.warns(DeprecationWarning):\n        _timelex('2014-03-03')\n    with pytest.warns(DeprecationWarning):\n        _parsetz('+05:00')\n@pytest.mark.skipif(IS_PY32, reason='pytest.warns not supported on Python 3.2')",
        "detail": "dateutil.test.test_internals",
        "documentation": {}
    },
    {
        "label": "test_parser_parser_private_not_warns",
        "kind": 2,
        "importPath": "dateutil.test.test_internals",
        "description": "dateutil.test.test_internals",
        "peekOfCode": "def test_parser_parser_private_not_warns():\n    from dateutil.parser._parser import _timelex, _tzparser\n    from dateutil.parser._parser import _parsetz\n    with pytest.warns(None) as recorder:\n        _tzparser()\n        assert len(recorder) == 0\n    with pytest.warns(None) as recorder:\n        _timelex('2014-03-03')\n        assert len(recorder) == 0\n    with pytest.warns(None) as recorder:",
        "detail": "dateutil.test.test_internals",
        "documentation": {}
    },
    {
        "label": "test_tzstr_internal_timedeltas",
        "kind": 2,
        "importPath": "dateutil.test.test_internals",
        "description": "dateutil.test.test_internals",
        "peekOfCode": "def test_tzstr_internal_timedeltas():\n    with pytest.warns(tz.DeprecatedTzFormatWarning):\n        tz1 = tz.tzstr(\"EST5EDT,5,4,0,7200,11,-3,0,7200\")\n    with pytest.warns(tz.DeprecatedTzFormatWarning):\n        tz2 = tz.tzstr(\"EST5EDT,4,1,0,7200,10,-1,0,7200\")\n    assert tz1._start_delta != tz2._start_delta\n    assert tz1._end_delta != tz2._end_delta",
        "detail": "dateutil.test.test_internals",
        "documentation": {}
    },
    {
        "label": "IS_PY32",
        "kind": 5,
        "importPath": "dateutil.test.test_internals",
        "description": "dateutil.test.test_internals",
        "peekOfCode": "IS_PY32 = sys.version_info[0:2] == (3, 2)\n@pytest.mark.smoke\ndef test_YMD_could_be_day():\n    ymd = _ymd('foo bar 124 baz')\n    ymd.append(2, 'M')\n    assert ymd.has_month\n    assert not ymd.has_year\n    assert ymd.could_be_day(4)\n    assert not ymd.could_be_day(-6)\n    assert not ymd.could_be_day(32)",
        "detail": "dateutil.test.test_internals",
        "documentation": {}
    },
    {
        "label": "test_year_only",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_year_only(dt):\n    dtstr = dt.strftime('%Y')\n    assert isoparse(dtstr) == dt\nDATES += [datetime(2000, 2, 1), datetime(2017, 4, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_month(dt):\n    fmt   = '%Y-%m'\n    dtstr = dt.strftime(fmt)\n    assert isoparse(dtstr) == dt\nDATES += [datetime(2016, 2, 29), datetime(2018, 3, 15)]",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_year_month",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_year_month(dt):\n    fmt   = '%Y-%m'\n    dtstr = dt.strftime(fmt)\n    assert isoparse(dtstr) == dt\nDATES += [datetime(2016, 2, 29), datetime(2018, 3, 15)]\nYMD_FMTS = ('%Y%m%d', '%Y-%m-%d')\n@pytest.mark.parametrize('dt', tuple(DATES))\n@pytest.mark.parametrize('fmt', YMD_FMTS)\ndef test_year_month_day(dt, fmt):\n    dtstr = dt.strftime(fmt)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_year_month_day",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_year_month_day(dt, fmt):\n    dtstr = dt.strftime(fmt)\n    assert isoparse(dtstr) == dt\ndef _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset,\n                            microsecond_precision=None):\n    tzi, offset_str = tzoffset\n    fmt = date_fmt + 'T' + time_fmt\n    dt = dt.replace(tzinfo=tzi)\n    dtstr = dt.strftime(fmt)\n    if microsecond_precision is not None:",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_ymd_h",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_ymd_h(dt, date_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, '%H', tzoffset)\nDATETIMES = [datetime(2012, 1, 6, 9, 37)]\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('time_fmt', ('%H%M', '%H:%M'))\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)\ndef test_ymd_hm(dt, date_fmt, time_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\nDATETIMES = [datetime(2003, 9, 2, 22, 14, 2),",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_ymd_hm",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_ymd_hm(dt, date_fmt, time_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\nDATETIMES = [datetime(2003, 9, 2, 22, 14, 2),\n             datetime(2003, 8, 8, 14, 9, 14),\n             datetime(2003, 4, 7, 6, 14, 59)]\nHMS_FMTS = ('%H%M%S', '%H:%M:%S')\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('time_fmt', HMS_FMTS)\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_ymd_hms",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_ymd_hms(dt, date_fmt, time_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\nDATETIMES = [datetime(2017, 11, 27, 6, 14, 30, 123456)]\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('time_fmt', (x + sep + '%f' for x in HMS_FMTS\n                                      for sep in '.,'))\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)\n@pytest.mark.parametrize('precision', list(range(3, 7)))\ndef test_ymd_hms_micro(dt, date_fmt, time_fmt, tzoffset, precision):",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_ymd_hms_micro",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_ymd_hms_micro(dt, date_fmt, time_fmt, tzoffset, precision):\n    # Truncate the microseconds to the desired precision for the representation\n    dt = dt.replace(microsecond=int(round(dt.microsecond, precision-6)))\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset, precision)\n###\n# Truncation of extra digits beyond microsecond precision\n@pytest.mark.parametrize('dt_str', [\n    '2018-07-03T14:07:00.123456000001',\n    '2018-07-03T14:07:00.123456999999',\n])",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_extra_subsecond_digits",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_extra_subsecond_digits(dt_str):\n    assert isoparse(dt_str) == datetime(2018, 7, 3, 14, 7, 0, 123456)\n@pytest.mark.parametrize('tzoffset', FULL_TZOFFSETS)\ndef test_full_tzoffsets(tzoffset):\n    dt = datetime(2017, 11, 27, 6, 14, 30, 123456)\n    date_fmt = '%Y-%m-%d'\n    time_fmt = '%H:%M:%S.%f'\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\n@pytest.mark.parametrize('dt_str', [\n    '2014-04-11T00',",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_full_tzoffsets",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_full_tzoffsets(tzoffset):\n    dt = datetime(2017, 11, 27, 6, 14, 30, 123456)\n    date_fmt = '%Y-%m-%d'\n    time_fmt = '%H:%M:%S.%f'\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\n@pytest.mark.parametrize('dt_str', [\n    '2014-04-11T00',\n    '2014-04-10T24',\n    '2014-04-11T00:00',\n    '2014-04-10T24:00',",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_datetime_midnight",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_datetime_midnight(dt_str):\n    assert isoparse(dt_str) == datetime(2014, 4, 11, 0, 0, 0, 0)\n@pytest.mark.parametrize('datestr', [\n    '2014-01-01',\n    '20140101',\n])\n@pytest.mark.parametrize('sep', [' ', 'a', 'T', '_', '-'])\ndef test_isoparse_sep_none(datestr, sep):\n    isostr = datestr + sep + '14:33:09'\n    assert isoparse(isostr) == datetime(2014, 1, 1, 14, 33, 9)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isoparse_sep_none",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isoparse_sep_none(datestr, sep):\n    isostr = datestr + sep + '14:33:09'\n    assert isoparse(isostr) == datetime(2014, 1, 1, 14, 33, 9)\n##\n# Uncommon date formats\nTIME_ARGS = ('time_args',\n    ((None, time(0), None), ) + tuple(('%H:%M:%S.%f', _t, _tz)\n        for _t, _tz in it.product([time(0), time(9, 30), time(14, 47)],\n                                  TZOFFSETS)))\n@pytest.mark.parametrize('isocal,dt_expected',[",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isoweek",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isoweek(isocal, dt_expected):\n    # TODO: Figure out how to parametrize this on formats, too\n    for fmt in ('{:04d}-W{:02d}', '{:04d}W{:02d}'):\n        dtstr = fmt.format(*isocal)\n        assert isoparse(dtstr) == dt_expected\n@pytest.mark.parametrize('isocal,dt_expected',[\n    ((2016, 13, 7), datetime(2016, 4, 3)),\n    ((2004, 53, 7), datetime(2005, 1, 2)),      # ISO year != Cal year\n    ((2009, 1, 2), datetime(2008, 12, 30)),     # ISO year < Cal year\n    ((2009, 53, 6), datetime(2010, 1, 2))       # ISO year > Cal year",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isoweek_day",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isoweek_day(isocal, dt_expected):\n    # TODO: Figure out how to parametrize this on formats, too\n    for fmt in ('{:04d}-W{:02d}-{:d}', '{:04d}W{:02d}{:d}'):\n        dtstr = fmt.format(*isocal)\n        assert isoparse(dtstr) == dt_expected\n@pytest.mark.parametrize('isoord,dt_expected', [\n    ((2004, 1), datetime(2004, 1, 1)),\n    ((2016, 60), datetime(2016, 2, 29)),\n    ((2017, 60), datetime(2017, 3, 1)),\n    ((2016, 366), datetime(2016, 12, 31)),",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_iso_ordinal",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_iso_ordinal(isoord, dt_expected):\n    for fmt in ('{:04d}-{:03d}', '{:04d}{:03d}'):\n        dtstr = fmt.format(*isoord)\n        assert isoparse(dtstr) == dt_expected\n###\n# Acceptance of bytes\n@pytest.mark.parametrize('isostr,dt', [\n    (b'2014', datetime(2014, 1, 1)),\n    (b'20140204', datetime(2014, 2, 4)),\n    (b'2014-02-04', datetime(2014, 2, 4)),",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_bytes",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_bytes(isostr, dt):\n    assert isoparse(isostr) == dt\n###\n# Invalid ISO strings\n@pytest.mark.parametrize('isostr,exception', [\n    ('201', ValueError),                        # ISO string too short\n    ('2012-0425', ValueError),                  # Inconsistent date separators\n    ('201204-25', ValueError),                  # Inconsistent date separators\n    ('20120425T0120:00', ValueError),           # Inconsistent time separators\n    ('20120425T01:2000', ValueError),           # Inconsistent time separators",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_iso_raises",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_iso_raises(isostr, exception):\n    with pytest.raises(exception):\n        isoparse(isostr)\n@pytest.mark.parametrize('sep_act, valid_sep, exception', [\n    ('T', 'C', ValueError),\n    ('C', 'T', ValueError),\n])\ndef test_iso_with_sep_raises(sep_act, valid_sep, exception):\n    parser = isoparser(sep=valid_sep)\n    isostr = '2012-04-25' + sep_act + '01:25:00'",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_iso_with_sep_raises",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_iso_with_sep_raises(sep_act, valid_sep, exception):\n    parser = isoparser(sep=valid_sep)\n    isostr = '2012-04-25' + sep_act + '01:25:00'\n    with pytest.raises(exception):\n        parser.isoparse(isostr)\n###\n# Test ISOParser constructor\n@pytest.mark.parametrize('sep', ['  ', '9', '🍛'])\ndef test_isoparser_invalid_sep(sep):\n    with pytest.raises(ValueError):",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isoparser_invalid_sep",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isoparser_invalid_sep(sep):\n    with pytest.raises(ValueError):\n        isoparser(sep=sep)\n# This only fails on Python 3\n@pytest.mark.xfail(not six.PY2, reason=\"Fails on Python 3 only\")\ndef test_isoparser_byte_sep():\n    dt = datetime(2017, 12, 6, 12, 30, 45)\n    dt_str = dt.isoformat(sep=str('T'))\n    dt_rt = isoparser(sep=b'T').isoparse(dt_str)\n    assert dt == dt_rt",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isoparser_byte_sep",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isoparser_byte_sep():\n    dt = datetime(2017, 12, 6, 12, 30, 45)\n    dt_str = dt.isoformat(sep=str('T'))\n    dt_rt = isoparser(sep=b'T').isoparse(dt_str)\n    assert dt == dt_rt\n###\n# Test parse_tzstr\n@pytest.mark.parametrize('tzoffset', FULL_TZOFFSETS)\ndef test_parse_tzstr(tzoffset):\n    dt = datetime(2017, 11, 27, 6, 14, 30, 123456)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_parse_tzstr",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_parse_tzstr(tzoffset):\n    dt = datetime(2017, 11, 27, 6, 14, 30, 123456)\n    date_fmt = '%Y-%m-%d'\n    time_fmt = '%H:%M:%S.%f'\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\n@pytest.mark.parametrize('tzstr', [\n    '-00:00', '+00:00', '+00', '-00', '+0000', '-0000'\n])\n@pytest.mark.parametrize('zero_as_utc', [True, False])\ndef test_parse_tzstr_zero_as_utc(tzstr, zero_as_utc):",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_parse_tzstr_zero_as_utc",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_parse_tzstr_zero_as_utc(tzstr, zero_as_utc):\n    tzi = isoparser().parse_tzstr(tzstr, zero_as_utc=zero_as_utc)\n    assert tzi == UTC\n    assert (type(tzi) == tz.tzutc) == zero_as_utc\n@pytest.mark.parametrize('tzstr,exception', [\n    ('00:00', ValueError),     # No sign\n    ('05:00', ValueError),     # No sign\n    ('_00:00', ValueError),    # Invalid sign\n    ('+25:00', ValueError),    # Offset too large\n    ('00:0000', ValueError),   # String too long",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_parse_tzstr_fails",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_parse_tzstr_fails(tzstr, exception):\n    with pytest.raises(exception):\n        isoparser().parse_tzstr(tzstr)\n###\n# Test parse_isodate\ndef __make_date_examples():\n    dates_no_day = [\n        date(1999, 12, 1),\n        date(2016, 2, 1)\n    ]",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_parse_isodate",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_parse_isodate(d, dt_fmt, as_bytes):\n    d_str = d.strftime(dt_fmt)\n    if isinstance(d_str, six.text_type) and as_bytes:\n        d_str = d_str.encode('ascii')\n    elif isinstance(d_str, bytes) and not as_bytes:\n        d_str = d_str.decode('ascii')\n    iparser = isoparser()\n    assert iparser.parse_isodate(d_str) == d\n@pytest.mark.parametrize('isostr,exception', [\n    ('243', ValueError),                        # ISO string too short",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isodate_raises",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isodate_raises(isostr, exception):\n    with pytest.raises(exception):\n        isoparser().parse_isodate(isostr)\ndef test_parse_isodate_error_text():\n    with pytest.raises(ValueError) as excinfo:\n        isoparser().parse_isodate('2014-0423')\n    # ensure the error message does not contain b' prefixes\n    if six.PY2:\n        expected_error = \"String contains unknown ISO components: u'2014-0423'\"\n    else:",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_parse_isodate_error_text",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_parse_isodate_error_text():\n    with pytest.raises(ValueError) as excinfo:\n        isoparser().parse_isodate('2014-0423')\n    # ensure the error message does not contain b' prefixes\n    if six.PY2:\n        expected_error = \"String contains unknown ISO components: u'2014-0423'\"\n    else:\n        expected_error = \"String contains unknown ISO components: '2014-0423'\"\n    assert expected_error == str(excinfo.value)\n###",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isotime",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isotime(time_val, time_fmt, as_bytes):\n    tstr = time_val.strftime(time_fmt)\n    if isinstance(tstr, six.text_type) and as_bytes:\n        tstr = tstr.encode('ascii')\n    elif isinstance(tstr, bytes) and not as_bytes:\n        tstr = tstr.decode('ascii')\n    iparser = isoparser()\n    assert iparser.parse_isotime(tstr) == time_val\n@pytest.mark.parametrize('isostr', [\n    '24:00',",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isotime_midnight",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isotime_midnight(isostr):\n    iparser = isoparser()\n    assert iparser.parse_isotime(isostr) == time(0, 0, 0, 0)\n@pytest.mark.parametrize('isostr,exception', [\n    ('3', ValueError),                          # ISO string too short\n    ('14時30分15秒', ValueError),                # Not ASCII\n    ('14_30_15', ValueError),                   # Invalid separators\n    ('1430:15', ValueError),                    # Inconsistent separator use\n    ('25', ValueError),                         # Invalid hours\n    ('25:15', ValueError),                      # Invalid hours",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "test_isotime_raises",
        "kind": 2,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "def test_isotime_raises(isostr, exception):\n    iparser = isoparser()\n    with pytest.raises(exception):\n        iparser.parse_isotime(isostr)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "FULL_TZOFFSETS",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "FULL_TZOFFSETS = _generate_tzoffsets(False)\nFULL_TZOFFSETS_AWARE = [x for x in FULL_TZOFFSETS if x[1]]\nTZOFFSETS = _generate_tzoffsets(True)\nDATES = [datetime(1996, 1, 1), datetime(2017, 1, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_only(dt):\n    dtstr = dt.strftime('%Y')\n    assert isoparse(dtstr) == dt\nDATES += [datetime(2000, 2, 1), datetime(2017, 4, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "FULL_TZOFFSETS_AWARE",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "FULL_TZOFFSETS_AWARE = [x for x in FULL_TZOFFSETS if x[1]]\nTZOFFSETS = _generate_tzoffsets(True)\nDATES = [datetime(1996, 1, 1), datetime(2017, 1, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_only(dt):\n    dtstr = dt.strftime('%Y')\n    assert isoparse(dtstr) == dt\nDATES += [datetime(2000, 2, 1), datetime(2017, 4, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_month(dt):",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "TZOFFSETS",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "TZOFFSETS = _generate_tzoffsets(True)\nDATES = [datetime(1996, 1, 1), datetime(2017, 1, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_only(dt):\n    dtstr = dt.strftime('%Y')\n    assert isoparse(dtstr) == dt\nDATES += [datetime(2000, 2, 1), datetime(2017, 4, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_month(dt):\n    fmt   = '%Y-%m'",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "DATES",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "DATES = [datetime(1996, 1, 1), datetime(2017, 1, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_only(dt):\n    dtstr = dt.strftime('%Y')\n    assert isoparse(dtstr) == dt\nDATES += [datetime(2000, 2, 1), datetime(2017, 4, 1)]\n@pytest.mark.parametrize('dt', tuple(DATES))\ndef test_year_month(dt):\n    fmt   = '%Y-%m'\n    dtstr = dt.strftime(fmt)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "YMD_FMTS",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "YMD_FMTS = ('%Y%m%d', '%Y-%m-%d')\n@pytest.mark.parametrize('dt', tuple(DATES))\n@pytest.mark.parametrize('fmt', YMD_FMTS)\ndef test_year_month_day(dt, fmt):\n    dtstr = dt.strftime(fmt)\n    assert isoparse(dtstr) == dt\ndef _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset,\n                            microsecond_precision=None):\n    tzi, offset_str = tzoffset\n    fmt = date_fmt + 'T' + time_fmt",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "DATETIMES",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "DATETIMES = [datetime(1998, 4, 16, 12),\n             datetime(2019, 11, 18, 23),\n             datetime(2014, 12, 16, 4)]\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)\ndef test_ymd_h(dt, date_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, '%H', tzoffset)\nDATETIMES = [datetime(2012, 1, 6, 9, 37)]\n@pytest.mark.parametrize('dt', tuple(DATETIMES))",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "DATETIMES",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "DATETIMES = [datetime(2012, 1, 6, 9, 37)]\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('time_fmt', ('%H%M', '%H:%M'))\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)\ndef test_ymd_hm(dt, date_fmt, time_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\nDATETIMES = [datetime(2003, 9, 2, 22, 14, 2),\n             datetime(2003, 8, 8, 14, 9, 14),\n             datetime(2003, 4, 7, 6, 14, 59)]",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "DATETIMES",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "DATETIMES = [datetime(2003, 9, 2, 22, 14, 2),\n             datetime(2003, 8, 8, 14, 9, 14),\n             datetime(2003, 4, 7, 6, 14, 59)]\nHMS_FMTS = ('%H%M%S', '%H:%M:%S')\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('time_fmt', HMS_FMTS)\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)\ndef test_ymd_hms(dt, date_fmt, time_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "HMS_FMTS",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "HMS_FMTS = ('%H%M%S', '%H:%M:%S')\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('time_fmt', HMS_FMTS)\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)\ndef test_ymd_hms(dt, date_fmt, time_fmt, tzoffset):\n    _isoparse_date_and_time(dt, date_fmt, time_fmt, tzoffset)\nDATETIMES = [datetime(2017, 11, 27, 6, 14, 30, 123456)]\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "DATETIMES",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "DATETIMES = [datetime(2017, 11, 27, 6, 14, 30, 123456)]\n@pytest.mark.parametrize('dt', tuple(DATETIMES))\n@pytest.mark.parametrize('date_fmt', YMD_FMTS)\n@pytest.mark.parametrize('time_fmt', (x + sep + '%f' for x in HMS_FMTS\n                                      for sep in '.,'))\n@pytest.mark.parametrize('tzoffset', TZOFFSETS)\n@pytest.mark.parametrize('precision', list(range(3, 7)))\ndef test_ymd_hms_micro(dt, date_fmt, time_fmt, tzoffset, precision):\n    # Truncate the microseconds to the desired precision for the representation\n    dt = dt.replace(microsecond=int(round(dt.microsecond, precision-6)))",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "TIME_ARGS",
        "kind": 5,
        "importPath": "dateutil.test.test_isoparser",
        "description": "dateutil.test.test_isoparser",
        "peekOfCode": "TIME_ARGS = ('time_args',\n    ((None, time(0), None), ) + tuple(('%H:%M:%S.%f', _t, _tz)\n        for _t, _tz in it.product([time(0), time(9, 30), time(14, 47)],\n                                  TZOFFSETS)))\n@pytest.mark.parametrize('isocal,dt_expected',[\n    ((2017, 10), datetime(2017, 3, 6)),\n    ((2020, 1), datetime(2019, 12, 30)),    # ISO year != Cal year\n    ((2004, 53), datetime(2004, 12, 27)),   # Only half the week is in 2014\n])\ndef test_isoweek(isocal, dt_expected):",
        "detail": "dateutil.test.test_isoparser",
        "documentation": {}
    },
    {
        "label": "TestFormat",
        "kind": 6,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "class TestFormat(object):\n    def test_ybd(self):\n        # If we have a 4-digit year, a non-numeric month (abbreviated or not),\n        # and a day (1 or 2 digits), then there is no ambiguity as to which\n        # token is a year/month/day.  This holds regardless of what order the\n        # terms are in and for each of the separators below.\n        seps = ['-', ' ', '/', '.']\n        year_tokens = ['%Y']\n        month_tokens = ['%b', '%B']\n        day_tokens = ['%d']",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "TestInputTypes",
        "kind": 6,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "class TestInputTypes(object):\n    def test_empty_string_invalid(self):\n        with pytest.raises(ParserError):\n            parse('')\n    def test_none_invalid(self):\n        with pytest.raises(TypeError):\n            parse(None)\n    def test_int_invalid(self):\n        with pytest.raises(TypeError):\n            parse(13)",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "TestTzinfoInputTypes",
        "kind": 6,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "class TestTzinfoInputTypes(object):\n    def assert_equal_same_tz(self, dt1, dt2):\n        assert dt1 == dt2\n        assert dt1.tzinfo is dt2.tzinfo\n    def test_tzinfo_dict_could_return_none(self):\n        dstr = \"2017-02-03 12:40 BRST\"\n        result = parse(dstr, tzinfos={\"BRST\": None})\n        expected = datetime(2017, 2, 3, 12, 40)\n        self.assert_equal_same_tz(result, expected)\n    def test_tzinfos_callable_could_return_none(self):",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "ParserTest",
        "kind": 6,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "class ParserTest(unittest.TestCase):\n    @classmethod\n    def setup_class(cls):\n        cls.tzinfos = {\"BRST\": -10800}\n        cls.brsttz = tzoffset(\"BRST\", -10800)\n        cls.default = datetime(2003, 9, 25)\n        # Parser should be able to handle bytestring and unicode\n        cls.uni_str = '2014-05-01 08:00:00'\n        cls.str_str = cls.uni_str.encode()\n    def testParserParseStr(self):",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "TestOutOfBounds",
        "kind": 6,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "class TestOutOfBounds(object):\n    def test_no_year_zero(self):\n        with pytest.raises(ParserError):\n            parse(\"0000 Jun 20\")\n    def test_out_of_bound_day(self):\n        with pytest.raises(ParserError):\n            parse(\"Feb 30, 2007\")\n    def test_illegal_month_error(self):\n        with pytest.raises(ParserError):\n            parse(\"0-100\")",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "TestParseUnimplementedCases",
        "kind": 6,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "class TestParseUnimplementedCases(object):\n    @pytest.mark.xfail\n    def test_somewhat_ambiguous_string(self):\n        # Ref: github issue #487\n        # The parser is choosing the wrong part for hour\n        # causing datetime to raise an exception.\n        dtstr = '1237 PM BRST Mon Oct 30 2017'\n        res = parse(dtstr, tzinfo=self.tzinfos)\n        assert res == datetime(2017, 10, 30, 12, 37, tzinfo=self.tzinfos)\n    @pytest.mark.xfail",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "TestTZVar",
        "kind": 6,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "class TestTZVar(object):\n    def test_parse_unambiguous_nonexistent_local(self):\n        # When dates are specified \"EST\" even when they should be \"EDT\" in the\n        # local time zone, we should still assign the local time zone\n        with TZEnvContext('EST+5EDT,M3.2.0/2,M11.1.0/2'):\n            dt_exp = datetime(2011, 8, 1, 12, 30, tzinfo=tz.tzlocal())\n            dt = parse('2011-08-01T12:30 EST')\n            assert dt.tzname() == 'EDT'\n            assert dt == dt_exp\n    def test_tzlocal_in_gmt(self):",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "fuzzy",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def fuzzy(request):\n    \"\"\"Fixture to pass fuzzy=True or fuzzy=False to parse\"\"\"\n    return request.param\n# Parser test cases using no keyword arguments. Format: (parsable_text, expected_datetime, assertion_message)\nPARSER_TEST_CASES = [\n    (\"Thu Sep 25 10:36:28 2003\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Thu Sep 25 2003\", datetime(2003, 9, 25), \"date command format strip\"),\n    (\"2003-09-25T10:49:41\", datetime(2003, 9, 25, 10, 49, 41), \"iso format strip\"),\n    (\"2003-09-25T10:49\", datetime(2003, 9, 25, 10, 49), \"iso format strip\"),\n    (\"2003-09-25T10\", datetime(2003, 9, 25, 10), \"iso format strip\"),",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parser",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parser(parsable_text, expected_datetime, assertion_message):\n    assert parse(parsable_text) == expected_datetime, assertion_message\n# Parser test cases using datetime(2003, 9, 25) as a default.\n# Format: (parsable_text, expected_datetime, assertion_message)\nPARSER_DEFAULT_TEST_CASES = [\n    (\"Thu Sep 25 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Thu Sep 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Thu 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Sep 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parser_default",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parser_default(parsable_text, expected_datetime, assertion_message):\n    assert parse(parsable_text, default=datetime(2003, 9, 25)) == expected_datetime, assertion_message\n@pytest.mark.parametrize('sep', ['-', '.', '/', ' '])\ndef test_parse_dayfirst(sep):\n    expected = datetime(2003, 9, 10)\n    fmt = sep.join(['%d', '%m', '%Y'])\n    dstr = expected.strftime(fmt)\n    result = parse(dstr, dayfirst=True)\n    assert result == expected\n@pytest.mark.parametrize('sep', ['-', '.', '/', ' '])",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_dayfirst",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parse_dayfirst(sep):\n    expected = datetime(2003, 9, 10)\n    fmt = sep.join(['%d', '%m', '%Y'])\n    dstr = expected.strftime(fmt)\n    result = parse(dstr, dayfirst=True)\n    assert result == expected\n@pytest.mark.parametrize('sep', ['-', '.', '/', ' '])\ndef test_parse_yearfirst(sep):\n    expected = datetime(2010, 9, 3)\n    fmt = sep.join(['%Y', '%m', '%d'])",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_yearfirst",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parse_yearfirst(sep):\n    expected = datetime(2010, 9, 3)\n    fmt = sep.join(['%Y', '%m', '%d'])\n    dstr = expected.strftime(fmt)\n    result = parse(dstr, yearfirst=True)\n    assert result == expected\n@pytest.mark.parametrize('dstr,expected', [\n    (\"Thu Sep 25 10:36:28 BRST 2003\", datetime(2003, 9, 25, 10, 36, 28)),\n    (\"1996.07.10 AD at 15:08:56 PDT\", datetime(1996, 7, 10, 15, 8, 56)),\n    (\"Tuesday, April 12, 1952 AD 3:30:42pm PST\",",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_ignoretz",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parse_ignoretz(dstr, expected):\n    result = parse(dstr, ignoretz=True)\n    assert result == expected\n_brsttz = tzoffset(\"BRST\", -10800)\n@pytest.mark.parametrize('dstr,expected', [\n    (\"20030925T104941-0300\",\n     datetime(2003, 9, 25, 10, 49, 41, tzinfo=_brsttz)),\n    (\"Thu, 25 Sep 2003 10:49:41 -0300\",\n     datetime(2003, 9, 25, 10, 49, 41, tzinfo=_brsttz)),\n    (\"2003-09-25T10:49:41.5-03:00\",",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_with_tzoffset",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parse_with_tzoffset(dstr, expected):\n    # In these cases, we are _not_ passing a tzinfos arg\n    result = parse(dstr)\n    assert result == expected\nclass TestFormat(object):\n    def test_ybd(self):\n        # If we have a 4-digit year, a non-numeric month (abbreviated or not),\n        # and a day (1 or 2 digits), then there is no ambiguity as to which\n        # token is a year/month/day.  This holds regardless of what order the\n        # terms are in and for each of the separators below.",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parse_tzinfos_fold",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parse_tzinfos_fold():\n    NYC = tz.gettz('America/New_York')\n    tzinfos = {'EST': NYC, 'EDT': NYC}\n    dt_exp = tz.enfold(datetime(2011, 11, 6, 1, 30, tzinfo=NYC), fold=1)\n    dt = parse('2011-11-06T01:30 EST', tzinfos=tzinfos)\n    assert dt == dt_exp\n    assert dt.tzinfo is dt_exp.tzinfo\n    assert getattr(dt, 'fold') == getattr(dt_exp, 'fold')\n    assert dt.astimezone(tz.UTC) == dt_exp.astimezone(tz.UTC)\n@pytest.mark.parametrize('dtstr,dt', [",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_rounding_floatlike_strings",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_rounding_floatlike_strings(dtstr, dt):\n    assert parse(dtstr, default=datetime(2003, 9, 25)) == dt\n@pytest.mark.parametrize('value', ['1: test', 'Nan'])\ndef test_decimal_error(value):\n    # GH 632, GH 662 - decimal.Decimal raises some non-ParserError exception\n    # when constructed with an invalid value\n    with pytest.raises(ParserError):\n        parse(value)\ndef test_parsererror_repr():\n    # GH 991 — the __repr__ was not properly indented and so was never defined.",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_decimal_error",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_decimal_error(value):\n    # GH 632, GH 662 - decimal.Decimal raises some non-ParserError exception\n    # when constructed with an invalid value\n    with pytest.raises(ParserError):\n        parse(value)\ndef test_parsererror_repr():\n    # GH 991 — the __repr__ was not properly indented and so was never defined.\n    # This tests the current behavior of the ParserError __repr__, but the\n    # precise format is not guaranteed to be stable and may change even in\n    # minor versions. This test exists to avoid regressions.",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "test_parsererror_repr",
        "kind": 2,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "def test_parsererror_repr():\n    # GH 991 — the __repr__ was not properly indented and so was never defined.\n    # This tests the current behavior of the ParserError __repr__, but the\n    # precise format is not guaranteed to be stable and may change even in\n    # minor versions. This test exists to avoid regressions.\n    s = repr(ParserError(\"Problem with string: %s\", \"2019-01-01\"))\n    assert s == \"ParserError('Problem with string: %s', '2019-01-01')\"",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "IS_WIN",
        "kind": 5,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "IS_WIN = sys.platform.startswith('win')\nPLATFORM_HAS_DASH_D = False\ntry:\n    if datetime.now().strftime('%-d'):\n        PLATFORM_HAS_DASH_D = True\nexcept ValueError:\n    pass\n@pytest.fixture(params=[True, False])\ndef fuzzy(request):\n    \"\"\"Fixture to pass fuzzy=True or fuzzy=False to parse\"\"\"",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "PLATFORM_HAS_DASH_D",
        "kind": 5,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "PLATFORM_HAS_DASH_D = False\ntry:\n    if datetime.now().strftime('%-d'):\n        PLATFORM_HAS_DASH_D = True\nexcept ValueError:\n    pass\n@pytest.fixture(params=[True, False])\ndef fuzzy(request):\n    \"\"\"Fixture to pass fuzzy=True or fuzzy=False to parse\"\"\"\n    return request.param",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "PARSER_TEST_CASES",
        "kind": 5,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "PARSER_TEST_CASES = [\n    (\"Thu Sep 25 10:36:28 2003\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Thu Sep 25 2003\", datetime(2003, 9, 25), \"date command format strip\"),\n    (\"2003-09-25T10:49:41\", datetime(2003, 9, 25, 10, 49, 41), \"iso format strip\"),\n    (\"2003-09-25T10:49\", datetime(2003, 9, 25, 10, 49), \"iso format strip\"),\n    (\"2003-09-25T10\", datetime(2003, 9, 25, 10), \"iso format strip\"),\n    (\"2003-09-25\", datetime(2003, 9, 25), \"iso format strip\"),\n    (\"20030925T104941\", datetime(2003, 9, 25, 10, 49, 41), \"iso stripped format strip\"),\n    (\"20030925T1049\", datetime(2003, 9, 25, 10, 49, 0), \"iso stripped format strip\"),\n    (\"20030925T10\", datetime(2003, 9, 25, 10), \"iso stripped format strip\"),",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "PARSER_DEFAULT_TEST_CASES",
        "kind": 5,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "PARSER_DEFAULT_TEST_CASES = [\n    (\"Thu Sep 25 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Thu Sep 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Thu 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"Sep 10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"10:36:28\", datetime(2003, 9, 25, 10, 36, 28), \"date command format strip\"),\n    (\"10:36\", datetime(2003, 9, 25, 10, 36), \"date command format strip\"),\n    (\"Sep 2003\", datetime(2003, 9, 25), \"date command format strip\"),\n    (\"Sep\", datetime(2003, 9, 25), \"date command format strip\"),\n    (\"2003\", datetime(2003, 9, 25), \"date command format strip\"),",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "_brsttz",
        "kind": 5,
        "importPath": "dateutil.test.test_parser",
        "description": "dateutil.test.test_parser",
        "peekOfCode": "_brsttz = tzoffset(\"BRST\", -10800)\n@pytest.mark.parametrize('dstr,expected', [\n    (\"20030925T104941-0300\",\n     datetime(2003, 9, 25, 10, 49, 41, tzinfo=_brsttz)),\n    (\"Thu, 25 Sep 2003 10:49:41 -0300\",\n     datetime(2003, 9, 25, 10, 49, 41, tzinfo=_brsttz)),\n    (\"2003-09-25T10:49:41.5-03:00\",\n     datetime(2003, 9, 25, 10, 49, 41, 500000, tzinfo=_brsttz)),\n    (\"2003-09-25T10:49:41-03:00\",\n     datetime(2003, 9, 25, 10, 49, 41, tzinfo=_brsttz)),",
        "detail": "dateutil.test.test_parser",
        "documentation": {}
    },
    {
        "label": "RelativeDeltaTest",
        "kind": 6,
        "importPath": "dateutil.test.test_relativedelta",
        "description": "dateutil.test.test_relativedelta",
        "peekOfCode": "class RelativeDeltaTest(unittest.TestCase):\n    now = datetime(2003, 9, 17, 20, 54, 47, 282310)\n    today = date(2003, 9, 17)\n    def testInheritance(self):\n        # Ensure that relativedelta is inheritance-friendly.\n        class rdChildClass(relativedelta):\n            pass\n        ccRD = rdChildClass(years=1, months=1, days=1, leapdays=1, weeks=1,\n                            hours=1, minutes=1, seconds=1, microseconds=1)\n        rd = relativedelta(years=1, months=1, days=1, leapdays=1, weeks=1,",
        "detail": "dateutil.test.test_relativedelta",
        "documentation": {}
    },
    {
        "label": "RelativeDeltaWeeksPropertyGetterTest",
        "kind": 6,
        "importPath": "dateutil.test.test_relativedelta",
        "description": "dateutil.test.test_relativedelta",
        "peekOfCode": "class RelativeDeltaWeeksPropertyGetterTest(unittest.TestCase):\n    \"\"\"Test the weeks property getter\"\"\"\n    def test_one_day(self):\n        rd = relativedelta(days=1)\n        self.assertEqual(rd.days, 1)\n        self.assertEqual(rd.weeks, 0)\n    def test_minus_one_day(self):\n        rd = relativedelta(days=-1)\n        self.assertEqual(rd.days, -1)\n        self.assertEqual(rd.weeks, 0)",
        "detail": "dateutil.test.test_relativedelta",
        "documentation": {}
    },
    {
        "label": "RelativeDeltaWeeksPropertySetterTest",
        "kind": 6,
        "importPath": "dateutil.test.test_relativedelta",
        "description": "dateutil.test.test_relativedelta",
        "peekOfCode": "class RelativeDeltaWeeksPropertySetterTest(unittest.TestCase):\n    \"\"\"Test the weeks setter which makes a \"smart\" update of the days attribute\"\"\"\n    def test_one_day_set_one_week(self):\n        rd = relativedelta(days=1)\n        rd.weeks = 1  # add 7 days\n        self.assertEqual(rd.days, 8)\n        self.assertEqual(rd.weeks, 1)\n    def test_minus_one_day_set_one_week(self):\n        rd = relativedelta(days=-1)\n        rd.weeks = 1  # add 7 days",
        "detail": "dateutil.test.test_relativedelta",
        "documentation": {}
    },
    {
        "label": "RRuleTest",
        "kind": 6,
        "importPath": "dateutil.test.test_rrule",
        "description": "dateutil.test.test_rrule",
        "peekOfCode": "class RRuleTest(unittest.TestCase):\n    def _rrulestr_reverse_test(self, rule):\n        \"\"\"\n        Call with an `rrule` and it will test that `str(rrule)` generates a\n        string which generates the same `rrule` as the input when passed to\n        `rrulestr()`\n        \"\"\"\n        rr_str = str(rule)\n        rrulestr_rrule = rrulestr(rr_str)\n        self.assertEqual(list(rule), list(rrulestr_rrule))",
        "detail": "dateutil.test.test_rrule",
        "documentation": {}
    },
    {
        "label": "RRuleSetTest",
        "kind": 6,
        "importPath": "dateutil.test.test_rrule",
        "description": "dateutil.test.test_rrule",
        "peekOfCode": "class RRuleSetTest(unittest.TestCase):\n    def testSet(self):\n        rrset = rruleset()\n        rrset.rrule(rrule(YEARLY, count=2, byweekday=TU,\n                          dtstart=datetime(1997, 9, 2, 9, 0)))\n        rrset.rrule(rrule(YEARLY, count=1, byweekday=TH,\n                          dtstart=datetime(1997, 9, 2, 9, 0)))\n        self.assertEqual(list(rrset),\n                         [datetime(1997, 9, 2, 9, 0),\n                          datetime(1997, 9, 4, 9, 0),",
        "detail": "dateutil.test.test_rrule",
        "documentation": {}
    },
    {
        "label": "WeekdayTest",
        "kind": 6,
        "importPath": "dateutil.test.test_rrule",
        "description": "dateutil.test.test_rrule",
        "peekOfCode": "class WeekdayTest(unittest.TestCase):\n    def testInvalidNthWeekday(self):\n        with self.assertRaises(ValueError):\n            FR(0)\n    def testWeekdayCallable(self):\n        # Calling a weekday instance generates a new weekday instance with the\n        # value of n changed.\n        from dateutil.rrule import weekday\n        self.assertEqual(MO(1), weekday(0, 1))\n        # Calling a weekday instance with the identical n returns the original",
        "detail": "dateutil.test.test_rrule",
        "documentation": {}
    },
    {
        "label": "test_generated_aware_dtstart",
        "kind": 2,
        "importPath": "dateutil.test.test_rrule",
        "description": "dateutil.test.test_rrule",
        "peekOfCode": "def test_generated_aware_dtstart():\n    dtstart_exp = datetime(2018, 3, 6, 5, 36, tzinfo=tz.UTC)\n    UNTIL = datetime(2018, 3, 6, 8, 0, tzinfo=tz.UTC)\n    rule_without_dtstart = rrule(freq=HOURLY, until=UNTIL)\n    rule_with_dtstart = rrule(freq=HOURLY, dtstart=dtstart_exp, until=UNTIL)\n    assert list(rule_without_dtstart) == list(rule_with_dtstart)\n@pytest.mark.rrule\n@pytest.mark.rrulestr\n@pytest.mark.xfail(reason=\"rrulestr loses time zone, gh issue #637\")\n@freeze_time(datetime(2018, 3, 6, 5, 36, tzinfo=tz.UTC))",
        "detail": "dateutil.test.test_rrule",
        "documentation": {}
    },
    {
        "label": "test_generated_aware_dtstart_rrulestr",
        "kind": 2,
        "importPath": "dateutil.test.test_rrule",
        "description": "dateutil.test.test_rrule",
        "peekOfCode": "def test_generated_aware_dtstart_rrulestr():\n    rrule_without_dtstart = rrule(freq=HOURLY,\n                                  until=datetime(2018, 3, 6, 8, 0,\n                                                 tzinfo=tz.UTC))\n    rrule_r = rrulestr(str(rrule_without_dtstart))\n    assert list(rrule_r) == list(rrule_without_dtstart)\n@pytest.mark.rruleset\nclass RRuleSetTest(unittest.TestCase):\n    def testSet(self):\n        rrset = rruleset()",
        "detail": "dateutil.test.test_rrule",
        "documentation": {}
    },
    {
        "label": "context_passthrough",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class context_passthrough(object):\n    def __init__(*args, **kwargs):\n        pass\n    def __enter__(*args, **kwargs):\n        pass\n    def __exit__(*args, **kwargs):\n        pass\nclass TzFoldMixin(object):\n    \"\"\" Mix-in class for testing ambiguous times \"\"\"\n    def gettz(self, tzname):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzFoldMixin",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzFoldMixin(object):\n    \"\"\" Mix-in class for testing ambiguous times \"\"\"\n    def gettz(self, tzname):\n        raise NotImplementedError\n    def _get_tzname(self, tzname):\n        return tzname\n    def _gettz_context(self, tzname):\n        return context_passthrough()\n    def testFoldPositiveUTCOffset(self):\n        # Test that we can resolve ambiguous times",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzWinFoldMixin",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzWinFoldMixin(object):\n    def get_args(self, tzname):\n        return (tzname, )\n    class context(object):\n        def __init__(*args, **kwargs):\n            pass\n        def __enter__(*args, **kwargs):\n            pass\n        def __exit__(*args, **kwargs):\n            pass",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzUTCTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzUTCTest(unittest.TestCase):\n    def testSingleton(self):\n        UTC_0 = tz.tzutc()\n        UTC_1 = tz.tzutc()\n        self.assertIs(UTC_0, UTC_1)\n    def testOffset(self):\n        ct = datetime(2009, 4, 1, 12, 11, 13, tzinfo=tz.tzutc())\n        self.assertEqual(ct.utcoffset(), timedelta(seconds=0))\n    def testDst(self):\n        ct = datetime(2009, 4, 1, 12, 11, 13, tzinfo=tz.tzutc())",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzOffsetTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzOffsetTest(unittest.TestCase):\n    def testTimedeltaOffset(self):\n        est = tz.tzoffset('EST', timedelta(hours=-5))\n        est_s = tz.tzoffset('EST', -18000)\n        self.assertEqual(est, est_s)\n    def testTzNameNone(self):\n        gmt5 = tz.tzoffset(None, -18000)       # -5:00\n        self.assertIs(datetime(2003, 10, 26, 0, 0, tzinfo=gmt5).tzname(),\n                      None)\n    def testTimeOnlyOffset(self):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzLocalTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzLocalTest(unittest.TestCase):\n    def testEquality(self):\n        tz1 = tz.tzlocal()\n        tz2 = tz.tzlocal()\n        # Explicitly calling == and != here to ensure the operators work\n        self.assertTrue(tz1 == tz2)\n        self.assertFalse(tz1 != tz2)\n    def testInequalityFixedOffset(self):\n        tzl = tz.tzlocal()\n        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzLocalNixTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzLocalNixTest(unittest.TestCase, TzFoldMixin):\n    # This is a set of tests for `tzlocal()` on *nix systems\n    # POSIX string indicating change to summer time on the 2nd Sunday in March\n    # at 2AM, and ending the 1st Sunday in November at 2AM. (valid >= 2007)\n    TZ_EST = 'EST+5EDT,M3.2.0/2,M11.1.0/2'\n    # POSIX string for AEST/AEDT (valid >= 2008)\n    TZ_AEST = 'AEST-10AEDT,M10.1.0/2,M4.1.0/3'\n    # POSIX string for BST/GMT\n    TZ_LON = 'GMT0BST,M3.5.0,M10.5.0'\n    # POSIX string for UTC",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "GettzTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class GettzTest(unittest.TestCase, TzFoldMixin):\n    gettz = staticmethod(tz.gettz)\n    def testGettz(self):\n        # bug 892569\n        str(self.gettz('UTC'))\n    def testGetTzEquality(self):\n        self.assertEqual(self.gettz('UTC'), self.gettz('UTC'))\n    def testTimeOnlyGettz(self):\n        # gettz returns None\n        tz_get = self.gettz('Europe/Minsk')",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "ZoneInfoGettzTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class ZoneInfoGettzTest(GettzTest):\n    def gettz(self, name):\n        zoneinfo_file = zoneinfo.get_zonefile_instance()\n        return zoneinfo_file.get(name)\n    def testZoneInfoFileStart1(self):\n        tz = self.gettz(\"EST5EDT\")\n        self.assertEqual(datetime(2003, 4, 6, 1, 59, tzinfo=tz).tzname(), \"EST\",\n                         MISSING_TARBALL)\n        self.assertEqual(datetime(2003, 4, 6, 2, 00, tzinfo=tz).tzname(), \"EDT\")\n    def testZoneInfoFileEnd1(self):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TZRangeTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TZRangeTest(unittest.TestCase, TzFoldMixin):\n    TZ_EST = tz.tzrange('EST', timedelta(hours=-5),\n                        'EDT', timedelta(hours=-4),\n                        start=relativedelta(month=3, day=1, hour=2,\n                                            weekday=SU(+2)),\n                        end=relativedelta(month=11, day=1, hour=1,\n                                          weekday=SU(+1)))\n    TZ_AEST = tz.tzrange('AEST', timedelta(hours=10),\n                         'AEDT', timedelta(hours=11),\n                         start=relativedelta(month=10, day=1, hour=2,",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TZStrTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TZStrTest(unittest.TestCase, TzFoldMixin):\n    # POSIX string indicating change to summer time on the 2nd Sunday in March\n    # at 2AM, and ending the 1st Sunday in November at 2AM. (valid >= 2007)\n    TZ_EST = 'EST+5EDT,M3.2.0/2,M11.1.0/2'\n    # POSIX string for AEST/AEDT (valid >= 2008)\n    TZ_AEST = 'AEST-10AEDT,M10.1.0/2,M4.1.0/3'\n    # POSIX string for GMT/BST\n    TZ_LON = 'GMT0BST,M3.5.0,M10.5.0'\n    def gettz(self, tzname):\n        # Actual time zone changes are handled by the _gettz_context function",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TZICalTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TZICalTest(unittest.TestCase, TzFoldMixin):\n    def _gettz_str_tuple(self, tzname):\n        TZ_EST = (\n            'BEGIN:VTIMEZONE',\n            'TZID:US-Eastern',\n            'BEGIN:STANDARD',\n            'DTSTART:19971029T020000',\n            'RRULE:FREQ=YEARLY;BYDAY=+1SU;BYMONTH=11',\n            'TZOFFSETFROM:-0400',\n            'TZOFFSETTO:-0500',",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TZTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TZTest(unittest.TestCase):\n    def testFileStart1(self):\n        tzc = tz.tzfile(BytesIO(base64.b64decode(TZFILE_EST5EDT)))\n        self.assertEqual(datetime(2003, 4, 6, 1, 59, tzinfo=tzc).tzname(), \"EST\")\n        self.assertEqual(datetime(2003, 4, 6, 2, 00, tzinfo=tzc).tzname(), \"EDT\")\n    def testFileEnd1(self):\n        tzc = tz.tzfile(BytesIO(base64.b64decode(TZFILE_EST5EDT)))\n        self.assertEqual(datetime(2003, 10, 26, 0, 59, tzinfo=tzc).tzname(),\n                         \"EDT\")\n        end_est = tz.enfold(datetime(2003, 10, 26, 1, 00, tzinfo=tzc))",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzWinTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzWinTest(unittest.TestCase, TzWinFoldMixin):\n    def setUp(self):\n        self.tzclass = tzwin.tzwin\n    def testTzResLoadName(self):\n        # This may not work right on non-US locales.\n        tzr = tzwin.tzres()\n        self.assertEqual(tzr.load_name(112), \"Eastern Standard Time\")\n    def testTzResNameFromString(self):\n        tzr = tzwin.tzres()\n        self.assertEqual(tzr.name_from_string('@tzres.dll,-221'),",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzWinLocalTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzWinLocalTest(unittest.TestCase, TzWinFoldMixin):\n    def setUp(self):\n        self.tzclass = tzwin.tzwinlocal\n        self.context = TZWinContext\n    def get_args(self, tzname):\n        return ()\n    def testLocal(self):\n        # Not sure how to pin a local time zone, so for now we're just going\n        # to run this and make sure it doesn't raise an error\n        # See GitHub Issue #135: https://github.com/dateutil/dateutil/issues/135",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzPickleTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzPickleTest(PicklableMixin, unittest.TestCase):\n    _asfile = False\n    def setUp(self):\n        self.assertPicklable = partial(self.assertPicklable,\n                                       asfile=self._asfile)\n    def testPickleTzUTC(self):\n        self.assertPicklable(tz.tzutc(), singleton=True)\n    def testPickleTzOffsetZero(self):\n        self.assertPicklable(tz.tzoffset('UTC', 0), singleton=True)\n    def testPickleTzOffsetPos(self):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TzPickleFileTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TzPickleFileTest(TzPickleTest):\n    \"\"\" Run all the TzPickleTest tests, using a temporary file \"\"\"\n    _asfile = True\nclass DatetimeAmbiguousTest(unittest.TestCase):\n    \"\"\" Test the datetime_exists / datetime_ambiguous functions \"\"\"\n    def testNoTzSpecified(self):\n        with self.assertRaises(ValueError):\n            tz.datetime_ambiguous(datetime(2016, 4, 1, 2, 9))\n    def _get_no_support_tzinfo_class(self, dt_start, dt_end, dst_only=False):\n        # Generates a class of tzinfo with no support for is_ambiguous",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "DatetimeAmbiguousTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class DatetimeAmbiguousTest(unittest.TestCase):\n    \"\"\" Test the datetime_exists / datetime_ambiguous functions \"\"\"\n    def testNoTzSpecified(self):\n        with self.assertRaises(ValueError):\n            tz.datetime_ambiguous(datetime(2016, 4, 1, 2, 9))\n    def _get_no_support_tzinfo_class(self, dt_start, dt_end, dst_only=False):\n        # Generates a class of tzinfo with no support for is_ambiguous\n        # where dates between dt_start and dt_end are ambiguous.\n        class FoldingTzInfo(tzinfo):\n            def utcoffset(self, dt):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "DatetimeExistsTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class DatetimeExistsTest(unittest.TestCase):\n    def testNoTzSpecified(self):\n        with self.assertRaises(ValueError):\n            tz.datetime_exists(datetime(2016, 4, 1, 2, 9))\n    def testInGapNaive(self):\n        tzi = tz.gettz('Australia/Sydney')\n        dt = datetime(2012, 10, 7, 2, 30)\n        self.assertFalse(tz.datetime_exists(dt, tz=tzi))\n    def testInGapAware(self):\n        tzi = tz.gettz('Australia/Sydney')",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TestEnfold",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class TestEnfold:\n    def test_enter_fold_default(self):\n        dt = tz.enfold(datetime(2020, 1, 19, 3, 32))\n        assert dt.fold == 1\n    def test_enter_fold(self):\n        dt = tz.enfold(datetime(2020, 1, 19, 3, 32), fold=1)\n        assert dt.fold == 1\n    def test_exit_fold(self):\n        dt = tz.enfold(datetime(2020, 1, 19, 3, 32), fold=0)\n        # Before Python 3.6, dt.fold won't exist if fold is 0.",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "ImaginaryDateTest",
        "kind": 6,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "class ImaginaryDateTest(unittest.TestCase):\n    def testCanberraForward(self):\n        tzi = tz.gettz('Australia/Canberra')\n        dt = datetime(2018, 10, 7, 2, 30, tzinfo=tzi)\n        dt_act = tz.resolve_imaginary(dt)\n        dt_exp = datetime(2018, 10, 7, 3, 30, tzinfo=tzi)\n        self.assertEqual(dt_act, dt_exp)\n    def testLondonForward(self):\n        tzi = tz.gettz('Europe/London')\n        dt = datetime(2018, 3, 25, 1, 30, tzinfo=tzi)",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "get_timezone_tuple",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def get_timezone_tuple(dt):\n    \"\"\"Retrieve a (tzname, utcoffset, dst) tuple for a given DST\"\"\"\n    return dt.tzname(), dt.utcoffset(), dt.dst()\n###\n# Mix-ins\nclass context_passthrough(object):\n    def __init__(*args, **kwargs):\n        pass\n    def __enter__(*args, **kwargs):\n        pass",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzoffset_weakref",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzoffset_weakref():\n    UTC1 = tz.tzoffset('UTC', 0)\n    UTC_ref = weakref.ref(tz.tzoffset('UTC', 0))\n    UTC1 is UTC_ref()\n    del UTC1\n    gc.collect()\n    assert UTC_ref() is not None    # Should be in the strong cache\n    assert UTC_ref() is tz.tzoffset('UTC', 0)\n    # Fill the strong cache with other items\n    for offset in range(5,15):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzoffset_singleton",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzoffset_singleton(args):\n    tz1 = tz.tzoffset(*args)\n    tz2 = tz.tzoffset(*args)\n    assert tz1 is tz2\n@pytest.mark.tzoffset\n@pytest.mark.skipif(not SUPPORTS_SUB_MINUTE_OFFSETS,\n                    reason='Sub-minute offsets not supported')\ndef test_tzoffset_sub_minute():\n    delta = timedelta(hours=12, seconds=30)\n    test_datetime = datetime(2000, 1, 1, tzinfo=tz.tzoffset(None, delta))",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzoffset_sub_minute",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzoffset_sub_minute():\n    delta = timedelta(hours=12, seconds=30)\n    test_datetime = datetime(2000, 1, 1, tzinfo=tz.tzoffset(None, delta))\n    assert test_datetime.utcoffset() == delta\n@pytest.mark.tzoffset\n@pytest.mark.skipif(SUPPORTS_SUB_MINUTE_OFFSETS,\n                    reason='Sub-minute offsets supported')\ndef test_tzoffset_sub_minute_rounding():\n    delta = timedelta(hours=12, seconds=30)\n    test_date = datetime(2000, 1, 1, tzinfo=tz.tzoffset(None, delta))",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzoffset_sub_minute_rounding",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzoffset_sub_minute_rounding():\n    delta = timedelta(hours=12, seconds=30)\n    test_date = datetime(2000, 1, 1, tzinfo=tz.tzoffset(None, delta))\n    assert test_date.utcoffset() == timedelta(hours=12, minutes=1)\n@pytest.mark.tzlocal\nclass TzLocalTest(unittest.TestCase):\n    def testEquality(self):\n        tz1 = tz.tzlocal()\n        tz2 = tz.tzlocal()\n        # Explicitly calling == and != here to ensure the operators work",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzoffset_is",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzoffset_is(args, kwargs):\n    tz_ref = tz.tzoffset('EST', -18000)\n    assert tz.tzoffset(*args, **kwargs) is tz_ref\ndef test_tzoffset_is_not():\n    assert tz.tzoffset('EDT', -14400) is not tz.tzoffset('EST', -18000)\n@pytest.mark.tzlocal\n@unittest.skipIf(IS_WIN, \"requires Unix\")\nclass TzLocalNixTest(unittest.TestCase, TzFoldMixin):\n    # This is a set of tests for `tzlocal()` on *nix systems\n    # POSIX string indicating change to summer time on the 2nd Sunday in March",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzoffset_is_not",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzoffset_is_not():\n    assert tz.tzoffset('EDT', -14400) is not tz.tzoffset('EST', -18000)\n@pytest.mark.tzlocal\n@unittest.skipIf(IS_WIN, \"requires Unix\")\nclass TzLocalNixTest(unittest.TestCase, TzFoldMixin):\n    # This is a set of tests for `tzlocal()` on *nix systems\n    # POSIX string indicating change to summer time on the 2nd Sunday in March\n    # at 2AM, and ending the 1st Sunday in November at 2AM. (valid >= 2007)\n    TZ_EST = 'EST+5EDT,M3.2.0/2,M11.1.0/2'\n    # POSIX string for AEST/AEDT (valid >= 2008)",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "mark_tzlocal_nix",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def mark_tzlocal_nix(f):\n    marks = [\n        pytest.mark.tzlocal,\n        pytest.mark.skipif(IS_WIN, reason='requires Unix'),\n    ]\n    for mark in reversed(marks):\n        f = mark(f)\n    return f\n@mark_tzlocal_nix\n@pytest.mark.parametrize('tzvar', ['UTC', 'GMT0', 'UTC0'])",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzlocal_utc_equal",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzlocal_utc_equal(tzvar):\n    with TZEnvContext(tzvar):\n        assert tz.tzlocal() == tz.UTC\n@mark_tzlocal_nix\n@pytest.mark.parametrize('tzvar', [\n    'Europe/London', 'America/New_York',\n    'GMT0BST', 'EST5EDT'])\ndef test_tzlocal_utc_unequal(tzvar):\n    with TZEnvContext(tzvar):\n        assert tz.tzlocal() != tz.UTC",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzlocal_utc_unequal",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzlocal_utc_unequal(tzvar):\n    with TZEnvContext(tzvar):\n        assert tz.tzlocal() != tz.UTC\n@mark_tzlocal_nix\ndef test_tzlocal_local_time_trim_colon():\n    with TZEnvContext(':/etc/localtime'):\n        assert tz.gettz() is not None\n@mark_tzlocal_nix\n@pytest.mark.parametrize('tzvar, tzoff', [\n    ('EST5', tz.tzoffset('EST', -18000)),",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzlocal_local_time_trim_colon",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzlocal_local_time_trim_colon():\n    with TZEnvContext(':/etc/localtime'):\n        assert tz.gettz() is not None\n@mark_tzlocal_nix\n@pytest.mark.parametrize('tzvar, tzoff', [\n    ('EST5', tz.tzoffset('EST', -18000)),\n    ('GMT0', tz.tzoffset('GMT', 0)),\n    ('YAKT-9', tz.tzoffset('YAKT', timedelta(hours=9))),\n    ('JST-9', tz.tzoffset('JST', timedelta(hours=9))),\n])",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzlocal_offset_equal",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzlocal_offset_equal(tzvar, tzoff):\n    with TZEnvContext(tzvar):\n        # Including both to test both __eq__ and __ne__\n        assert tz.tzlocal() == tzoff\n        assert not (tz.tzlocal() != tzoff)\n@mark_tzlocal_nix\n@pytest.mark.parametrize('tzvar, tzoff', [\n    ('EST5EDT', tz.tzoffset('EST', -18000)),\n    ('GMT0BST', tz.tzoffset('GMT', 0)),\n    ('EST5', tz.tzoffset('EST', -14400)),",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzlocal_offset_unequal",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzlocal_offset_unequal(tzvar, tzoff):\n    with TZEnvContext(tzvar):\n        # Including both to test both __eq__ and __ne__\n        assert tz.tzlocal() != tzoff\n        assert not (tz.tzlocal() == tzoff)\n@pytest.mark.gettz\nclass GettzTest(unittest.TestCase, TzFoldMixin):\n    gettz = staticmethod(tz.gettz)\n    def testGettz(self):\n        # bug 892569",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_gettz_same_result_for_none_and_empty_string",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_gettz_same_result_for_none_and_empty_string():\n    local_from_none = tz.gettz()\n    local_from_empty_string = tz.gettz(\"\")\n    assert local_from_none is not None\n    assert local_from_empty_string is not None\n    assert local_from_none == local_from_empty_string\n@pytest.mark.gettz\n@pytest.mark.parametrize('badzone', [\n    'Fake.Region/Abcdefghijklmnop',  # Violates several tz project name rules\n])",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_gettz_badzone",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_gettz_badzone(badzone):\n    # Make sure passing a bad TZ string to gettz returns None (GH #800)\n    tzi = tz.gettz(badzone)\n    assert tzi is None\n@pytest.mark.gettz\ndef test_gettz_badzone_unicode():\n    # Make sure a unicode string can be passed to TZ (GH #802)\n    # When fixed, combine this with test_gettz_badzone\n    tzi = tz.gettz('🐼')\n    assert tzi is None",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_gettz_badzone_unicode",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_gettz_badzone_unicode():\n    # Make sure a unicode string can be passed to TZ (GH #802)\n    # When fixed, combine this with test_gettz_badzone\n    tzi = tz.gettz('🐼')\n    assert tzi is None\n@pytest.mark.gettz\n@pytest.mark.parametrize(\n    \"badzone,exc_reason\",\n    [\n        pytest.param(",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_gettz_zone_wrong_type",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_gettz_zone_wrong_type(badzone, exc_reason):\n    with pytest.raises(TypeError, match=exc_reason):\n        tz.gettz(badzone)\n@pytest.mark.gettz\n@pytest.mark.xfail(IS_WIN, reason='zoneinfo separately cached')\ndef test_gettz_cache_clear():\n    NYC1 = tz.gettz('America/New_York')\n    tz.gettz.cache_clear()\n    NYC2 = tz.gettz('America/New_York')\n    assert NYC1 is not NYC2",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_gettz_cache_clear",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_gettz_cache_clear():\n    NYC1 = tz.gettz('America/New_York')\n    tz.gettz.cache_clear()\n    NYC2 = tz.gettz('America/New_York')\n    assert NYC1 is not NYC2\n@pytest.mark.gettz\n@pytest.mark.xfail(IS_WIN, reason='zoneinfo separately cached')\ndef test_gettz_set_cache_size():\n    tz.gettz.cache_clear()\n    tz.gettz.set_cache_size(3)",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_gettz_set_cache_size",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_gettz_set_cache_size():\n    tz.gettz.cache_clear()\n    tz.gettz.set_cache_size(3)\n    MONACO_ref = weakref.ref(tz.gettz('Europe/Monaco'))\n    EASTER_ref = weakref.ref(tz.gettz('Pacific/Easter'))\n    CURRIE_ref = weakref.ref(tz.gettz('Australia/Currie'))\n    gc.collect()\n    assert MONACO_ref() is not None\n    assert EASTER_ref() is not None\n    assert CURRIE_ref() is not None",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_gettz_weakref",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_gettz_weakref():\n    tz.gettz.cache_clear()\n    tz.gettz.set_cache_size(2)\n    NYC1 = tz.gettz('America/New_York')\n    NYC_ref = weakref.ref(tz.gettz('America/New_York'))\n    assert NYC1 is NYC_ref()\n    del NYC1\n    gc.collect()\n    assert NYC_ref() is not None        # Should still be in the strong cache\n    assert tz.gettz('America/New_York') is NYC_ref()",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzstr_weakref",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzstr_weakref():\n    tz_t1 = tz.tzstr('EST5EDT')\n    tz_t2_ref = weakref.ref(tz.tzstr('EST5EDT'))\n    assert tz_t1 is tz_t2_ref()\n    del tz_t1\n    gc.collect()\n    assert tz_t2_ref() is not None\n    assert tz.tzstr('EST5EDT') is tz_t2_ref()\n    for offset in range(5,15):\n        tz.tzstr('GMT+{}'.format(offset))",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_valid_GNU_tzstr",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_valid_GNU_tzstr(tz_str, expected):\n    tzi = tz.tzstr(tz_str)\n    assert tzi == expected\n@pytest.mark.tzstr\n@pytest.mark.parametrize('tz_str, expected', [\n    ('EST5EDT,5,4,0,7200,11,3,0,7200',\n     tz.tzrange('EST', timedelta(hours=-5), 'EDT',\n        start=relativedelta(month=5, day=1, weekday=SU(+4), hours=+2),\n        end=relativedelta(month=11, day=1, weekday=SU(+3), hours=+1))),\n    ('EST5EDT,5,-4,0,7200,11,3,0,7200',",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_valid_dateutil_format",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_valid_dateutil_format(tz_str, expected):\n    # This tests the dateutil-specific format that is used widely in the tests\n    # and examples. It is unclear where this format originated from.\n    with pytest.warns(tz.DeprecatedTzFormatWarning):\n        tzi = tz.tzstr.instance(tz_str)\n    assert tzi == expected\n@pytest.mark.tzstr\n@pytest.mark.parametrize('tz_str', [\n    'hdfiughdfuig,dfughdfuigpu87ñ::',\n    ',dfughdfuigpu87ñ::',",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_invalid_GNU_tzstr",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_invalid_GNU_tzstr(tz_str):\n    with pytest.raises(ValueError):\n        tz.tzstr(tz_str)\n# Different representations of the same default rule set\nDEFAULT_TZSTR_RULES_EQUIV_2003 = [\n    'EST5EDT',\n    'EST5EDT4,M4.1.0/02:00:00,M10-5-0/02:00',\n    'EST5EDT4,95/02:00:00,298/02:00',\n    'EST5EDT4,J96/02:00:00,J299/02:00',\n    'EST5EDT4,J96/02:00:00,J299/02'",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzstr_default_start",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzstr_default_start(tz_str):\n    tzi = tz.tzstr(tz_str)\n    dt_std = datetime(2003, 4, 6, 1, 59, tzinfo=tzi)\n    dt_dst = datetime(2003, 4, 6, 2, 00, tzinfo=tzi)\n    assert get_timezone_tuple(dt_std) == EST_TUPLE\n    assert get_timezone_tuple(dt_dst) == EDT_TUPLE\n@pytest.mark.tzstr\n@pytest.mark.parametrize('tz_str', DEFAULT_TZSTR_RULES_EQUIV_2003)\ndef test_tzstr_default_end(tz_str):\n    tzi = tz.tzstr(tz_str)",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzstr_default_end",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzstr_default_end(tz_str):\n    tzi = tz.tzstr(tz_str)\n    dt_dst = datetime(2003, 10, 26, 0, 59, tzinfo=tzi)\n    dt_dst_ambig = datetime(2003, 10, 26, 1, 00, tzinfo=tzi)\n    dt_std_ambig = tz.enfold(dt_dst_ambig, fold=1)\n    dt_std = datetime(2003, 10, 26, 2, 00, tzinfo=tzi)\n    assert get_timezone_tuple(dt_dst) == EDT_TUPLE\n    assert get_timezone_tuple(dt_dst_ambig) == EDT_TUPLE\n    assert get_timezone_tuple(dt_std_ambig) == EST_TUPLE\n    assert get_timezone_tuple(dt_std) == EST_TUPLE",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzstr_default_cmp",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzstr_default_cmp(tzstr_1, tzstr_2):\n    tz1 = tz.tzstr(tzstr_1)\n    tz2 = tz.tzstr(tzstr_2)\n    assert tz1 == tz2\nclass TZICalTest(unittest.TestCase, TzFoldMixin):\n    def _gettz_str_tuple(self, tzname):\n        TZ_EST = (\n            'BEGIN:VTIMEZONE',\n            'TZID:US-Eastern',\n            'BEGIN:STANDARD',",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_tzfile_sub_minute_offset",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_tzfile_sub_minute_offset():\n    # If user running python 3.6 or newer, exact offset is used\n    tzc = tz.tzfile(BytesIO(base64.b64decode(EUROPE_HELSINKI)))\n    offset = timedelta(hours=1, minutes=39, seconds=52)\n    assert datetime(1900, 1, 1, 0, 0, tzinfo=tzc).utcoffset() == offset\n@pytest.mark.tzfile\n@pytest.mark.skipif(SUPPORTS_SUB_MINUTE_OFFSETS,\n                    reason='Sub-minute offsets supported.')\ndef test_sub_minute_rounding_tzfile():\n    # This timezone has an offset of 5992 seconds in 1900-01-01.",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_sub_minute_rounding_tzfile",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_sub_minute_rounding_tzfile():\n    # This timezone has an offset of 5992 seconds in 1900-01-01.\n    # For python version pre-3.6, this will be rounded\n    tzc = tz.tzfile(BytesIO(base64.b64decode(EUROPE_HELSINKI)))\n    offset = timedelta(hours=1, minutes=40)\n    assert datetime(1900, 1, 1, 0, 0, tzinfo=tzc).utcoffset() == offset\n@pytest.mark.tzfile\ndef test_samoa_transition():\n    # utcoffset() was erroneously returning +14:00 an hour early (GH #812)\n    APIA = tz.gettz('Pacific/Apia')",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_samoa_transition",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_samoa_transition():\n    # utcoffset() was erroneously returning +14:00 an hour early (GH #812)\n    APIA = tz.gettz('Pacific/Apia')\n    dt = datetime(2011, 12, 29, 23, 59, tzinfo=APIA)\n    assert dt.utcoffset() == timedelta(hours=-10)\n    # Make sure the transition actually works, too\n    dt_after = (dt.astimezone(tz.UTC) + timedelta(minutes=1)).astimezone(APIA)\n    assert dt_after == datetime(2011, 12, 31, tzinfo=APIA)\n    assert dt_after.utcoffset() == timedelta(hours=14)\n@unittest.skipUnless(IS_WIN, \"Requires Windows\")",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_resolve_imaginary_ambiguous",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_resolve_imaginary_ambiguous(dt):\n    assert tz.resolve_imaginary(dt) is dt\n    dt_f = tz.enfold(dt)\n    assert dt is not dt_f\n    assert tz.resolve_imaginary(dt_f) is dt_f\n@pytest.mark.tz_resolve_imaginary\n@pytest.mark.parametrize('dt', [\n    datetime(2017, 6, 2, 12, 30, tzinfo=tz.gettz('America/New_York')),\n    datetime(2018, 4, 2, 9, 30, tzinfo=tz.gettz('Europe/London')),\n    datetime(2017, 2, 2, 16, 30, tzinfo=tz.gettz('Australia/Sydney')),",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_resolve_imaginary_existing",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_resolve_imaginary_existing(dt):\n    assert tz.resolve_imaginary(dt) is dt\ndef __get_kiritimati_resolve_imaginary_test():\n    # In the 2018d release of the IANA database, the Kiritimati \"imaginary day\"\n    # data was corrected, so if the system zoneinfo is older than 2018d, the\n    # Kiritimati test will fail.\n    tzi = tz.gettz('Pacific/Kiritimati')\n    new_version = False\n    if not tz.datetime_exists(datetime(1995, 1, 1, 12, 30), tzi):\n        zif = zoneinfo.get_zonefile_instance()",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_resolve_imaginary",
        "kind": 2,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "def test_resolve_imaginary(tzi, dt, dt_exp):\n    dt = dt.replace(tzinfo=tzi)\n    dt_exp = dt_exp.replace(tzinfo=tzi)\n    dt_r = tz.resolve_imaginary(dt)\n    assert dt_r == dt_exp\n    assert dt_r.tzname() == dt_exp.tzname()\n    assert dt_r.utcoffset() == dt_exp.utcoffset()",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "IS_WIN",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "IS_WIN = sys.platform.startswith('win')\nimport pytest\n# dateutil imports\nfrom dateutil.relativedelta import relativedelta, SU, TH\nfrom dateutil.parser import parse\nfrom dateutil import tz as tz\nfrom dateutil import zoneinfo\ntry:\n    from dateutil import tzwin\nexcept ImportError as e:",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "MISSING_TARBALL",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "MISSING_TARBALL = (\"This test fails if you don't have the dateutil \"\n                   \"timezone file installed. Please read the README\")\nTZFILE_EST5EDT = b\"\"\"\nVFppZgAAAAAAAAAAAAAAAAAAAAAAAAAEAAAABAAAAAAAAADrAAAABAAAABCeph5wn7rrYKCGAHCh\nms1gomXicKOD6eCkaq5wpTWnYKZTyvCnFYlgqDOs8Kj+peCqE47wqt6H4KvzcPCsvmngrdNS8K6e\nS+CvszTwsH4t4LGcUXCyZ0pgs3wzcLRHLGC1XBVwticOYLc793C4BvBguRvZcLnm0mC7BPXwu8a0\nYLzk1/C9r9DgvsS58L+PsuDApJvwwW+U4MKEffDDT3bgxGRf8MUvWODGTXxwxw864MgtXnDI+Fdg\nyg1AcMrYOWDLiPBw0iP0cNJg++DTdeTw1EDd4NVVxvDWIL/g1zWo8NgAoeDZFYrw2eCD4Nr+p3Db\nwGXg3N6JcN2pgmDevmtw34lkYOCeTXDhaUZg4n4vcONJKGDkXhFw5Vcu4OZHLfDnNxDg6CcP8OkW\n8uDqBvHw6vbU4Ovm0/Ds1rbg7ca18O6/02Dvr9Jw8J+1YPGPtHDyf5dg82+WcPRfeWD1T3hw9j9b",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TZFILE_EST5EDT",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "TZFILE_EST5EDT = b\"\"\"\nVFppZgAAAAAAAAAAAAAAAAAAAAAAAAAEAAAABAAAAAAAAADrAAAABAAAABCeph5wn7rrYKCGAHCh\nms1gomXicKOD6eCkaq5wpTWnYKZTyvCnFYlgqDOs8Kj+peCqE47wqt6H4KvzcPCsvmngrdNS8K6e\nS+CvszTwsH4t4LGcUXCyZ0pgs3wzcLRHLGC1XBVwticOYLc793C4BvBguRvZcLnm0mC7BPXwu8a0\nYLzk1/C9r9DgvsS58L+PsuDApJvwwW+U4MKEffDDT3bgxGRf8MUvWODGTXxwxw864MgtXnDI+Fdg\nyg1AcMrYOWDLiPBw0iP0cNJg++DTdeTw1EDd4NVVxvDWIL/g1zWo8NgAoeDZFYrw2eCD4Nr+p3Db\nwGXg3N6JcN2pgmDevmtw34lkYOCeTXDhaUZg4n4vcONJKGDkXhFw5Vcu4OZHLfDnNxDg6CcP8OkW\n8uDqBvHw6vbU4Ovm0/Ds1rbg7ca18O6/02Dvr9Jw8J+1YPGPtHDyf5dg82+WcPRfeWD1T3hw9j9b\nYPcvWnD4KHfg+Q88cPoIWeD6+Fjw++g74PzYOvD9yB3g/rgc8P+n/+AAl/7wAYfh4AJ34PADcP5g\nBGD9cAVQ4GAGQN9wBzDCYAeNGXAJEKRgCa2U8ArwhmAL4IVwDNmi4A3AZ3AOuYTgD6mD8BCZZuAR",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "EUROPE_HELSINKI",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "EUROPE_HELSINKI = b\"\"\"\nVFppZgAAAAAAAAAAAAAAAAAAAAAAAAAFAAAABQAAAAAAAAB1AAAABQAAAA2kc28Yy85RYMy/hdAV\nI+uQFhPckBcDzZAX876QGOOvkBnToJAaw5GQG7y9EBysrhAdnJ8QHoyQEB98gRAgbHIQIVxjECJM\nVBAjPEUQJCw2ECUcJxAmDBgQJwVDkCf1NJAo5SWQKdUWkCrFB5ArtPiQLKTpkC2U2pAuhMuQL3S8\nkDBkrZAxXdkQMnK0EDM9uxA0UpYQNR2dEDYyeBA2/X8QOBuUkDjdYRA5+3aQOr1DEDvbWJA8pl+Q\nPbs6kD6GQZA/mxyQQGYjkEGEORBCRgWQQ2QbEEQl55BFQ/0QRgXJkEcj3xBH7uYQSQPBEEnOyBBK\n46MQS66qEEzMv5BNjowQTqyhkE9ubhBQjIOQUVeKkFJsZZBTN2yQVExHkFUXTpBWLCmQVvcwkFgV\nRhBY1xKQWfUoEFq29JBb1QoQXKAREF207BBef/MQX5TOEGBf1RBhfeqQYj+3EGNdzJBkH5kQZT2u\nkGYItZBnHZCQZ+iXkGj9cpBpyHmQat1UkGuoW5BsxnEQbYg9kG6mUxBvaB+QcIY1EHFRPBByZhcQ\nczEeEHRF+RB1EQAQdi8VkHbw4hB4DveQeNDEEHnu2ZB6sKYQe867kHyZwpB9rp2QfnmkkH+Of5AC",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "NEW_YORK",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "NEW_YORK = b\"\"\"\nVFppZgAAAAAAAAAAAAAAAAAAAAAAAAAEAAAABAAAABcAAADrAAAABAAAABCeph5wn7rrYKCGAHCh\nms1gomXicKOD6eCkaq5wpTWnYKZTyvCnFYlgqDOs8Kj+peCqE47wqt6H4KvzcPCsvmngrdNS8K6e\nS+CvszTwsH4t4LGcUXCyZ0pgs3wzcLRHLGC1XBVwticOYLc793C4BvBguRvZcLnm0mC7BPXwu8a0\nYLzk1/C9r9DgvsS58L+PsuDApJvwwW+U4MKEffDDT3bgxGRf8MUvWODGTXxwxw864MgtXnDI+Fdg\nyg1AcMrYOWDLiPBw0iP0cNJg++DTdeTw1EDd4NVVxvDWIL/g1zWo8NgAoeDZFYrw2eCD4Nr+p3Db\nwGXg3N6JcN2pgmDevmtw34lkYOCeTXDhaUZg4n4vcONJKGDkXhFw5Vcu4OZHLfDnNxDg6CcP8OkW\n8uDqBvHw6vbU4Ovm0/Ds1rbg7ca18O6/02Dvr9Jw8J+1YPGPtHDyf5dg82+WcPRfeWD1T3hw9j9b\nYPcvWnD4KHfg+Q88cPoIWeD6+Fjw++g74PzYOvD9yB3g/rgc8P+n/+AAl/7wAYfh4AJ34PADcP5g\nBGD9cAVQ4GEGQN9yBzDCYgeNGXMJEKRjCa2U9ArwhmQL4IV1DNmi5Q3AZ3YOuYTmD6mD9xCZZucR",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TZICAL_EST5EDT",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "TZICAL_EST5EDT = \"\"\"\nBEGIN:VTIMEZONE\nTZID:US-Eastern\nLAST-MODIFIED:19870101T000000Z\nTZURL:http://zones.stds_r_us.net/tz/US-Eastern\nBEGIN:STANDARD\nDTSTART:19671029T020000\nRRULE:FREQ=YEARLY;BYDAY=-1SU;BYMONTH=10\nTZOFFSETFROM:-0400\nTZOFFSETTO:-0500",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "TZICAL_PST8PDT",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "TZICAL_PST8PDT = \"\"\"\nBEGIN:VTIMEZONE\nTZID:US-Pacific\nLAST-MODIFIED:19870101T000000Z\nBEGIN:STANDARD\nDTSTART:19671029T020000\nRRULE:FREQ=YEARLY;BYDAY=-1SU;BYMONTH=10\nTZOFFSETFROM:-0700\nTZOFFSETTO:-0800\nTZNAME:PST",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "EST_TUPLE",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "EST_TUPLE = ('EST', timedelta(hours=-5), timedelta(hours=0))\nEDT_TUPLE = ('EDT', timedelta(hours=-4), timedelta(hours=1))\nSUPPORTS_SUB_MINUTE_OFFSETS = sys.version_info >= (3, 6)\n###\n# Helper functions\ndef get_timezone_tuple(dt):\n    \"\"\"Retrieve a (tzname, utcoffset, dst) tuple for a given DST\"\"\"\n    return dt.tzname(), dt.utcoffset(), dt.dst()\n###\n# Mix-ins",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "EDT_TUPLE",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "EDT_TUPLE = ('EDT', timedelta(hours=-4), timedelta(hours=1))\nSUPPORTS_SUB_MINUTE_OFFSETS = sys.version_info >= (3, 6)\n###\n# Helper functions\ndef get_timezone_tuple(dt):\n    \"\"\"Retrieve a (tzname, utcoffset, dst) tuple for a given DST\"\"\"\n    return dt.tzname(), dt.utcoffset(), dt.dst()\n###\n# Mix-ins\nclass context_passthrough(object):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "SUPPORTS_SUB_MINUTE_OFFSETS",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "SUPPORTS_SUB_MINUTE_OFFSETS = sys.version_info >= (3, 6)\n###\n# Helper functions\ndef get_timezone_tuple(dt):\n    \"\"\"Retrieve a (tzname, utcoffset, dst) tuple for a given DST\"\"\"\n    return dt.tzname(), dt.utcoffset(), dt.dst()\n###\n# Mix-ins\nclass context_passthrough(object):\n    def __init__(*args, **kwargs):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "DEFAULT_TZSTR_RULES_EQUIV_2003",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "DEFAULT_TZSTR_RULES_EQUIV_2003 = [\n    'EST5EDT',\n    'EST5EDT4,M4.1.0/02:00:00,M10-5-0/02:00',\n    'EST5EDT4,95/02:00:00,298/02:00',\n    'EST5EDT4,J96/02:00:00,J299/02:00',\n    'EST5EDT4,J96/02:00:00,J299/02'\n]\n@pytest.mark.tzstr\n@pytest.mark.parametrize('tz_str', DEFAULT_TZSTR_RULES_EQUIV_2003)\ndef test_tzstr_default_start(tz_str):",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "resolve_imaginary_tests",
        "kind": 5,
        "importPath": "dateutil.test.test_tz",
        "description": "dateutil.test.test_tz",
        "peekOfCode": "resolve_imaginary_tests = [\n    (tz.gettz('Europe/London'),\n     datetime(2018, 3, 25, 1, 30), datetime(2018, 3, 25, 2, 30)),\n    (tz.gettz('America/New_York'),\n     datetime(2017, 3, 12, 2, 30), datetime(2017, 3, 12, 3, 30)),\n    (tz.gettz('Australia/Sydney'),\n     datetime(2014, 10, 5, 2, 0), datetime(2014, 10, 5, 3, 0)),\n    __get_kiritimati_resolve_imaginary_test(),\n]\nif SUPPORTS_SUB_MINUTE_OFFSETS:",
        "detail": "dateutil.test.test_tz",
        "documentation": {}
    },
    {
        "label": "test_utils_today",
        "kind": 2,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "def test_utils_today():\n    assert utils.today() == datetime(2014, 12, 15, 0, 0, 0)\n@freeze_time(datetime(2014, 12, 15, 12), tz_offset=5)\ndef test_utils_today_tz_info():\n    assert utils.today(NYC) == datetime(2014, 12, 15, 0, 0, 0, tzinfo=NYC)\n@freeze_time(datetime(2014, 12, 15, 23), tz_offset=5)\ndef test_utils_today_tz_info_different_day():\n    assert utils.today(UTC) == datetime(2014, 12, 16, 0, 0, 0, tzinfo=UTC)\ndef test_utils_default_tz_info_naive():\n    dt = datetime(2014, 9, 14, 9, 30)",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "test_utils_today_tz_info",
        "kind": 2,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "def test_utils_today_tz_info():\n    assert utils.today(NYC) == datetime(2014, 12, 15, 0, 0, 0, tzinfo=NYC)\n@freeze_time(datetime(2014, 12, 15, 23), tz_offset=5)\ndef test_utils_today_tz_info_different_day():\n    assert utils.today(UTC) == datetime(2014, 12, 16, 0, 0, 0, tzinfo=UTC)\ndef test_utils_default_tz_info_naive():\n    dt = datetime(2014, 9, 14, 9, 30)\n    assert utils.default_tzinfo(dt, NYC).tzinfo is NYC\ndef test_utils_default_tz_info_aware():\n    dt = datetime(2014, 9, 14, 9, 30, tzinfo=UTC)",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "test_utils_today_tz_info_different_day",
        "kind": 2,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "def test_utils_today_tz_info_different_day():\n    assert utils.today(UTC) == datetime(2014, 12, 16, 0, 0, 0, tzinfo=UTC)\ndef test_utils_default_tz_info_naive():\n    dt = datetime(2014, 9, 14, 9, 30)\n    assert utils.default_tzinfo(dt, NYC).tzinfo is NYC\ndef test_utils_default_tz_info_aware():\n    dt = datetime(2014, 9, 14, 9, 30, tzinfo=UTC)\n    assert utils.default_tzinfo(dt, NYC).tzinfo is UTC\ndef test_utils_within_delta():\n    d1 = datetime(2016, 1, 1, 12, 14, 1, 9)",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "test_utils_default_tz_info_naive",
        "kind": 2,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "def test_utils_default_tz_info_naive():\n    dt = datetime(2014, 9, 14, 9, 30)\n    assert utils.default_tzinfo(dt, NYC).tzinfo is NYC\ndef test_utils_default_tz_info_aware():\n    dt = datetime(2014, 9, 14, 9, 30, tzinfo=UTC)\n    assert utils.default_tzinfo(dt, NYC).tzinfo is UTC\ndef test_utils_within_delta():\n    d1 = datetime(2016, 1, 1, 12, 14, 1, 9)\n    d2 = d1.replace(microsecond=15)\n    assert within_delta(d1, d2, timedelta(seconds=1))",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "test_utils_default_tz_info_aware",
        "kind": 2,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "def test_utils_default_tz_info_aware():\n    dt = datetime(2014, 9, 14, 9, 30, tzinfo=UTC)\n    assert utils.default_tzinfo(dt, NYC).tzinfo is UTC\ndef test_utils_within_delta():\n    d1 = datetime(2016, 1, 1, 12, 14, 1, 9)\n    d2 = d1.replace(microsecond=15)\n    assert within_delta(d1, d2, timedelta(seconds=1))\n    assert not within_delta(d1, d2, timedelta(microseconds=1))\ndef test_utils_within_delta_with_negative_delta():\n    d1 = datetime(2016, 1, 1)",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "test_utils_within_delta",
        "kind": 2,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "def test_utils_within_delta():\n    d1 = datetime(2016, 1, 1, 12, 14, 1, 9)\n    d2 = d1.replace(microsecond=15)\n    assert within_delta(d1, d2, timedelta(seconds=1))\n    assert not within_delta(d1, d2, timedelta(microseconds=1))\ndef test_utils_within_delta_with_negative_delta():\n    d1 = datetime(2016, 1, 1)\n    d2 = datetime(2015, 12, 31)\n    assert within_delta(d2, d1, timedelta(days=-1))",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "test_utils_within_delta_with_negative_delta",
        "kind": 2,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "def test_utils_within_delta_with_negative_delta():\n    d1 = datetime(2016, 1, 1)\n    d2 = datetime(2015, 12, 31)\n    assert within_delta(d2, d1, timedelta(days=-1))",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "NYC",
        "kind": 5,
        "importPath": "dateutil.test.test_utils",
        "description": "dateutil.test.test_utils",
        "peekOfCode": "NYC = tz.gettz(\"America/New_York\")\n@freeze_time(datetime(2014, 12, 15, 1, 21, 33, 4003))\ndef test_utils_today():\n    assert utils.today() == datetime(2014, 12, 15, 0, 0, 0)\n@freeze_time(datetime(2014, 12, 15, 12), tz_offset=5)\ndef test_utils_today_tz_info():\n    assert utils.today(NYC) == datetime(2014, 12, 15, 0, 0, 0, tzinfo=NYC)\n@freeze_time(datetime(2014, 12, 15, 23), tz_offset=5)\ndef test_utils_today_tz_info_different_day():\n    assert utils.today(UTC) == datetime(2014, 12, 16, 0, 0, 0, tzinfo=UTC)",
        "detail": "dateutil.test.test_utils",
        "documentation": {}
    },
    {
        "label": "_tzinfo",
        "kind": 6,
        "importPath": "dateutil.tz._common",
        "description": "dateutil.tz._common",
        "peekOfCode": "class _tzinfo(tzinfo):\n    \"\"\"\n    Base class for all ``dateutil`` ``tzinfo`` objects.\n    \"\"\"\n    def is_ambiguous(self, dt):\n        \"\"\"\n        Whether or not the \"wall time\" of a given datetime is ambiguous in this\n        zone.\n        :param dt:\n            A :py:class:`datetime.datetime`, naive or time zone aware.",
        "detail": "dateutil.tz._common",
        "documentation": {}
    },
    {
        "label": "tzrangebase",
        "kind": 6,
        "importPath": "dateutil.tz._common",
        "description": "dateutil.tz._common",
        "peekOfCode": "class tzrangebase(_tzinfo):\n    \"\"\"\n    This is an abstract base class for time zones represented by an annual\n    transition into and out of DST. Child classes should implement the following\n    methods:\n        * ``__init__(self, *args, **kwargs)``\n        * ``transitions(self, year)`` - this is expected to return a tuple of\n          datetimes representing the DST on and off transitions in standard\n          time.\n    A fully initialized ``tzrangebase`` subclass should also provide the",
        "detail": "dateutil.tz._common",
        "documentation": {}
    },
    {
        "label": "tzname_in_python2",
        "kind": 2,
        "importPath": "dateutil.tz._common",
        "description": "dateutil.tz._common",
        "peekOfCode": "def tzname_in_python2(namefunc):\n    \"\"\"Change unicode output into bytestrings in Python 2\n    tzname() API changed in Python 3. It used to return bytes, but was changed\n    to unicode strings\n    \"\"\"\n    if PY2:\n        @wraps(namefunc)\n        def adjust_encoding(*args, **kwargs):\n            name = namefunc(*args, **kwargs)\n            if name is not None:",
        "detail": "dateutil.tz._common",
        "documentation": {}
    },
    {
        "label": "ZERO",
        "kind": 5,
        "importPath": "dateutil.tz._common",
        "description": "dateutil.tz._common",
        "peekOfCode": "ZERO = timedelta(0)\n__all__ = ['tzname_in_python2', 'enfold']\ndef tzname_in_python2(namefunc):\n    \"\"\"Change unicode output into bytestrings in Python 2\n    tzname() API changed in Python 3. It used to return bytes, but was changed\n    to unicode strings\n    \"\"\"\n    if PY2:\n        @wraps(namefunc)\n        def adjust_encoding(*args, **kwargs):",
        "detail": "dateutil.tz._common",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dateutil.tz._common",
        "description": "dateutil.tz._common",
        "peekOfCode": "__all__ = ['tzname_in_python2', 'enfold']\ndef tzname_in_python2(namefunc):\n    \"\"\"Change unicode output into bytestrings in Python 2\n    tzname() API changed in Python 3. It used to return bytes, but was changed\n    to unicode strings\n    \"\"\"\n    if PY2:\n        @wraps(namefunc)\n        def adjust_encoding(*args, **kwargs):\n            name = namefunc(*args, **kwargs)",
        "detail": "dateutil.tz._common",
        "documentation": {}
    },
    {
        "label": "_TzSingleton",
        "kind": 6,
        "importPath": "dateutil.tz._factories",
        "description": "dateutil.tz._factories",
        "peekOfCode": "class _TzSingleton(type):\n    def __init__(cls, *args, **kwargs):\n        cls.__instance = None\n        super(_TzSingleton, cls).__init__(*args, **kwargs)\n    def __call__(cls):\n        if cls.__instance is None:\n            cls.__instance = super(_TzSingleton, cls).__call__()\n        return cls.__instance\nclass _TzFactory(type):\n    def instance(cls, *args, **kwargs):",
        "detail": "dateutil.tz._factories",
        "documentation": {}
    },
    {
        "label": "_TzFactory",
        "kind": 6,
        "importPath": "dateutil.tz._factories",
        "description": "dateutil.tz._factories",
        "peekOfCode": "class _TzFactory(type):\n    def instance(cls, *args, **kwargs):\n        \"\"\"Alternate constructor that returns a fresh instance\"\"\"\n        return type.__call__(cls, *args, **kwargs)\nclass _TzOffsetFactory(_TzFactory):\n    def __init__(cls, *args, **kwargs):\n        cls.__instances = weakref.WeakValueDictionary()\n        cls.__strong_cache = OrderedDict()\n        cls.__strong_cache_size = 8\n        cls._cache_lock = _thread.allocate_lock()",
        "detail": "dateutil.tz._factories",
        "documentation": {}
    },
    {
        "label": "_TzOffsetFactory",
        "kind": 6,
        "importPath": "dateutil.tz._factories",
        "description": "dateutil.tz._factories",
        "peekOfCode": "class _TzOffsetFactory(_TzFactory):\n    def __init__(cls, *args, **kwargs):\n        cls.__instances = weakref.WeakValueDictionary()\n        cls.__strong_cache = OrderedDict()\n        cls.__strong_cache_size = 8\n        cls._cache_lock = _thread.allocate_lock()\n    def __call__(cls, name, offset):\n        if isinstance(offset, timedelta):\n            key = (name, offset.total_seconds())\n        else:",
        "detail": "dateutil.tz._factories",
        "documentation": {}
    },
    {
        "label": "_TzStrFactory",
        "kind": 6,
        "importPath": "dateutil.tz._factories",
        "description": "dateutil.tz._factories",
        "peekOfCode": "class _TzStrFactory(_TzFactory):\n    def __init__(cls, *args, **kwargs):\n        cls.__instances = weakref.WeakValueDictionary()\n        cls.__strong_cache = OrderedDict()\n        cls.__strong_cache_size = 8\n        cls.__cache_lock = _thread.allocate_lock()\n    def __call__(cls, s, posix_offset=False):\n        key = (s, posix_offset)\n        instance = cls.__instances.get(key, None)\n        if instance is None:",
        "detail": "dateutil.tz._factories",
        "documentation": {}
    },
    {
        "label": "tzutc",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class tzutc(datetime.tzinfo):\n    \"\"\"\n    This is a tzinfo object that represents the UTC time zone.\n    **Examples:**\n    .. doctest::\n        >>> from datetime import *\n        >>> from dateutil.tz import *\n        >>> datetime.now()\n        datetime.datetime(2003, 9, 27, 9, 40, 1, 521290)\n        >>> datetime.now(tzutc())",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "tzoffset",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class tzoffset(datetime.tzinfo):\n    \"\"\"\n    A simple class for representing a fixed offset from UTC.\n    :param name:\n        The timezone name, to be returned when ``tzname()`` is called.\n    :param offset:\n        The time zone offset in seconds, or (since version 2.6.0, represented\n        as a :py:class:`datetime.timedelta` object).\n    \"\"\"\n    def __init__(self, name, offset):",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "tzlocal",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class tzlocal(_tzinfo):\n    \"\"\"\n    A :class:`tzinfo` subclass built around the ``time`` timezone functions.\n    \"\"\"\n    def __init__(self):\n        super(tzlocal, self).__init__()\n        self._std_offset = datetime.timedelta(seconds=-time.timezone)\n        if time.daylight:\n            self._dst_offset = datetime.timedelta(seconds=-time.altzone)\n        else:",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "_ttinfo",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class _ttinfo(object):\n    __slots__ = [\"offset\", \"delta\", \"isdst\", \"abbr\",\n                 \"isstd\", \"isgmt\", \"dstoffset\"]\n    def __init__(self):\n        for attr in self.__slots__:\n            setattr(self, attr, None)\n    def __repr__(self):\n        l = []\n        for attr in self.__slots__:\n            value = getattr(self, attr)",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "_tzfile",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class _tzfile(object):\n    \"\"\"\n    Lightweight class for holding the relevant transition and time zone\n    information read from binary tzfiles.\n    \"\"\"\n    attrs = ['trans_list', 'trans_list_utc', 'trans_idx', 'ttinfo_list',\n             'ttinfo_std', 'ttinfo_dst', 'ttinfo_before', 'ttinfo_first']\n    def __init__(self, **kwargs):\n        for attr in self.attrs:\n            setattr(self, attr, kwargs.get(attr, None))",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "tzfile",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class tzfile(_tzinfo):\n    \"\"\"\n    This is a ``tzinfo`` subclass that allows one to use the ``tzfile(5)``\n    format timezone files to extract current and historical zone information.\n    :param fileobj:\n        This can be an opened file stream or a file name that the time zone\n        information can be read from.\n    :param filename:\n        This is an optional parameter specifying the source of the time zone\n        information in the event that ``fileobj`` is a file object. If omitted",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "tzrange",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class tzrange(tzrangebase):\n    \"\"\"\n    The ``tzrange`` object is a time zone specified by a set of offsets and\n    abbreviations, equivalent to the way the ``TZ`` variable can be specified\n    in POSIX-like systems, but using Python delta objects to specify DST\n    start, end and offsets.\n    :param stdabbr:\n        The abbreviation for standard time (e.g. ``'EST'``).\n    :param stdoffset:\n        An integer or :class:`datetime.timedelta` object or equivalent",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "tzstr",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class tzstr(tzrange):\n    \"\"\"\n    ``tzstr`` objects are time zone objects specified by a time-zone string as\n    it would be passed to a ``TZ`` variable on POSIX-style systems (see\n    the `GNU C Library: TZ Variable`_ for more details).\n    There is one notable exception, which is that POSIX-style time zones use an\n    inverted offset format, so normally ``GMT+3`` would be parsed as an offset\n    3 hours *behind* GMT. The ``tzstr`` time zone object will parse this as an\n    offset 3 hours *ahead* of GMT. If you would like to maintain the POSIX\n    behavior, pass a ``True`` value to ``posix_offset``.",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "_tzicalvtzcomp",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class _tzicalvtzcomp(object):\n    def __init__(self, tzoffsetfrom, tzoffsetto, isdst,\n                 tzname=None, rrule=None):\n        self.tzoffsetfrom = datetime.timedelta(seconds=tzoffsetfrom)\n        self.tzoffsetto = datetime.timedelta(seconds=tzoffsetto)\n        self.tzoffsetdiff = self.tzoffsetto - self.tzoffsetfrom\n        self.isdst = isdst\n        self.tzname = tzname\n        self.rrule = rrule\nclass _tzicalvtz(_tzinfo):",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "_tzicalvtz",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class _tzicalvtz(_tzinfo):\n    def __init__(self, tzid, comps=[]):\n        super(_tzicalvtz, self).__init__()\n        self._tzid = tzid\n        self._comps = comps\n        self._cachedate = []\n        self._cachecomp = []\n        self._cache_lock = _thread.allocate_lock()\n    def _find_comp(self, dt):\n        if len(self._comps) == 1:",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "tzical",
        "kind": 6,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "class tzical(object):\n    \"\"\"\n    This object is designed to parse an iCalendar-style ``VTIMEZONE`` structure\n    as set out in `RFC 5545`_ Section 4.6.5 into one or more `tzinfo` objects.\n    :param `fileobj`:\n        A file or stream in iCalendar format, which should be UTF-8 encoded\n        with CRLF endings.\n    .. _`RFC 5545`: https://tools.ietf.org/html/rfc5545\n    \"\"\"\n    def __init__(self, fileobj):",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "datetime_exists",
        "kind": 2,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "def datetime_exists(dt, tz=None):\n    \"\"\"\n    Given a datetime and a time zone, determine whether or not a given datetime\n    would fall in a gap.\n    :param dt:\n        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``\n        is provided.)\n    :param tz:\n        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If\n        ``None`` or not provided, the datetime's own time zone will be used.",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "datetime_ambiguous",
        "kind": 2,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "def datetime_ambiguous(dt, tz=None):\n    \"\"\"\n    Given a datetime and a time zone, determine whether or not a given datetime\n    is ambiguous (i.e if there are two times differentiated only by their DST\n    status).\n    :param dt:\n        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``\n        is provided.)\n    :param tz:\n        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "resolve_imaginary",
        "kind": 2,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "def resolve_imaginary(dt):\n    \"\"\"\n    Given a datetime that may be imaginary, return an existing datetime.\n    This function assumes that an imaginary datetime represents what the\n    wall time would be in a zone had the offset transition not occurred, so\n    it will always fall forward by the transition's change in offset.\n    .. doctest::\n        >>> from dateutil import tz\n        >>> from datetime import datetime\n        >>> NYC = tz.gettz('America/New_York')",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "ZERO",
        "kind": 5,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "ZERO = datetime.timedelta(0)\nEPOCH = datetime.datetime.utcfromtimestamp(0)\nEPOCHORDINAL = EPOCH.toordinal()\n@six.add_metaclass(_TzSingleton)\nclass tzutc(datetime.tzinfo):\n    \"\"\"\n    This is a tzinfo object that represents the UTC time zone.\n    **Examples:**\n    .. doctest::\n        >>> from datetime import *",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "EPOCH",
        "kind": 5,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "EPOCH = datetime.datetime.utcfromtimestamp(0)\nEPOCHORDINAL = EPOCH.toordinal()\n@six.add_metaclass(_TzSingleton)\nclass tzutc(datetime.tzinfo):\n    \"\"\"\n    This is a tzinfo object that represents the UTC time zone.\n    **Examples:**\n    .. doctest::\n        >>> from datetime import *\n        >>> from dateutil.tz import *",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "EPOCHORDINAL",
        "kind": 5,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "EPOCHORDINAL = EPOCH.toordinal()\n@six.add_metaclass(_TzSingleton)\nclass tzutc(datetime.tzinfo):\n    \"\"\"\n    This is a tzinfo object that represents the UTC time zone.\n    **Examples:**\n    .. doctest::\n        >>> from datetime import *\n        >>> from dateutil.tz import *\n        >>> datetime.now()",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "UTC",
        "kind": 5,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "UTC = tzutc()\n@six.add_metaclass(_TzOffsetFactory)\nclass tzoffset(datetime.tzinfo):\n    \"\"\"\n    A simple class for representing a fixed offset from UTC.\n    :param name:\n        The timezone name, to be returned when ``tzname()`` is called.\n    :param offset:\n        The time zone offset in seconds, or (since version 2.6.0, represented\n        as a :py:class:`datetime.timedelta` object).",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "gettz",
        "kind": 5,
        "importPath": "dateutil.tz.tz",
        "description": "dateutil.tz.tz",
        "peekOfCode": "gettz = __get_gettz()\ndel __get_gettz\ndef datetime_exists(dt, tz=None):\n    \"\"\"\n    Given a datetime and a time zone, determine whether or not a given datetime\n    would fall in a gap.\n    :param dt:\n        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``\n        is provided.)\n    :param tz:",
        "detail": "dateutil.tz.tz",
        "documentation": {}
    },
    {
        "label": "tzres",
        "kind": 6,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "class tzres(object):\n    \"\"\"\n    Class for accessing ``tzres.dll``, which contains timezone name related\n    resources.\n    .. versionadded:: 2.5.0\n    \"\"\"\n    p_wchar = ctypes.POINTER(wintypes.WCHAR)        # Pointer to a wide char\n    def __init__(self, tzres_loc='tzres.dll'):\n        # Load the user32 DLL so we can load strings from tzres\n        user32 = ctypes.WinDLL('user32')",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "tzwinbase",
        "kind": 6,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "class tzwinbase(tzrangebase):\n    \"\"\"tzinfo class based on win32's timezones available in the registry.\"\"\"\n    def __init__(self):\n        raise NotImplementedError('tzwinbase is an abstract base class')\n    def __eq__(self, other):\n        # Compare on all relevant dimensions, including name.\n        if not isinstance(other, tzwinbase):\n            return NotImplemented\n        return  (self._std_offset == other._std_offset and\n                 self._dst_offset == other._dst_offset and",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "tzwin",
        "kind": 6,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "class tzwin(tzwinbase):\n    \"\"\"\n    Time zone object created from the zone info in the Windows registry\n    These are similar to :py:class:`dateutil.tz.tzrange` objects in that\n    the time zone data is provided in the format of a single offset rule\n    for either 0 or 2 time zone transitions per year.\n    :param: name\n        The name of a Windows time zone key, e.g. \"Eastern Standard Time\".\n        The full list of keys can be retrieved with :func:`tzwin.list`.\n    \"\"\"",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "tzwinlocal",
        "kind": 6,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "class tzwinlocal(tzwinbase):\n    \"\"\"\n    Class representing the local time zone information in the Windows registry\n    While :class:`dateutil.tz.tzlocal` makes system calls (via the :mod:`time`\n    module) to retrieve time zone information, ``tzwinlocal`` retrieves the\n    rules directly from the Windows registry and creates an object like\n    :class:`dateutil.tz.tzwin`.\n    Because Windows does not have an equivalent of :func:`time.tzset`, on\n    Windows, :class:`dateutil.tz.tzlocal` instances will always reflect the\n    time zone settings *at the time that the process was started*, meaning",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "picknthweekday",
        "kind": 2,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "def picknthweekday(year, month, dayofweek, hour, minute, whichweek):\n    \"\"\" dayofweek == 0 means Sunday, whichweek 5 means last instance \"\"\"\n    first = datetime.datetime(year, month, 1, hour, minute)\n    # This will work if dayofweek is ISO weekday (1-7) or Microsoft-style (0-6),\n    # Because 7 % 7 = 0\n    weekdayone = first.replace(day=((dayofweek - first.isoweekday()) % 7) + 1)\n    wd = weekdayone + ((whichweek - 1) * ONEWEEK)\n    if (wd.month != month):\n        wd -= ONEWEEK\n    return wd",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "valuestodict",
        "kind": 2,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "def valuestodict(key):\n    \"\"\"Convert a registry key's values to a dictionary.\"\"\"\n    dout = {}\n    size = winreg.QueryInfoKey(key)[1]\n    tz_res = None\n    for i in range(size):\n        key_name, value, dtype = winreg.EnumValue(key, i)\n        if dtype == winreg.REG_DWORD or dtype == winreg.REG_DWORD_LITTLE_ENDIAN:\n            # If it's a DWORD (32-bit integer), it's stored as unsigned - convert\n            # that to a proper signed integer",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "__all__ = [\"tzwin\", \"tzwinlocal\", \"tzres\"]\nONEWEEK = datetime.timedelta(7)\nTZKEYNAMENT = r\"SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Time Zones\"\nTZKEYNAME9X = r\"SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Time Zones\"\nTZLOCALKEYNAME = r\"SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\"\ndef _settzkeyname():\n    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\n    try:\n        winreg.OpenKey(handle, TZKEYNAMENT).Close()\n        TZKEYNAME = TZKEYNAMENT",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "ONEWEEK",
        "kind": 5,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "ONEWEEK = datetime.timedelta(7)\nTZKEYNAMENT = r\"SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Time Zones\"\nTZKEYNAME9X = r\"SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Time Zones\"\nTZLOCALKEYNAME = r\"SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\"\ndef _settzkeyname():\n    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\n    try:\n        winreg.OpenKey(handle, TZKEYNAMENT).Close()\n        TZKEYNAME = TZKEYNAMENT\n    except WindowsError:",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "TZKEYNAMENT",
        "kind": 5,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "TZKEYNAMENT = r\"SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Time Zones\"\nTZKEYNAME9X = r\"SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Time Zones\"\nTZLOCALKEYNAME = r\"SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\"\ndef _settzkeyname():\n    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\n    try:\n        winreg.OpenKey(handle, TZKEYNAMENT).Close()\n        TZKEYNAME = TZKEYNAMENT\n    except WindowsError:\n        TZKEYNAME = TZKEYNAME9X",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "TZKEYNAME9X",
        "kind": 5,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "TZKEYNAME9X = r\"SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Time Zones\"\nTZLOCALKEYNAME = r\"SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\"\ndef _settzkeyname():\n    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\n    try:\n        winreg.OpenKey(handle, TZKEYNAMENT).Close()\n        TZKEYNAME = TZKEYNAMENT\n    except WindowsError:\n        TZKEYNAME = TZKEYNAME9X\n    handle.Close()",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "TZLOCALKEYNAME",
        "kind": 5,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "TZLOCALKEYNAME = r\"SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\"\ndef _settzkeyname():\n    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\n    try:\n        winreg.OpenKey(handle, TZKEYNAMENT).Close()\n        TZKEYNAME = TZKEYNAMENT\n    except WindowsError:\n        TZKEYNAME = TZKEYNAME9X\n    handle.Close()\n    return TZKEYNAME",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "TZKEYNAME",
        "kind": 5,
        "importPath": "dateutil.tz.win",
        "description": "dateutil.tz.win",
        "peekOfCode": "TZKEYNAME = _settzkeyname()\nclass tzres(object):\n    \"\"\"\n    Class for accessing ``tzres.dll``, which contains timezone name related\n    resources.\n    .. versionadded:: 2.5.0\n    \"\"\"\n    p_wchar = ctypes.POINTER(wintypes.WCHAR)        # Pointer to a wide char\n    def __init__(self, tzres_loc='tzres.dll'):\n        # Load the user32 DLL so we can load strings from tzres",
        "detail": "dateutil.tz.win",
        "documentation": {}
    },
    {
        "label": "rebuild",
        "kind": 2,
        "importPath": "dateutil.zoneinfo.rebuild",
        "description": "dateutil.zoneinfo.rebuild",
        "peekOfCode": "def rebuild(filename, tag=None, format=\"gz\", zonegroups=[], metadata=None):\n    \"\"\"Rebuild the internal timezone info in dateutil/zoneinfo/zoneinfo*tar*\n    filename is the timezone tarball from ``ftp.iana.org/tz``.\n    \"\"\"\n    tmpdir = tempfile.mkdtemp()\n    zonedir = os.path.join(tmpdir, \"zoneinfo\")\n    moduledir = os.path.dirname(__file__)\n    try:\n        with TarFile.open(filename) as tf:\n            for name in zonegroups:",
        "detail": "dateutil.zoneinfo.rebuild",
        "documentation": {}
    },
    {
        "label": "weekday",
        "kind": 6,
        "importPath": "dateutil._common",
        "description": "dateutil._common",
        "peekOfCode": "class weekday(object):\n    __slots__ = [\"weekday\", \"n\"]\n    def __init__(self, weekday, n=None):\n        self.weekday = weekday\n        self.n = n\n    def __call__(self, n):\n        if n == self.n:\n            return self\n        else:\n            return self.__class__(self.weekday, n)",
        "detail": "dateutil._common",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "dateutil._version",
        "description": "dateutil._version",
        "peekOfCode": "version = '2.8.2'\nversion_tuple = (2, 8, 2)",
        "detail": "dateutil._version",
        "documentation": {}
    },
    {
        "label": "version_tuple",
        "kind": 5,
        "importPath": "dateutil._version",
        "description": "dateutil._version",
        "peekOfCode": "version_tuple = (2, 8, 2)",
        "detail": "dateutil._version",
        "documentation": {}
    },
    {
        "label": "easter",
        "kind": 2,
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "peekOfCode": "def easter(year, method=EASTER_WESTERN):\n    \"\"\"\n    This method was ported from the work done by GM Arts,\n    on top of the algorithm by Claus Tondering, which was\n    based in part on the algorithm of Ouding (1940), as\n    quoted in \"Explanatory Supplement to the Astronomical\n    Almanac\", P.  Kenneth Seidelmann, editor.\n    This algorithm implements three different Easter\n    calculation methods:\n    1. Original calculation in Julian calendar, valid in",
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "peekOfCode": "__all__ = [\"easter\", \"EASTER_JULIAN\", \"EASTER_ORTHODOX\", \"EASTER_WESTERN\"]\nEASTER_JULIAN = 1\nEASTER_ORTHODOX = 2\nEASTER_WESTERN = 3\ndef easter(year, method=EASTER_WESTERN):\n    \"\"\"\n    This method was ported from the work done by GM Arts,\n    on top of the algorithm by Claus Tondering, which was\n    based in part on the algorithm of Ouding (1940), as\n    quoted in \"Explanatory Supplement to the Astronomical",
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "EASTER_JULIAN",
        "kind": 5,
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "peekOfCode": "EASTER_JULIAN = 1\nEASTER_ORTHODOX = 2\nEASTER_WESTERN = 3\ndef easter(year, method=EASTER_WESTERN):\n    \"\"\"\n    This method was ported from the work done by GM Arts,\n    on top of the algorithm by Claus Tondering, which was\n    based in part on the algorithm of Ouding (1940), as\n    quoted in \"Explanatory Supplement to the Astronomical\n    Almanac\", P.  Kenneth Seidelmann, editor.",
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "EASTER_ORTHODOX",
        "kind": 5,
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "peekOfCode": "EASTER_ORTHODOX = 2\nEASTER_WESTERN = 3\ndef easter(year, method=EASTER_WESTERN):\n    \"\"\"\n    This method was ported from the work done by GM Arts,\n    on top of the algorithm by Claus Tondering, which was\n    based in part on the algorithm of Ouding (1940), as\n    quoted in \"Explanatory Supplement to the Astronomical\n    Almanac\", P.  Kenneth Seidelmann, editor.\n    This algorithm implements three different Easter",
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "EASTER_WESTERN",
        "kind": 5,
        "importPath": "dateutil.easter",
        "description": "dateutil.easter",
        "peekOfCode": "EASTER_WESTERN = 3\ndef easter(year, method=EASTER_WESTERN):\n    \"\"\"\n    This method was ported from the work done by GM Arts,\n    on top of the algorithm by Claus Tondering, which was\n    based in part on the algorithm of Ouding (1940), as\n    quoted in \"Explanatory Supplement to the Astronomical\n    Almanac\", P.  Kenneth Seidelmann, editor.\n    This algorithm implements three different Easter\n    calculation methods:",
        "detail": "dateutil.easter",
        "documentation": {}
    },
    {
        "label": "relativedelta",
        "kind": 6,
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "peekOfCode": "class relativedelta(object):\n    \"\"\"\n    The relativedelta type is designed to be applied to an existing datetime and\n    can replace specific components of that datetime, or represents an interval\n    of time.\n    It is based on the specification of the excellent work done by M.-A. Lemburg\n    in his\n    `mx.DateTime <https://www.egenix.com/products/python/mxBase/mxDateTime/>`_ extension.\n    However, notice that this type does *NOT* implement the same algorithm as\n    his work. Do *NOT* expect it to behave like mx.DateTime's counterpart.",
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dateutil.relativedelta",
        "description": "dateutil.relativedelta",
        "peekOfCode": "__all__ = [\"relativedelta\", \"MO\", \"TU\", \"WE\", \"TH\", \"FR\", \"SA\", \"SU\"]\nclass relativedelta(object):\n    \"\"\"\n    The relativedelta type is designed to be applied to an existing datetime and\n    can replace specific components of that datetime, or represents an interval\n    of time.\n    It is based on the specification of the excellent work done by M.-A. Lemburg\n    in his\n    `mx.DateTime <https://www.egenix.com/products/python/mxBase/mxDateTime/>`_ extension.\n    However, notice that this type does *NOT* implement the same algorithm as",
        "detail": "dateutil.relativedelta",
        "documentation": {}
    },
    {
        "label": "weekday",
        "kind": 6,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "class weekday(weekdaybase):\n    \"\"\"\n    This version of weekday does not allow n = 0.\n    \"\"\"\n    def __init__(self, wkday, n=None):\n        if n == 0:\n            raise ValueError(\"Can't create weekday with n==0\")\n        super(weekday, self).__init__(wkday, n)\nMO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))\ndef _invalidates_cache(f):",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "rrulebase",
        "kind": 6,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "class rrulebase(object):\n    def __init__(self, cache=False):\n        if cache:\n            self._cache = []\n            self._cache_lock = _thread.allocate_lock()\n            self._invalidate_cache()\n        else:\n            self._cache = None\n            self._cache_complete = False\n            self._len = None",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "rrule",
        "kind": 6,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "class rrule(rrulebase):\n    \"\"\"\n    That's the base of the rrule operation. It accepts all the keywords\n    defined in the RFC as its constructor parameters (except byday,\n    which was renamed to byweekday) and more. The constructor prototype is::\n            rrule(freq)\n    Where freq must be one of YEARLY, MONTHLY, WEEKLY, DAILY, HOURLY, MINUTELY,\n    or SECONDLY.\n    .. note::\n        Per RFC section 3.3.10, recurrence instances falling on invalid dates",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "_iterinfo",
        "kind": 6,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "class _iterinfo(object):\n    __slots__ = [\"rrule\", \"lastyear\", \"lastmonth\",\n                 \"yearlen\", \"nextyearlen\", \"yearordinal\", \"yearweekday\",\n                 \"mmask\", \"mrange\", \"mdaymask\", \"nmdaymask\",\n                 \"wdaymask\", \"wnomask\", \"nwdaymask\", \"eastermask\"]\n    def __init__(self, rrule):\n        for attr in self.__slots__:\n            setattr(self, attr, None)\n        self.rrule = rrule\n    def rebuild(self, year, month):",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "rruleset",
        "kind": 6,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "class rruleset(rrulebase):\n    \"\"\" The rruleset type allows more complex recurrence setups, mixing\n    multiple rules, dates, exclusion rules, and exclusion dates. The type\n    constructor takes the following keyword arguments:\n    :param cache: If True, caching of results will be enabled, improving\n                  performance of multiple queries considerably. \"\"\"\n    class _genitem(object):\n        def __init__(self, genlist, gen):\n            try:\n                self.dt = advance_iterator(gen)",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "_rrulestr",
        "kind": 6,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "class _rrulestr(object):\n    \"\"\" Parses a string representation of a recurrence rule or set of\n    recurrence rules.\n    :param s:\n        Required, a string defining one or more recurrence rules.\n    :param dtstart:\n        If given, used as the default recurrence start if not specified in the\n        rule string.\n    :param cache:\n        If set ``True`` caching of results will be enabled, improving",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "__all__ = [\"rrule\", \"rruleset\", \"rrulestr\",\n           \"YEARLY\", \"MONTHLY\", \"WEEKLY\", \"DAILY\",\n           \"HOURLY\", \"MINUTELY\", \"SECONDLY\",\n           \"MO\", \"TU\", \"WE\", \"TH\", \"FR\", \"SA\", \"SU\"]\n# Every mask is 7 days longer to handle cross-year weekly periods.\nM366MASK = tuple([1]*31+[2]*29+[3]*31+[4]*30+[5]*31+[6]*30 +\n                 [7]*31+[8]*31+[9]*30+[10]*31+[11]*30+[12]*31+[1]*7)\nM365MASK = list(M366MASK)\nM29, M30, M31 = list(range(1, 30)), list(range(1, 31)), list(range(1, 32))\nMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "M366MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "M366MASK = tuple([1]*31+[2]*29+[3]*31+[4]*30+[5]*31+[6]*30 +\n                 [7]*31+[8]*31+[9]*30+[10]*31+[11]*30+[12]*31+[1]*7)\nM365MASK = list(M366MASK)\nM29, M30, M31 = list(range(1, 30)), list(range(1, 31)), list(range(1, 32))\nMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nMDAY365MASK = list(MDAY366MASK)\nM29, M30, M31 = list(range(-29, 0)), list(range(-30, 0)), list(range(-31, 0))\nNMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nNMDAY365MASK = list(NMDAY366MASK)\nM366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "M365MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "M365MASK = list(M366MASK)\nM29, M30, M31 = list(range(1, 30)), list(range(1, 31)), list(range(1, 32))\nMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nMDAY365MASK = list(MDAY366MASK)\nM29, M30, M31 = list(range(-29, 0)), list(range(-30, 0)), list(range(-31, 0))\nNMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nNMDAY365MASK = list(NMDAY366MASK)\nM366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)\nM365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)\nWDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "MDAY366MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "MDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nMDAY365MASK = list(MDAY366MASK)\nM29, M30, M31 = list(range(-29, 0)), list(range(-30, 0)), list(range(-31, 0))\nNMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nNMDAY365MASK = list(NMDAY366MASK)\nM366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)\nM365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)\nWDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55\ndel M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]\nMDAY365MASK = tuple(MDAY365MASK)",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "MDAY365MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "MDAY365MASK = list(MDAY366MASK)\nM29, M30, M31 = list(range(-29, 0)), list(range(-30, 0)), list(range(-31, 0))\nNMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nNMDAY365MASK = list(NMDAY366MASK)\nM366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)\nM365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)\nWDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55\ndel M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]\nMDAY365MASK = tuple(MDAY365MASK)\nM365MASK = tuple(M365MASK)",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "NMDAY366MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "NMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])\nNMDAY365MASK = list(NMDAY366MASK)\nM366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)\nM365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)\nWDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55\ndel M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]\nMDAY365MASK = tuple(MDAY365MASK)\nM365MASK = tuple(M365MASK)\nFREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "NMDAY365MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "NMDAY365MASK = list(NMDAY366MASK)\nM366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)\nM365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)\nWDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55\ndel M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]\nMDAY365MASK = tuple(MDAY365MASK)\nM365MASK = tuple(M365MASK)\nFREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,\n MONTHLY,",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "M366RANGE",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "M366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)\nM365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)\nWDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55\ndel M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]\nMDAY365MASK = tuple(MDAY365MASK)\nM365MASK = tuple(M365MASK)\nFREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,\n MONTHLY,\n WEEKLY,",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "M365RANGE",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "M365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)\nWDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55\ndel M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]\nMDAY365MASK = tuple(MDAY365MASK)\nM365MASK = tuple(M365MASK)\nFREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,\n MONTHLY,\n WEEKLY,\n DAILY,",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "WDAYMASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "WDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55\ndel M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]\nMDAY365MASK = tuple(MDAY365MASK)\nM365MASK = tuple(M365MASK)\nFREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,\n MONTHLY,\n WEEKLY,\n DAILY,\n HOURLY,",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "MDAY365MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "MDAY365MASK = tuple(MDAY365MASK)\nM365MASK = tuple(M365MASK)\nFREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,\n MONTHLY,\n WEEKLY,\n DAILY,\n HOURLY,\n MINUTELY,\n SECONDLY) = list(range(7))",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "M365MASK",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "M365MASK = tuple(M365MASK)\nFREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,\n MONTHLY,\n WEEKLY,\n DAILY,\n HOURLY,\n MINUTELY,\n SECONDLY) = list(range(7))\n# Imported on demand.",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "FREQNAMES",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "FREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']\n(YEARLY,\n MONTHLY,\n WEEKLY,\n DAILY,\n HOURLY,\n MINUTELY,\n SECONDLY) = list(range(7))\n# Imported on demand.\neaster = None",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "easter",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "easter = None\nparser = None\nclass weekday(weekdaybase):\n    \"\"\"\n    This version of weekday does not allow n = 0.\n    \"\"\"\n    def __init__(self, wkday, n=None):\n        if n == 0:\n            raise ValueError(\"Can't create weekday with n==0\")\n        super(weekday, self).__init__(wkday, n)",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "parser = None\nclass weekday(weekdaybase):\n    \"\"\"\n    This version of weekday does not allow n = 0.\n    \"\"\"\n    def __init__(self, wkday, n=None):\n        if n == 0:\n            raise ValueError(\"Can't create weekday with n==0\")\n        super(weekday, self).__init__(wkday, n)\nMO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "rrulestr",
        "kind": 5,
        "importPath": "dateutil.rrule",
        "description": "dateutil.rrule",
        "peekOfCode": "rrulestr = _rrulestr()\n# vim:ts=4:sw=4:et",
        "detail": "dateutil.rrule",
        "documentation": {}
    },
    {
        "label": "today",
        "kind": 2,
        "importPath": "dateutil.utils",
        "description": "dateutil.utils",
        "peekOfCode": "def today(tzinfo=None):\n    \"\"\"\n    Returns a :py:class:`datetime` representing the current day at midnight\n    :param tzinfo:\n        The time zone to attach (also used to determine the current day).\n    :return:\n        A :py:class:`datetime.datetime` object representing the current day\n        at midnight.\n    \"\"\"\n    dt = datetime.now(tzinfo)",
        "detail": "dateutil.utils",
        "documentation": {}
    },
    {
        "label": "default_tzinfo",
        "kind": 2,
        "importPath": "dateutil.utils",
        "description": "dateutil.utils",
        "peekOfCode": "def default_tzinfo(dt, tzinfo):\n    \"\"\"\n    Sets the ``tzinfo`` parameter on naive datetimes only\n    This is useful for example when you are provided a datetime that may have\n    either an implicit or explicit time zone, such as when parsing a time zone\n    string.\n    .. doctest::\n        >>> from dateutil.tz import tzoffset\n        >>> from dateutil.parser import parse\n        >>> from dateutil.utils import default_tzinfo",
        "detail": "dateutil.utils",
        "documentation": {}
    },
    {
        "label": "within_delta",
        "kind": 2,
        "importPath": "dateutil.utils",
        "description": "dateutil.utils",
        "peekOfCode": "def within_delta(dt1, dt2, delta):\n    \"\"\"\n    Useful for comparing two datetimes that may have a negligible difference\n    to be considered equal.\n    \"\"\"\n    delta = abs(delta)\n    difference = dt1 - dt2\n    return -delta <= difference <= delta",
        "detail": "dateutil.utils",
        "documentation": {}
    },
    {
        "label": "to_native_string",
        "kind": 2,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "def to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where\n    necessary. This assumes ASCII unless told otherwise.\n    \"\"\"\n    if isinstance(string, builtin_str):\n        out = string\n    else:\n        out = string.decode(encoding)\n    return out",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "unicode_is_ascii",
        "kind": 2,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "def unicode_is_ascii(u_string):\n    \"\"\"Determine if unicode string only contains ASCII characters.\n    :param str u_string: unicode string to check. Must be unicode\n        and not Python 2 `str`.\n    :rtype: bool\n    \"\"\"\n    assert isinstance(u_string, str)\n    try:\n        u_string.encode(\"ascii\")\n        return True",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "_VALID_HEADER_NAME_RE_BYTE",
        "kind": 5,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "_VALID_HEADER_NAME_RE_BYTE = re.compile(rb\"^[^:\\s][^:\\r\\n]*$\")\n_VALID_HEADER_NAME_RE_STR = re.compile(r\"^[^:\\s][^:\\r\\n]*$\")\n_VALID_HEADER_VALUE_RE_BYTE = re.compile(rb\"^\\S[^\\r\\n]*$|^$\")\n_VALID_HEADER_VALUE_RE_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "_VALID_HEADER_NAME_RE_STR",
        "kind": 5,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "_VALID_HEADER_NAME_RE_STR = re.compile(r\"^[^:\\s][^:\\r\\n]*$\")\n_VALID_HEADER_VALUE_RE_BYTE = re.compile(rb\"^\\S[^\\r\\n]*$|^$\")\n_VALID_HEADER_VALUE_RE_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\ndef to_native_string(string, encoding=\"ascii\"):",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "_VALID_HEADER_VALUE_RE_BYTE",
        "kind": 5,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "_VALID_HEADER_VALUE_RE_BYTE = re.compile(rb\"^\\S[^\\r\\n]*$|^$\")\n_VALID_HEADER_VALUE_RE_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\ndef to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "_VALID_HEADER_VALUE_RE_STR",
        "kind": 5,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "_VALID_HEADER_VALUE_RE_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\ndef to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "_HEADER_VALIDATORS_STR",
        "kind": 5,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\ndef to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where\n    necessary. This assumes ASCII unless told otherwise.",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "_HEADER_VALIDATORS_BYTE",
        "kind": 5,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\nHEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\ndef to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where\n    necessary. This assumes ASCII unless told otherwise.\n    \"\"\"",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "HEADER_VALIDATORS",
        "kind": 5,
        "importPath": "requests._internal_utils",
        "description": "requests._internal_utils",
        "peekOfCode": "HEADER_VALIDATORS = {\n    bytes: _HEADER_VALIDATORS_BYTE,\n    str: _HEADER_VALIDATORS_STR,\n}\ndef to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where\n    necessary. This assumes ASCII unless told otherwise.\n    \"\"\"\n    if isinstance(string, builtin_str):",
        "detail": "requests._internal_utils",
        "documentation": {}
    },
    {
        "label": "BaseAdapter",
        "kind": 6,
        "importPath": "requests.adapters",
        "description": "requests.adapters",
        "peekOfCode": "class BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n    def __init__(self):\n        super().__init__()\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.",
        "detail": "requests.adapters",
        "documentation": {}
    },
    {
        "label": "HTTPAdapter",
        "kind": 6,
        "importPath": "requests.adapters",
        "description": "requests.adapters",
        "peekOfCode": "class HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket",
        "detail": "requests.adapters",
        "documentation": {}
    },
    {
        "label": "DEFAULT_POOLBLOCK",
        "kind": 5,
        "importPath": "requests.adapters",
        "description": "requests.adapters",
        "peekOfCode": "DEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n    def __init__(self):\n        super().__init__()\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None",
        "detail": "requests.adapters",
        "documentation": {}
    },
    {
        "label": "DEFAULT_POOLSIZE",
        "kind": 5,
        "importPath": "requests.adapters",
        "description": "requests.adapters",
        "peekOfCode": "DEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n    def __init__(self):\n        super().__init__()\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):",
        "detail": "requests.adapters",
        "documentation": {}
    },
    {
        "label": "DEFAULT_RETRIES",
        "kind": 5,
        "importPath": "requests.adapters",
        "description": "requests.adapters",
        "peekOfCode": "DEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n    def __init__(self):\n        super().__init__()\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.",
        "detail": "requests.adapters",
        "documentation": {}
    },
    {
        "label": "DEFAULT_POOL_TIMEOUT",
        "kind": 5,
        "importPath": "requests.adapters",
        "description": "requests.adapters",
        "peekOfCode": "DEFAULT_POOL_TIMEOUT = None\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n    def __init__(self):\n        super().__init__()\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.",
        "detail": "requests.adapters",
        "documentation": {}
    },
    {
        "label": "request",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "get",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n    return request(\"get\", url, params=params, **kwargs)",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "options",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n    return request(\"options\", url, **kwargs)\ndef head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "head",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n    kwargs.setdefault(\"allow_redirects\", False)",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "post",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "put",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def put(url, data=None, **kwargs):\n    r\"\"\"Sends a PUT request.\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "patch",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def patch(url, data=None, **kwargs):\n    r\"\"\"Sends a PATCH request.\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "delete",
        "kind": 2,
        "importPath": "requests.api",
        "description": "requests.api",
        "peekOfCode": "def delete(url, **kwargs):\n    r\"\"\"Sends a DELETE request.\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n    return request(\"delete\", url, **kwargs)",
        "detail": "requests.api",
        "documentation": {}
    },
    {
        "label": "AuthBase",
        "kind": 6,
        "importPath": "requests.auth",
        "description": "requests.auth",
        "peekOfCode": "class AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n    def __call__(self, r):\n        raise NotImplementedError(\"Auth hooks must be callable.\")\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n    def __eq__(self, other):",
        "detail": "requests.auth",
        "documentation": {}
    },
    {
        "label": "HTTPBasicAuth",
        "kind": 6,
        "importPath": "requests.auth",
        "description": "requests.auth",
        "peekOfCode": "class HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n    def __eq__(self, other):\n        return all(\n            [\n                self.username == getattr(other, \"username\", None),\n                self.password == getattr(other, \"password\", None),",
        "detail": "requests.auth",
        "documentation": {}
    },
    {
        "label": "HTTPProxyAuth",
        "kind": 6,
        "importPath": "requests.auth",
        "description": "requests.auth",
        "peekOfCode": "class HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n    def __call__(self, r):\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\n        return r\nclass HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password",
        "detail": "requests.auth",
        "documentation": {}
    },
    {
        "label": "HTTPDigestAuth",
        "kind": 6,
        "importPath": "requests.auth",
        "description": "requests.auth",
        "peekOfCode": "class HTTPDigestAuth(AuthBase):\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n        # Keep state in per-thread local storage\n        self._thread_local = threading.local()\n    def init_per_thread_state(self):\n        # Ensure state is initialized just once per-thread\n        if not hasattr(self._thread_local, \"init\"):",
        "detail": "requests.auth",
        "documentation": {}
    },
    {
        "label": "CONTENT_TYPE_FORM_URLENCODED",
        "kind": 5,
        "importPath": "requests.auth",
        "description": "requests.auth",
        "peekOfCode": "CONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility",
        "detail": "requests.auth",
        "documentation": {}
    },
    {
        "label": "CONTENT_TYPE_MULTI_PART",
        "kind": 5,
        "importPath": "requests.auth",
        "description": "requests.auth",
        "peekOfCode": "CONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.",
        "detail": "requests.auth",
        "documentation": {}
    },
    {
        "label": "_ver",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "_ver = sys.version_info\n#: Python 2.x?\nis_py2 = _ver[0] == 2\n#: Python 3.x?\nis_py3 = _ver[0] == 3\n# json/simplejson module import resolution\nhas_simplejson = False\ntry:\n    import simplejson as json\n    has_simplejson = True",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "is_py2",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "is_py2 = _ver[0] == 2\n#: Python 3.x?\nis_py3 = _ver[0] == 3\n# json/simplejson module import resolution\nhas_simplejson = False\ntry:\n    import simplejson as json\n    has_simplejson = True\nexcept ImportError:\n    import json",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "is_py3",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "is_py3 = _ver[0] == 3\n# json/simplejson module import resolution\nhas_simplejson = False\ntry:\n    import simplejson as json\n    has_simplejson = True\nexcept ImportError:\n    import json\nif has_simplejson:\n    from simplejson import JSONDecodeError",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "has_simplejson",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "has_simplejson = False\ntry:\n    import simplejson as json\n    has_simplejson = True\nexcept ImportError:\n    import json\nif has_simplejson:\n    from simplejson import JSONDecodeError\nelse:\n    from json import JSONDecodeError",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "builtin_str",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "builtin_str = str\nstr = str\nbytes = bytes\nbasestring = (str, bytes)\nnumeric_types = (int, float)\ninteger_types = (int,)",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "str",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "str = str\nbytes = bytes\nbasestring = (str, bytes)\nnumeric_types = (int, float)\ninteger_types = (int,)",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "bytes",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "bytes = bytes\nbasestring = (str, bytes)\nnumeric_types = (int, float)\ninteger_types = (int,)",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "basestring",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "basestring = (str, bytes)\nnumeric_types = (int, float)\ninteger_types = (int,)",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "numeric_types",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "numeric_types = (int, float)\ninteger_types = (int,)",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "integer_types",
        "kind": 5,
        "importPath": "requests.compat",
        "description": "requests.compat",
        "peekOfCode": "integer_types = (int,)",
        "detail": "requests.compat",
        "documentation": {}
    },
    {
        "label": "MockRequest",
        "kind": 6,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "class MockRequest:\n    \"\"\"Wraps a `requests.Request` to mimic a `urllib2.Request`.\n    The code in `cookielib.CookieJar` expects this interface in order to correctly\n    manage cookie policies, i.e., determine whether a cookie can be set, given the\n    domains of the request and the cookie.\n    The original request object is read-only. The client is responsible for collecting\n    the new headers via `get_new_headers()` and interpreting them appropriately. You\n    probably want `get_cookie_header`, defined below.\n    \"\"\"\n    def __init__(self, request):",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "MockResponse",
        "kind": 6,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "class MockResponse:\n    \"\"\"Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.\n    ...what? Basically, expose the parsed HTTP headers from the server response\n    the way `cookielib` expects to see them.\n    \"\"\"\n    def __init__(self, headers):\n        \"\"\"Make a MockResponse for `cookielib` to read.\n        :param headers: a httplib.HTTPMessage or analogous carrying the headers\n        \"\"\"\n        self._headers = headers",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "CookieConflictError",
        "kind": 6,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "class CookieConflictError(RuntimeError):\n    \"\"\"There are two cookies that meet the criteria specified in the cookie jar.\n    Use .get and .set and include domain and path args in order to be more specific.\n    \"\"\"\nclass RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n    \"\"\"Compatibility class; is a cookielib.CookieJar, but exposes a dict\n    interface.\n    This is the CookieJar we create by default for requests and sessions that\n    don't specify one, since some clients may expect response.cookies and\n    session.cookies to support dict operations.",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "RequestsCookieJar",
        "kind": 6,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "class RequestsCookieJar(cookielib.CookieJar, MutableMapping):\n    \"\"\"Compatibility class; is a cookielib.CookieJar, but exposes a dict\n    interface.\n    This is the CookieJar we create by default for requests and sessions that\n    don't specify one, since some clients may expect response.cookies and\n    session.cookies to support dict operations.\n    Requests does not use the dict interface internally; it's just for\n    compatibility with external client code. All requests code should work\n    out of the box with externally provided instances of ``CookieJar``, e.g.\n    ``LWPCookieJar`` and ``FileCookieJar``.",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "extract_cookies_to_jar",
        "kind": 2,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "def extract_cookies_to_jar(jar, request, response):\n    \"\"\"Extract the cookies from the response into a CookieJar.\n    :param jar: cookielib.CookieJar (not necessarily a RequestsCookieJar)\n    :param request: our own requests.Request object\n    :param response: urllib3.HTTPResponse object\n    \"\"\"\n    if not (hasattr(response, \"_original_response\") and response._original_response):\n        return\n    # the _original_response field is the wrapped httplib.HTTPResponse object,\n    req = MockRequest(request)",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "get_cookie_header",
        "kind": 2,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "def get_cookie_header(jar, request):\n    \"\"\"\n    Produce an appropriate Cookie header string to be sent with `request`, or None.\n    :rtype: str\n    \"\"\"\n    r = MockRequest(request)\n    jar.add_cookie_header(r)\n    return r.get_new_headers().get(\"Cookie\")\ndef remove_cookie_by_name(cookiejar, name, domain=None, path=None):\n    \"\"\"Unsets a cookie by name, by default over all domains and paths.",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "remove_cookie_by_name",
        "kind": 2,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "def remove_cookie_by_name(cookiejar, name, domain=None, path=None):\n    \"\"\"Unsets a cookie by name, by default over all domains and paths.\n    Wraps CookieJar.clear(), is O(n).\n    \"\"\"\n    clearables = []\n    for cookie in cookiejar:\n        if cookie.name != name:\n            continue\n        if domain is not None and domain != cookie.domain:\n            continue",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "create_cookie",
        "kind": 2,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "def create_cookie(name, value, **kwargs):\n    \"\"\"Make a cookie from underspecified parameters.\n    By default, the pair of `name` and `value` will be set for the domain ''\n    and sent on every request (this is sometimes called a \"supercookie\").\n    \"\"\"\n    result = {\n        \"version\": 0,\n        \"name\": name,\n        \"value\": value,\n        \"port\": None,",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "morsel_to_cookie",
        "kind": 2,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "def morsel_to_cookie(morsel):\n    \"\"\"Convert a Morsel object into a Cookie containing the one k/v pair.\"\"\"\n    expires = None\n    if morsel[\"max-age\"]:\n        try:\n            expires = int(time.time() + int(morsel[\"max-age\"]))\n        except ValueError:\n            raise TypeError(f\"max-age: {morsel['max-age']} must be integer\")\n    elif morsel[\"expires\"]:\n        time_template = \"%a, %d-%b-%Y %H:%M:%S GMT\"",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "cookiejar_from_dict",
        "kind": 2,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "def cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :param cookiejar: (optional) A cookiejar to add the cookies to.\n    :param overwrite: (optional) If False, will not replace cookies\n        already in the jar with new ones.\n    :rtype: CookieJar\n    \"\"\"\n    if cookiejar is None:\n        cookiejar = RequestsCookieJar()",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "merge_cookies",
        "kind": 2,
        "importPath": "requests.cookies",
        "description": "requests.cookies",
        "peekOfCode": "def merge_cookies(cookiejar, cookies):\n    \"\"\"Add cookies to cookiejar and returns a merged CookieJar.\n    :param cookiejar: CookieJar object to add the cookies to.\n    :param cookies: Dictionary or CookieJar object to be added.\n    :rtype: CookieJar\n    \"\"\"\n    if not isinstance(cookiejar, cookielib.CookieJar):\n        raise ValueError(\"You can only merge into CookieJar\")\n    if isinstance(cookies, dict):\n        cookiejar = cookiejar_from_dict(cookies, cookiejar=cookiejar, overwrite=False)",
        "detail": "requests.cookies",
        "documentation": {}
    },
    {
        "label": "RequestException",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class RequestException(IOError):\n    \"\"\"There was an ambiguous exception that occurred while handling your\n    request.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\n        response = kwargs.pop(\"response\", None)\n        self.response = response\n        self.request = kwargs.pop(\"request\", None)\n        if response is not None and not self.request and hasattr(response, \"request\"):",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "InvalidJSONError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class InvalidJSONError(RequestException):\n    \"\"\"A JSON error occurred.\"\"\"\nclass JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n    \"\"\"Couldn't decode the text into json\"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Construct the JSONDecodeError instance first with all\n        args. Then use it's args to construct the IOError so that\n        the json specific args aren't used as IOError specific args\n        and the error message from JSONDecodeError is preserved.",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "JSONDecodeError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n    \"\"\"Couldn't decode the text into json\"\"\"\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Construct the JSONDecodeError instance first with all\n        args. Then use it's args to construct the IOError so that\n        the json specific args aren't used as IOError specific args\n        and the error message from JSONDecodeError is preserved.\n        \"\"\"\n        CompatJSONDecodeError.__init__(self, *args)",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "HTTPError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class HTTPError(RequestException):\n    \"\"\"An HTTP error occurred.\"\"\"\nclass ConnectionError(RequestException):\n    \"\"\"A Connection error occurred.\"\"\"\nclass ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\nclass Timeout(RequestException):\n    \"\"\"The request timed out.",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "ConnectionError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class ConnectionError(RequestException):\n    \"\"\"A Connection error occurred.\"\"\"\nclass ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "ProxyError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "SSLError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"\nclass ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "Timeout",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class Timeout(RequestException):\n    \"\"\"The request timed out.\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"\nclass ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.\n    Requests that produced this error are safe to retry.\n    \"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "ConnectTimeout",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.\n    Requests that produced this error are safe to retry.\n    \"\"\"\nclass ReadTimeout(Timeout):\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\nclass URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "ReadTimeout",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class ReadTimeout(Timeout):\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\nclass URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "URLRequired",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "TooManyRedirects",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "MissingSchema",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "InvalidSchema",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "InvalidURL",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "InvalidHeader",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "InvalidProxyURL",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "ChunkedEncodingError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "ContentDecodingError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n# Warnings\nclass RequestsWarning(Warning):",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "StreamConsumedError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n# Warnings\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\nclass FileModeWarning(RequestsWarning, DeprecationWarning):",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "RetryError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n# Warnings\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\nclass RequestsDependencyWarning(RequestsWarning):",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "UnrewindableBodyError",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n# Warnings\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\nclass RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "RequestsWarning",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\nclass RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "FileModeWarning",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\nclass RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "RequestsDependencyWarning",
        "kind": 6,
        "importPath": "requests.exceptions",
        "description": "requests.exceptions",
        "peekOfCode": "class RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"",
        "detail": "requests.exceptions",
        "documentation": {}
    },
    {
        "label": "info",
        "kind": 2,
        "importPath": "requests.help",
        "description": "requests.help",
        "peekOfCode": "def info():\n    \"\"\"Generate information for a bug report.\"\"\"\n    try:\n        platform_info = {\n            \"system\": platform.system(),\n            \"release\": platform.release(),\n        }\n    except OSError:\n        platform_info = {\n            \"system\": \"Unknown\",",
        "detail": "requests.help",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "requests.help",
        "description": "requests.help",
        "peekOfCode": "def main():\n    \"\"\"Pretty-print the bug information as JSON.\"\"\"\n    print(json.dumps(info(), sort_keys=True, indent=2))\nif __name__ == \"__main__\":\n    main()",
        "detail": "requests.help",
        "documentation": {}
    },
    {
        "label": "default_hooks",
        "kind": 2,
        "importPath": "requests.hooks",
        "description": "requests.hooks",
        "peekOfCode": "def default_hooks():\n    return {event: [] for event in HOOKS}\n# TODO: response is the only one\ndef dispatch_hook(key, hooks, hook_data, **kwargs):\n    \"\"\"Dispatches a hook dictionary on a given piece of data.\"\"\"\n    hooks = hooks or {}\n    hooks = hooks.get(key)\n    if hooks:\n        if hasattr(hooks, \"__call__\"):\n            hooks = [hooks]",
        "detail": "requests.hooks",
        "documentation": {}
    },
    {
        "label": "dispatch_hook",
        "kind": 2,
        "importPath": "requests.hooks",
        "description": "requests.hooks",
        "peekOfCode": "def dispatch_hook(key, hooks, hook_data, **kwargs):\n    \"\"\"Dispatches a hook dictionary on a given piece of data.\"\"\"\n    hooks = hooks or {}\n    hooks = hooks.get(key)\n    if hooks:\n        if hasattr(hooks, \"__call__\"):\n            hooks = [hooks]\n        for hook in hooks:\n            _hook_data = hook(hook_data, **kwargs)\n            if _hook_data is not None:",
        "detail": "requests.hooks",
        "documentation": {}
    },
    {
        "label": "HOOKS",
        "kind": 5,
        "importPath": "requests.hooks",
        "description": "requests.hooks",
        "peekOfCode": "HOOKS = [\"response\"]\ndef default_hooks():\n    return {event: [] for event in HOOKS}\n# TODO: response is the only one\ndef dispatch_hook(key, hooks, hook_data, **kwargs):\n    \"\"\"Dispatches a hook dictionary on a given piece of data.\"\"\"\n    hooks = hooks or {}\n    hooks = hooks.get(key)\n    if hooks:\n        if hasattr(hooks, \"__call__\"):",
        "detail": "requests.hooks",
        "documentation": {}
    },
    {
        "label": "RequestEncodingMixin",
        "kind": 6,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "class RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n        url = []\n        p = urlsplit(self.url)\n        path = p.path\n        if not path:\n            path = \"/\"\n        url.append(path)",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "RequestHooksMixin",
        "kind": 6,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "class RequestHooksMixin:\n    def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n        if event not in self.hooks:\n            raise ValueError(f'Unsupported event specified, with event name \"{event}\"')\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, \"__iter__\"):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\n    def deregister_hook(self, event, hook):",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "Request",
        "kind": 6,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "class Request(RequestHooksMixin):\n    \"\"\"A user-created :class:`Request <Request>` object.\n    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n    :param method: HTTP method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "PreparedRequest",
        "kind": 6,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n    Instances are generated from a :class:`Request <Request>` object, and\n    should not be instantiated manually; doing so may produce undesirable\n    effects.\n    Usage::\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "Response",
        "kind": 6,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "class Response:\n    \"\"\"The :class:`Response <Response>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n    __attrs__ = [\n        \"_content\",\n        \"status_code\",\n        \"headers\",\n        \"url\",\n        \"history\",",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "REDIRECT_STATI",
        "kind": 5,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "REDIRECT_STATI = (\n    codes.moved,  # 301\n    codes.found,  # 302\n    codes.other,  # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "DEFAULT_REDIRECT_LIMIT",
        "kind": 5,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "DEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n        url = []\n        p = urlsplit(self.url)\n        path = p.path",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "CONTENT_CHUNK_SIZE",
        "kind": 5,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "CONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n        url = []\n        p = urlsplit(self.url)\n        path = p.path\n        if not path:",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "ITER_CHUNK_SIZE",
        "kind": 5,
        "importPath": "requests.models",
        "description": "requests.models",
        "peekOfCode": "ITER_CHUNK_SIZE = 512\nclass RequestEncodingMixin:\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n        url = []\n        p = urlsplit(self.url)\n        path = p.path\n        if not path:\n            path = \"/\"",
        "detail": "requests.models",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "requests.packages",
        "description": "requests.packages",
        "peekOfCode": "target = chardet.__name__\nfor mod in list(sys.modules):\n    if mod == target or mod.startswith(f\"{target}.\"):\n        target = target.replace(target, \"chardet\")\n        sys.modules[f\"requests.packages.{target}\"] = sys.modules[mod]\n# Kinda cool, though, right?",
        "detail": "requests.packages",
        "documentation": {}
    },
    {
        "label": "SessionRedirectMixin",
        "kind": 6,
        "importPath": "requests.sessions",
        "description": "requests.sessions",
        "peekOfCode": "class SessionRedirectMixin:\n    def get_redirect_target(self, resp):\n        \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\n        # Due to the nature of how requests processes redirects this method will\n        # be called at least once upon the original response and at least twice\n        # on each subsequent redirect response (if any).\n        # If a custom mixin is used to handle this logic, it may be advantageous\n        # to cache the redirect location onto the response object as a private\n        # attribute.\n        if resp.is_redirect:",
        "detail": "requests.sessions",
        "documentation": {}
    },
    {
        "label": "Session",
        "kind": 6,
        "importPath": "requests.sessions",
        "description": "requests.sessions",
        "peekOfCode": "class Session(SessionRedirectMixin):\n    \"\"\"A Requests session.\n    Provides cookie persistence, connection-pooling, and configuration.\n    Basic Usage::\n      >>> import requests\n      >>> s = requests.Session()\n      >>> s.get('https://httpbin.org/get')\n      <Response [200]>\n    Or as a context manager::\n      >>> with requests.Session() as s:",
        "detail": "requests.sessions",
        "documentation": {}
    },
    {
        "label": "merge_setting",
        "kind": 2,
        "importPath": "requests.sessions",
        "description": "requests.sessions",
        "peekOfCode": "def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n    if session_setting is None:\n        return request_setting\n    if request_setting is None:\n        return session_setting\n    # Bypass if not a dictionary (e.g. verify)",
        "detail": "requests.sessions",
        "documentation": {}
    },
    {
        "label": "merge_hooks",
        "kind": 2,
        "importPath": "requests.sessions",
        "description": "requests.sessions",
        "peekOfCode": "def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n    \"\"\"Properly merges both requests and session hooks.\n    This is necessary because when request_hooks == {'response': []}, the\n    merge breaks Session hooks entirely.\n    \"\"\"\n    if session_hooks is None or session_hooks.get(\"response\") == []:\n        return request_hooks\n    if request_hooks is None or request_hooks.get(\"response\") == []:\n        return session_hooks\n    return merge_setting(request_hooks, session_hooks, dict_class)",
        "detail": "requests.sessions",
        "documentation": {}
    },
    {
        "label": "session",
        "kind": 2,
        "importPath": "requests.sessions",
        "description": "requests.sessions",
        "peekOfCode": "def session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n    .. deprecated:: 1.0.0\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n    :rtype: Session\n    \"\"\"\n    return Session()",
        "detail": "requests.sessions",
        "documentation": {}
    },
    {
        "label": "_codes",
        "kind": 5,
        "importPath": "requests.status_codes",
        "description": "requests.status_codes",
        "peekOfCode": "_codes = {\n    # Informational.\n    100: (\"continue\",),\n    101: (\"switching_protocols\",),\n    102: (\"processing\",),\n    103: (\"checkpoint\",),\n    122: (\"uri_too_long\", \"request_uri_too_long\"),\n    200: (\"ok\", \"okay\", \"all_ok\", \"all_okay\", \"all_good\", \"\\\\o/\", \"✓\"),\n    201: (\"created\",),\n    202: (\"accepted\",),",
        "detail": "requests.status_codes",
        "documentation": {}
    },
    {
        "label": "codes",
        "kind": 5,
        "importPath": "requests.status_codes",
        "description": "requests.status_codes",
        "peekOfCode": "codes = LookupDict(name=\"status_codes\")\ndef _init():\n    for code, titles in _codes.items():\n        for title in titles:\n            setattr(codes, title, code)\n            if not title.startswith((\"\\\\\", \"/\")):\n                setattr(codes, title.upper(), code)\n    def doc(code):\n        names = \", \".join(f\"``{n}``\" for n in _codes[code])\n        return \"* %d: %s\" % (code, names)",
        "detail": "requests.status_codes",
        "documentation": {}
    },
    {
        "label": "CaseInsensitiveDict",
        "kind": 6,
        "importPath": "requests.structures",
        "description": "requests.structures",
        "peekOfCode": "class CaseInsensitiveDict(MutableMapping):\n    \"\"\"A case-insensitive ``dict``-like object.\n    Implements all methods and operations of\n    ``MutableMapping`` as well as dict's ``copy``. Also\n    provides ``lower_items``.\n    All keys are expected to be strings. The structure remembers the\n    case of the last key to be set, and ``iter(instance)``,\n    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``\n    will contain case-sensitive keys. However, querying and contains\n    testing is case insensitive::",
        "detail": "requests.structures",
        "documentation": {}
    },
    {
        "label": "LookupDict",
        "kind": 6,
        "importPath": "requests.structures",
        "description": "requests.structures",
        "peekOfCode": "class LookupDict(dict):\n    \"\"\"Dictionary lookup object.\"\"\"\n    def __init__(self, name=None):\n        self.name = name\n        super().__init__()\n    def __repr__(self):\n        return f\"<lookup '{self.name}'>\"\n    def __getitem__(self, key):\n        # We allow fall-through here, so values default to None\n        return self.__dict__.get(key, None)",
        "detail": "requests.structures",
        "documentation": {}
    },
    {
        "label": "dict_to_sequence",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n    if hasattr(d, \"items\"):\n        d = d.items()\n    return d\ndef super_len(o):\n    total_length = None\n    current_position = 0\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "super_len",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def super_len(o):\n    total_length = None\n    current_position = 0\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "get_netrc_auth",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n    try:\n        from netrc import NetrcParseError, netrc\n        netrc_path = None",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "guess_filename",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "extract_zipped_paths",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "atomic_open",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "from_key_val_list",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n    ::\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "to_key_val_list",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n    ::\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "parse_list_header",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n    The return value is a standard :class:`list`:\n    >>> parse_list_header('token, \"quoted value\"')",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "parse_dict_header",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n    If there is no value for a key it will be `None`:\n    >>> parse_dict_header('key_without_value')",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "unquote_header_value",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "dict_from_cookiejar",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n    cookie_dict = {}\n    for cookie in cj:\n        cookie_dict[cookie.name] = cookie.value\n    return cookie_dict\ndef add_dict_to_cookiejar(cj, cookie_dict):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "add_dict_to_cookiejar",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n    return cookiejar_from_dict(cookie_dict, cj)\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n    :param content: bytestring to extract encodings from.",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "get_encodings_from_content",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "get_encoding_from_headers",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n    content_type = headers.get(\"content-type\")\n    if not content_type:\n        return None\n    content_type, params = _parse_content_type_header(content_type)\n    if \"charset\" in params:",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "stream_decode_response_unicode",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n    if r.encoding is None:\n        yield from iterator\n        return\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "iter_slices",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "get_unicode_from_response",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n    :param r: Response object to get unicode content from.\n    Tried:\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "unquote_unreserved",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "requote_uri",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "address_in_network",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "dotted_netmask",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n    Example: if mask is 24 function returns 255.255.255.0\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "is_ipv4_address",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\ndef is_valid_cidr(string_network):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "is_valid_cidr",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "set_environ",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "should_bypass_proxies",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n    :rtype: bool\n    \"\"\"\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n    # First check whether no_proxy is defined. If it is, check that the URL",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "get_environ_proxies",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\ndef select_proxy(url, proxies):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "select_proxy",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n    proxy_keys = [",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "resolve_proxies",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such a NO_PROXY to strip proxy configurations.\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "default_user_agent",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "default_headers",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "parse_header_links",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n    :rtype: list\n    \"\"\"\n    links = []\n    replace_chars = \" '\\\"\"\n    value = value.strip(replace_chars)\n    if not value:\n        return links",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "guess_json_utf",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "prepend_scheme_if_needed",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "get_auth_from_url",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "check_header_validity",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def check_header_validity(header):\n    \"\"\"Verifies that header parts don't contain leading whitespace\n    reserved characters, or return characters.\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n    _validate_header_part(header, name, 0)\n    _validate_header_part(header, value, 1)\ndef _validate_header_part(header, header_part, header_validator_index):\n    if isinstance(header_part, str):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "urldefragauth",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n    netloc = netloc.rsplit(\"@\", 1)[-1]",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "rewind_body",
        "kind": 2,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "def rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "NETRC_FILES",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "NETRC_FILES = (\".netrc\", \"_netrc\")\nDEFAULT_CA_BUNDLE_PATH = certs.where()\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n    def proxy_bypass_registry(host):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CA_BUNDLE_PATH",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "DEFAULT_CA_BUNDLE_PATH = certs.where()\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n    def proxy_bypass_registry(host):\n        try:",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_PORTS",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "DEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n    def proxy_bypass_registry(host):\n        try:\n            import winreg",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_ACCEPT_ENCODING",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "DEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "UNRESERVED_SET",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "UNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "_null",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "_null2",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "_null2 = _null * 2\n_null3 = _null * 3\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "_null3",
        "kind": 5,
        "importPath": "requests.utils",
        "description": "requests.utils",
        "peekOfCode": "_null3 = _null * 3\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):",
        "detail": "requests.utils",
        "documentation": {}
    },
    {
        "label": "needs_sphinx",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "needs_sphinx = \"1.0\"\n# Add any Sphinx extension module names here, as strings. They can be extensions\n# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.\nextensions = [\"sphinx.ext.intersphinx\"]\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n# The suffix of source filenames.\nsource_suffix = \".rst\"\n# The encoding of source files.\n#source_encoding = \"utf-8-sig\"",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "extensions",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "extensions = [\"sphinx.ext.intersphinx\"]\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n# The suffix of source filenames.\nsource_suffix = \".rst\"\n# The encoding of source files.\n#source_encoding = \"utf-8-sig\"\n# The master toctree document.\nmaster_doc = \"index\"\n# General information about the project.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "templates_path",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "templates_path = [\"_templates\"]\n# The suffix of source filenames.\nsource_suffix = \".rst\"\n# The encoding of source files.\n#source_encoding = \"utf-8-sig\"\n# The master toctree document.\nmaster_doc = \"index\"\n# General information about the project.\nproject = u\"six\"\ncopyright = u\"2010-2020, Benjamin Peterson\"",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "source_suffix",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "source_suffix = \".rst\"\n# The encoding of source files.\n#source_encoding = \"utf-8-sig\"\n# The master toctree document.\nmaster_doc = \"index\"\n# General information about the project.\nproject = u\"six\"\ncopyright = u\"2010-2020, Benjamin Peterson\"\nsys.path.append(os.path.abspath(os.path.join(\".\", \"..\")))\nfrom six import __version__ as six_version",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#source_encoding",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#source_encoding = \"utf-8-sig\"\n# The master toctree document.\nmaster_doc = \"index\"\n# General information about the project.\nproject = u\"six\"\ncopyright = u\"2010-2020, Benjamin Peterson\"\nsys.path.append(os.path.abspath(os.path.join(\".\", \"..\")))\nfrom six import __version__ as six_version\nsys.path.pop()\n# The version info for the project you're documenting, acts as replacement for",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "master_doc",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "master_doc = \"index\"\n# General information about the project.\nproject = u\"six\"\ncopyright = u\"2010-2020, Benjamin Peterson\"\nsys.path.append(os.path.abspath(os.path.join(\".\", \"..\")))\nfrom six import __version__ as six_version\nsys.path.pop()\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "project",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "project = u\"six\"\ncopyright = u\"2010-2020, Benjamin Peterson\"\nsys.path.append(os.path.abspath(os.path.join(\".\", \"..\")))\nfrom six import __version__ as six_version\nsys.path.pop()\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "copyright",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "copyright = u\"2010-2020, Benjamin Peterson\"\nsys.path.append(os.path.abspath(os.path.join(\".\", \"..\")))\nfrom six import __version__ as six_version\nsys.path.pop()\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = six_version[:-2]",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "version = six_version[:-2]\n# The full version, including alpha/beta/rc tags.\nrelease = six_version\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = ''\n# Else, today_fmt is used as the format for a strftime call.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "release",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "release = six_version\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#language = None\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = ''\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = '%B %d, %Y'\n# List of patterns, relative to source directory, that match files and",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#language",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#language = None\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n#today = ''\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = '%B %d, %Y'\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\"_build\"]\n# The reST default role (used for this markup: `text`) to use for all documents.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#today",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#today = ''\n# Else, today_fmt is used as the format for a strftime call.\n#today_fmt = '%B %d, %Y'\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\"_build\"]\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#today_fmt",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#today_fmt = '%B %d, %Y'\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\"_build\"]\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "exclude_patterns",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "exclude_patterns = [\"_build\"]\n# The reST default role (used for this markup: `text`) to use for all documents.\n#default_role = None\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#default_role",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#default_role = None\n# If true, '()' will be appended to :func: etc. cross-reference text.\n#add_function_parentheses = True\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n# The name of the Pygments (syntax highlighting) style to use.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#add_function_parentheses",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#add_function_parentheses = True\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\n#add_module_names = True\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"sphinx\"\n# A list of ignored prefixes for module index sorting.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#add_module_names",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#add_module_names = True\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n#show_authors = False\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"sphinx\"\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n# -- Options for HTML output ---------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#show_authors",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#show_authors = False\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"sphinx\"\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n# -- Options for HTML output ---------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"default\"\n# Theme options are theme-specific and customize the look and feel of a theme",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "pygments_style",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "pygments_style = \"sphinx\"\n# A list of ignored prefixes for module index sorting.\n#modindex_common_prefix = []\n# -- Options for HTML output ---------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"default\"\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#modindex_common_prefix",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#modindex_common_prefix = []\n# -- Options for HTML output ---------------------------------------------------\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"default\"\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n# Add any paths that contain custom themes here, relative to this directory.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "html_theme",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "html_theme = \"default\"\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\n#html_theme_options = {}\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n#html_title = None",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_theme_options",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_theme_options = {}\n# Add any paths that contain custom themes here, relative to this directory.\n#html_theme_path = []\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n#html_title = None\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_theme_path",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_theme_path = []\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n#html_title = None\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n# The name of an image file (within the static path) to use as favicon of the",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_title",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_title = None\n# A shorter title for the navigation bar.  Default is the same as html_title.\n#html_short_title = None\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_short_title",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_short_title = None\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n#html_logo = None\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_logo",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_logo = None\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n#html_favicon = None\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_favicon",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_favicon = None\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = '%b %d, %Y'\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "html_static_path",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "html_static_path = [\"_static\"]\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n#html_last_updated_fmt = '%b %d, %Y'\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n# Additional templates that should be rendered to pages, maps page names to",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_last_updated_fmt",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_last_updated_fmt = '%b %d, %Y'\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\n#html_use_smartypants = True\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n# If false, no module index is generated.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_use_smartypants",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_use_smartypants = True\n# Custom sidebar templates, maps document names to template names.\n#html_sidebars = {}\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n# If false, no module index is generated.\n#html_domain_indices = True\n# If false, no index is generated.\n#html_use_index = True",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_sidebars",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_sidebars = {}\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n#html_additional_pages = {}\n# If false, no module index is generated.\n#html_domain_indices = True\n# If false, no index is generated.\n#html_use_index = True\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_additional_pages",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_additional_pages = {}\n# If false, no module index is generated.\n#html_domain_indices = True\n# If false, no index is generated.\n#html_use_index = True\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_domain_indices",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_domain_indices = True\n# If false, no index is generated.\n#html_use_index = True\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_use_index",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_use_index = True\n# If true, the index is split into individual pages for each letter.\n#html_split_index = False\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n# If true, an OpenSearch description file will be output, and all pages will",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_split_index",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_split_index = False\n# If true, links to the reST sources are added to the pages.\n#html_show_sourcelink = True\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_show_sourcelink",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_show_sourcelink = True\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\n#html_show_sphinx = True\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = ''\n# If nonempty, this is the file name suffix for HTML files (e.g. \".xhtml\").",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_show_sphinx",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_show_sphinx = True\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n#html_show_copyright = True\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = ''\n# If nonempty, this is the file name suffix for HTML files (e.g. \".xhtml\").\n#html_file_suffix = ''\n# Output file base name for HTML help builder.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_show_copyright",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_show_copyright = True\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n#html_use_opensearch = ''\n# If nonempty, this is the file name suffix for HTML files (e.g. \".xhtml\").\n#html_file_suffix = ''\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'sixdoc'\n# -- Options for LaTeX output --------------------------------------------------",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_use_opensearch",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_use_opensearch = ''\n# If nonempty, this is the file name suffix for HTML files (e.g. \".xhtml\").\n#html_file_suffix = ''\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'sixdoc'\n# -- Options for LaTeX output --------------------------------------------------\n# The paper size ('letter' or 'a4').\n#latex_paper_size = 'letter'\n# The font size ('10pt', '11pt' or '12pt').\n#latex_font_size = '10pt'",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#html_file_suffix",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#html_file_suffix = ''\n# Output file base name for HTML help builder.\nhtmlhelp_basename = 'sixdoc'\n# -- Options for LaTeX output --------------------------------------------------\n# The paper size ('letter' or 'a4').\n#latex_paper_size = 'letter'\n# The font size ('10pt', '11pt' or '12pt').\n#latex_font_size = '10pt'\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "htmlhelp_basename",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "htmlhelp_basename = 'sixdoc'\n# -- Options for LaTeX output --------------------------------------------------\n# The paper size ('letter' or 'a4').\n#latex_paper_size = 'letter'\n# The font size ('10pt', '11pt' or '12pt').\n#latex_font_size = '10pt'\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  (\"index\", \"six.tex\", u\"six Documentation\",",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_paper_size",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_paper_size = 'letter'\n# The font size ('10pt', '11pt' or '12pt').\n#latex_font_size = '10pt'\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  (\"index\", \"six.tex\", u\"six Documentation\",\n   u\"Benjamin Peterson\", \"manual\"),\n]\n# The name of an image file (relative to this directory) to place at the top of",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_font_size",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_font_size = '10pt'\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title, author, documentclass [howto/manual]).\nlatex_documents = [\n  (\"index\", \"six.tex\", u\"six Documentation\",\n   u\"Benjamin Peterson\", \"manual\"),\n]\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "latex_documents",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "latex_documents = [\n  (\"index\", \"six.tex\", u\"six Documentation\",\n   u\"Benjamin Peterson\", \"manual\"),\n]\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n#latex_logo = None\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_logo",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_logo = None\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n#latex_use_parts = False\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n# Additional stuff for the LaTeX preamble.\n#latex_preamble = ''",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_use_parts",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_use_parts = False\n# If true, show page references after internal links.\n#latex_show_pagerefs = False\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n# Additional stuff for the LaTeX preamble.\n#latex_preamble = ''\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n# If false, no module index is generated.",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_show_pagerefs",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_show_pagerefs = False\n# If true, show URL addresses after external links.\n#latex_show_urls = False\n# Additional stuff for the LaTeX preamble.\n#latex_preamble = ''\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n# If false, no module index is generated.\n#latex_domain_indices = True\n# -- Options for manual page output --------------------------------------------",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_show_urls",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_show_urls = False\n# Additional stuff for the LaTeX preamble.\n#latex_preamble = ''\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n# If false, no module index is generated.\n#latex_domain_indices = True\n# -- Options for manual page output --------------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_preamble",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_preamble = ''\n# Documents to append as an appendix to all manuals.\n#latex_appendices = []\n# If false, no module index is generated.\n#latex_domain_indices = True\n# -- Options for manual page output --------------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\"index\", \"six\", u\"six Documentation\",",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_appendices",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_appendices = []\n# If false, no module index is generated.\n#latex_domain_indices = True\n# -- Options for manual page output --------------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\"index\", \"six\", u\"six Documentation\",\n     [u\"Benjamin Peterson\"], 1)\n]",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "#latex_domain_indices",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "#latex_domain_indices = True\n# -- Options for manual page output --------------------------------------------\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [\n    (\"index\", \"six\", u\"six Documentation\",\n     [u\"Benjamin Peterson\"], 1)\n]\n# -- Intersphinx ---------------------------------------------------------------\nintersphinx_mapping = {\"py2\" : (\"https://docs.python.org/2/\", None),",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "man_pages",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "man_pages = [\n    (\"index\", \"six\", u\"six Documentation\",\n     [u\"Benjamin Peterson\"], 1)\n]\n# -- Intersphinx ---------------------------------------------------------------\nintersphinx_mapping = {\"py2\" : (\"https://docs.python.org/2/\", None),\n                       \"py3\" : (\"https://docs.python.org/3/\", None)}",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "intersphinx_mapping",
        "kind": 5,
        "importPath": "six.documentation.conf",
        "description": "six.documentation.conf",
        "peekOfCode": "intersphinx_mapping = {\"py2\" : (\"https://docs.python.org/2/\", None),\n                       \"py3\" : (\"https://docs.python.org/3/\", None)}",
        "detail": "six.documentation.conf",
        "documentation": {}
    },
    {
        "label": "six_classifiers",
        "kind": 5,
        "importPath": "six.setup",
        "description": "six.setup",
        "peekOfCode": "six_classifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Programming Language :: Python :: 2\",\n    \"Programming Language :: Python :: 3\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Topic :: Software Development :: Libraries\",\n    \"Topic :: Utilities\",\n]\nwith open(\"README.rst\", \"r\") as fp:",
        "detail": "six.setup",
        "documentation": {}
    },
    {
        "label": "_LazyDescr",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class _LazyDescr(object):\n    def __init__(self, name):\n        self.name = name\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result)  # Invokes __set__.\n        try:\n            # This is a bit ugly, but it avoids running this again by\n            # removing this descriptor.\n            delattr(obj.__class__, self.name)",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "MovedModule",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class MovedModule(_LazyDescr):\n    def __init__(self, name, old, new=None):\n        super(MovedModule, self).__init__(name)\n        if PY3:\n            if new is None:\n                new = name\n            self.mod = new\n        else:\n            self.mod = old\n    def _resolve(self):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_LazyModule",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class _LazyModule(types.ModuleType):\n    def __init__(self, name):\n        super(_LazyModule, self).__init__(name)\n        self.__doc__ = self.__class__.__doc__\n    def __dir__(self):\n        attrs = [\"__doc__\", \"__name__\"]\n        attrs += [attr.name for attr in self._moved_attributes]\n        return attrs\n    # Subclasses should override this\n    _moved_attributes = []",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "MovedAttribute",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class MovedAttribute(_LazyDescr):\n    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):\n        super(MovedAttribute, self).__init__(name)\n        if PY3:\n            if new_mod is None:\n                new_mod = name\n            self.mod = new_mod\n            if new_attr is None:\n                if old_attr is None:\n                    new_attr = name",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_SixMetaPathImporter",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class _SixMetaPathImporter(object):\n    \"\"\"\n    A meta path importer to import six.moves and its submodules.\n    This class implements a PEP302 finder and loader. It should be compatible\n    with Python 2.5 and all existing versions of Python3\n    \"\"\"\n    def __init__(self, six_module_name):\n        self.name = six_module_name\n        self.known_modules = {}\n    def _add_module(self, mod, *fullnames):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_MovedItems",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class _MovedItems(_LazyModule):\n    \"\"\"Lazy loading of moved objects\"\"\"\n    __path__ = []  # mark as package\n_moved_attributes = [\n    MovedAttribute(\"cStringIO\", \"cStringIO\", \"io\", \"StringIO\"),\n    MovedAttribute(\"filter\", \"itertools\", \"builtins\", \"ifilter\", \"filter\"),\n    MovedAttribute(\"filterfalse\", \"itertools\", \"itertools\", \"ifilterfalse\", \"filterfalse\"),\n    MovedAttribute(\"input\", \"__builtin__\", \"builtins\", \"raw_input\", \"input\"),\n    MovedAttribute(\"intern\", \"__builtin__\", \"sys\"),\n    MovedAttribute(\"map\", \"itertools\", \"builtins\", \"imap\", \"map\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_parse",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class Module_six_moves_urllib_parse(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_parse\"\"\"\n_urllib_parse_moved_attributes = [\n    MovedAttribute(\"ParseResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"SplitResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qs\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qsl\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urldefrag\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urljoin\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlparse\", \"urlparse\", \"urllib.parse\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_error",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class Module_six_moves_urllib_error(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_error\"\"\"\n_urllib_error_moved_attributes = [\n    MovedAttribute(\"URLError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"HTTPError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"ContentTooShortError\", \"urllib\", \"urllib.error\"),\n]\nfor attr in _urllib_error_moved_attributes:\n    setattr(Module_six_moves_urllib_error, attr.name, attr)\ndel attr",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_request",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class Module_six_moves_urllib_request(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_request\"\"\"\n_urllib_request_moved_attributes = [\n    MovedAttribute(\"urlopen\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"install_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"build_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"pathname2url\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"url2pathname\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"getproxies\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"Request\", \"urllib2\", \"urllib.request\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_response",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class Module_six_moves_urllib_response(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_response\"\"\"\n_urllib_response_moved_attributes = [\n    MovedAttribute(\"addbase\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addclosehook\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfo\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfourl\", \"urllib\", \"urllib.response\"),\n]\nfor attr in _urllib_response_moved_attributes:\n    setattr(Module_six_moves_urllib_response, attr.name, attr)",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_robotparser",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class Module_six_moves_urllib_robotparser(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_robotparser\"\"\"\n_urllib_robotparser_moved_attributes = [\n    MovedAttribute(\"RobotFileParser\", \"robotparser\", \"urllib.robotparser\"),\n]\nfor attr in _urllib_robotparser_moved_attributes:\n    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\ndel attr\nModule_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib",
        "kind": 6,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "class Module_six_moves_urllib(types.ModuleType):\n    \"\"\"Create a six.moves.urllib namespace that resembles the Python 3 namespace\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n    def __dir__(self):\n        return ['parse', 'error', 'request', 'response', 'robotparser']",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "add_move",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def add_move(move):\n    \"\"\"Add an item to six.moves.\"\"\"\n    setattr(_MovedItems, move.name, move)\ndef remove_move(name):\n    \"\"\"Remove item from six.moves.\"\"\"\n    try:\n        delattr(_MovedItems, name)\n    except AttributeError:\n        try:\n            del moves.__dict__[name]",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "remove_move",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def remove_move(name):\n    \"\"\"Remove item from six.moves.\"\"\"\n    try:\n        delattr(_MovedItems, name)\n    except AttributeError:\n        try:\n            del moves.__dict__[name]\n        except KeyError:\n            raise AttributeError(\"no such move, %r\" % (name,))\nif PY3:",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "assertCountEqual",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def assertCountEqual(self, *args, **kwargs):\n    return getattr(self, _assertCountEqual)(*args, **kwargs)\ndef assertRaisesRegex(self, *args, **kwargs):\n    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\ndef assertRegex(self, *args, **kwargs):\n    return getattr(self, _assertRegex)(*args, **kwargs)\ndef assertNotRegex(self, *args, **kwargs):\n    return getattr(self, _assertNotRegex)(*args, **kwargs)\nif PY3:\n    exec_ = getattr(moves.builtins, \"exec\")",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "assertRaisesRegex",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def assertRaisesRegex(self, *args, **kwargs):\n    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\ndef assertRegex(self, *args, **kwargs):\n    return getattr(self, _assertRegex)(*args, **kwargs)\ndef assertNotRegex(self, *args, **kwargs):\n    return getattr(self, _assertNotRegex)(*args, **kwargs)\nif PY3:\n    exec_ = getattr(moves.builtins, \"exec\")\n    def reraise(tp, value, tb=None):\n        try:",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "assertRegex",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def assertRegex(self, *args, **kwargs):\n    return getattr(self, _assertRegex)(*args, **kwargs)\ndef assertNotRegex(self, *args, **kwargs):\n    return getattr(self, _assertNotRegex)(*args, **kwargs)\nif PY3:\n    exec_ = getattr(moves.builtins, \"exec\")\n    def reraise(tp, value, tb=None):\n        try:\n            if value is None:\n                value = tp()",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "assertNotRegex",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def assertNotRegex(self, *args, **kwargs):\n    return getattr(self, _assertNotRegex)(*args, **kwargs)\nif PY3:\n    exec_ = getattr(moves.builtins, \"exec\")\n    def reraise(tp, value, tb=None):\n        try:\n            if value is None:\n                value = tp()\n            if value.__traceback__ is not tb:\n                raise value.with_traceback(tb)",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "with_metaclass",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def with_metaclass(meta, *bases):\n    \"\"\"Create a base class with a metaclass.\"\"\"\n    # This requires a bit of explanation: the basic idea is to make a dummy\n    # metaclass for one level of class instantiation that replaces itself with\n    # the actual metaclass.\n    class metaclass(type):\n        def __new__(cls, name, this_bases, d):\n            if sys.version_info[:2] >= (3, 7):\n                # This version introduced PEP 560 that requires a bit\n                # of extra care (we mimic what is done by __build_class__).",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "add_metaclass",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def add_metaclass(metaclass):\n    \"\"\"Class decorator for creating a class with a metaclass.\"\"\"\n    def wrapper(cls):\n        orig_vars = cls.__dict__.copy()\n        slots = orig_vars.get('__slots__')\n        if slots is not None:\n            if isinstance(slots, str):\n                slots = [slots]\n            for slots_var in slots:\n                orig_vars.pop(slots_var)",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "ensure_binary",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def ensure_binary(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce **s** to six.binary_type.\n    For Python 2:\n      - `unicode` -> encoded to `str`\n      - `str` -> `str`\n    For Python 3:\n      - `str` -> encoded to `bytes`\n      - `bytes` -> `bytes`\n    \"\"\"\n    if isinstance(s, binary_type):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "ensure_str",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def ensure_str(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce *s* to `str`.\n    For Python 2:\n      - `unicode` -> encoded to `str`\n      - `str` -> `str`\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`\n    \"\"\"\n    # Optimization: Fast return for the common case.",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "ensure_text",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def ensure_text(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce *s* to six.text_type.\n    For Python 2:\n      - `unicode` -> `unicode`\n      - `str` -> `unicode`\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`\n    \"\"\"\n    if isinstance(s, binary_type):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "python_2_unicode_compatible",
        "kind": 2,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "def python_2_unicode_compatible(klass):\n    \"\"\"\n    A class decorator that defines __unicode__ and __str__ methods under Python 2.\n    Under Python 3 it does nothing.\n    To support Python 2 and 3 with a single code base, define a __str__ method\n    returning text and apply this decorator to the class.\n    \"\"\"\n    if PY2:\n        if '__str__' not in klass.__dict__:\n            raise ValueError(\"@python_2_unicode_compatible cannot be applied \"",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "__author__",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "__author__ = \"Benjamin Peterson <benjamin@python.org>\"\n__version__ = \"1.16.0\"\n# Useful for very coarse version differentiation.\nPY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "__version__",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "__version__ = \"1.16.0\"\n# Useful for very coarse version differentiation.\nPY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "PY2",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "PY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str\n    binary_type = bytes\n    MAXSIZE = sys.maxsize",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "PY3",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "PY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str\n    binary_type = bytes\n    MAXSIZE = sys.maxsize\nelse:",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "PY34",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "PY34 = sys.version_info[0:2] >= (3, 4)\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str\n    binary_type = bytes\n    MAXSIZE = sys.maxsize\nelse:\n    string_types = basestring,",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_importer",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_importer = _SixMetaPathImporter(__name__)\nclass _MovedItems(_LazyModule):\n    \"\"\"Lazy loading of moved objects\"\"\"\n    __path__ = []  # mark as package\n_moved_attributes = [\n    MovedAttribute(\"cStringIO\", \"cStringIO\", \"io\", \"StringIO\"),\n    MovedAttribute(\"filter\", \"itertools\", \"builtins\", \"ifilter\", \"filter\"),\n    MovedAttribute(\"filterfalse\", \"itertools\", \"itertools\", \"ifilterfalse\", \"filterfalse\"),\n    MovedAttribute(\"input\", \"__builtin__\", \"builtins\", \"raw_input\", \"input\"),\n    MovedAttribute(\"intern\", \"__builtin__\", \"sys\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_moved_attributes = [\n    MovedAttribute(\"cStringIO\", \"cStringIO\", \"io\", \"StringIO\"),\n    MovedAttribute(\"filter\", \"itertools\", \"builtins\", \"ifilter\", \"filter\"),\n    MovedAttribute(\"filterfalse\", \"itertools\", \"itertools\", \"ifilterfalse\", \"filterfalse\"),\n    MovedAttribute(\"input\", \"__builtin__\", \"builtins\", \"raw_input\", \"input\"),\n    MovedAttribute(\"intern\", \"__builtin__\", \"sys\"),\n    MovedAttribute(\"map\", \"itertools\", \"builtins\", \"imap\", \"map\"),\n    MovedAttribute(\"getcwd\", \"os\", \"os\", \"getcwdu\", \"getcwd\"),\n    MovedAttribute(\"getcwdb\", \"os\", \"os\", \"getcwd\", \"getcwdb\"),\n    MovedAttribute(\"getoutput\", \"commands\", \"subprocess\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_MovedItems._moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_MovedItems._moved_attributes = _moved_attributes\nmoves = _MovedItems(__name__ + \".moves\")\n_importer._add_module(moves, \"moves\")\nclass Module_six_moves_urllib_parse(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_parse\"\"\"\n_urllib_parse_moved_attributes = [\n    MovedAttribute(\"ParseResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"SplitResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qs\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qsl\", \"urlparse\", \"urllib.parse\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "moves",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "moves = _MovedItems(__name__ + \".moves\")\n_importer._add_module(moves, \"moves\")\nclass Module_six_moves_urllib_parse(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_parse\"\"\"\n_urllib_parse_moved_attributes = [\n    MovedAttribute(\"ParseResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"SplitResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qs\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qsl\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urldefrag\", \"urlparse\", \"urllib.parse\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_urllib_parse_moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_urllib_parse_moved_attributes = [\n    MovedAttribute(\"ParseResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"SplitResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qs\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qsl\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urldefrag\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urljoin\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlparse\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlsplit\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlunparse\", \"urlparse\", \"urllib.parse\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_parse._moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n                      \"moves.urllib_parse\", \"moves.urllib.parse\")\nclass Module_six_moves_urllib_error(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_error\"\"\"\n_urllib_error_moved_attributes = [\n    MovedAttribute(\"URLError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"HTTPError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"ContentTooShortError\", \"urllib\", \"urllib.error\"),\n]",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_urllib_error_moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_urllib_error_moved_attributes = [\n    MovedAttribute(\"URLError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"HTTPError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"ContentTooShortError\", \"urllib\", \"urllib.error\"),\n]\nfor attr in _urllib_error_moved_attributes:\n    setattr(Module_six_moves_urllib_error, attr.name, attr)\ndel attr\nModule_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_error._moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n                      \"moves.urllib_error\", \"moves.urllib.error\")\nclass Module_six_moves_urllib_request(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_request\"\"\"\n_urllib_request_moved_attributes = [\n    MovedAttribute(\"urlopen\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"install_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"build_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"pathname2url\", \"urllib\", \"urllib.request\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_urllib_request_moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_urllib_request_moved_attributes = [\n    MovedAttribute(\"urlopen\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"install_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"build_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"pathname2url\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"url2pathname\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"getproxies\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"Request\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"OpenerDirector\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPDefaultErrorHandler\", \"urllib2\", \"urllib.request\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_request._moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n                      \"moves.urllib_request\", \"moves.urllib.request\")\nclass Module_six_moves_urllib_response(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_response\"\"\"\n_urllib_response_moved_attributes = [\n    MovedAttribute(\"addbase\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addclosehook\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfo\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfourl\", \"urllib\", \"urllib.response\"),",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_urllib_response_moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_urllib_response_moved_attributes = [\n    MovedAttribute(\"addbase\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addclosehook\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfo\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfourl\", \"urllib\", \"urllib.response\"),\n]\nfor attr in _urllib_response_moved_attributes:\n    setattr(Module_six_moves_urllib_response, attr.name, attr)\ndel attr\nModule_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_response._moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n                      \"moves.urllib_response\", \"moves.urllib.response\")\nclass Module_six_moves_urllib_robotparser(_LazyModule):\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_robotparser\"\"\"\n_urllib_robotparser_moved_attributes = [\n    MovedAttribute(\"RobotFileParser\", \"robotparser\", \"urllib.robotparser\"),\n]\nfor attr in _urllib_robotparser_moved_attributes:\n    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "_urllib_robotparser_moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "_urllib_robotparser_moved_attributes = [\n    MovedAttribute(\"RobotFileParser\", \"robotparser\", \"urllib.robotparser\"),\n]\nfor attr in _urllib_robotparser_moved_attributes:\n    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\ndel attr\nModule_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n                      \"moves.urllib_robotparser\", \"moves.urllib.robotparser\")\nclass Module_six_moves_urllib(types.ModuleType):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "Module_six_moves_urllib_robotparser._moved_attributes",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n                      \"moves.urllib_robotparser\", \"moves.urllib.robotparser\")\nclass Module_six_moves_urllib(types.ModuleType):\n    \"\"\"Create a six.moves.urllib namespace that resembles the Python 3 namespace\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "next",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "next = advance_iterator\ntry:\n    callable = callable\nexcept NameError:\n    def callable(obj):\n        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\nif PY3:\n    def get_unbound_function(unbound):\n        return unbound\n    create_bound_method = types.MethodType",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "get_method_function",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "get_method_function = operator.attrgetter(_meth_func)\nget_method_self = operator.attrgetter(_meth_self)\nget_function_closure = operator.attrgetter(_func_closure)\nget_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n    def itervalues(d, **kw):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "get_method_self",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "get_method_self = operator.attrgetter(_meth_self)\nget_function_closure = operator.attrgetter(_func_closure)\nget_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "get_function_closure",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "get_function_closure = operator.attrgetter(_func_closure)\nget_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n    def iteritems(d, **kw):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "get_function_code",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "get_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n    def iteritems(d, **kw):\n        return iter(d.items(**kw))",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "get_function_defaults",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "get_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n    def iteritems(d, **kw):\n        return iter(d.items(**kw))\n    def iterlists(d, **kw):",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "get_function_globals",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "get_function_globals = operator.attrgetter(_func_globals)\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n    def iteritems(d, **kw):\n        return iter(d.items(**kw))\n    def iterlists(d, **kw):\n        return iter(d.lists(**kw))",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "print_",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "print_ = getattr(moves.builtins, \"print\", None)\nif print_ is None:\n    def print_(*args, **kwargs):\n        \"\"\"The new-style print function for Python 2.4 and 2.5.\"\"\"\n        fp = kwargs.pop(\"file\", sys.stdout)\n        if fp is None:\n            return\n        def write(data):\n            if not isinstance(data, basestring):\n                data = str(data)",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "__path__",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "__path__ = []  # required for PEP 302 and PEP 451\n__package__ = __name__  # see PEP 366 @ReservedAssignment\nif globals().get(\"__spec__\") is not None:\n    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable\n# Remove other six meta path importers, since they cause problems. This can\n# happen if six is removed from sys.modules and then reloaded. (Setuptools does\n# this for some reason.)\nif sys.meta_path:\n    for i, importer in enumerate(sys.meta_path):\n        # Here's some real nastiness: Another \"instance\" of the six module might",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "__package__",
        "kind": 5,
        "importPath": "six.six",
        "description": "six.six",
        "peekOfCode": "__package__ = __name__  # see PEP 366 @ReservedAssignment\nif globals().get(\"__spec__\") is not None:\n    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable\n# Remove other six meta path importers, since they cause problems. This can\n# happen if six is removed from sys.modules and then reloaded. (Setuptools does\n# this for some reason.)\nif sys.meta_path:\n    for i, importer in enumerate(sys.meta_path):\n        # Here's some real nastiness: Another \"instance\" of the six module might\n        # be floating around. Therefore, we can't use isinstance() to check for",
        "detail": "six.six",
        "documentation": {}
    },
    {
        "label": "TestCustomizedMoves",
        "kind": 6,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "class TestCustomizedMoves:\n    def teardown_method(self, meth):\n        try:\n            del six._MovedItems.spam\n        except AttributeError:\n            pass\n        try:\n            del six.moves.__dict__[\"spam\"]\n        except KeyError:\n            pass",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "EnsureTests",
        "kind": 6,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "class EnsureTests:\n    # grinning face emoji\n    UNICODE_EMOJI = six.u(\"\\U0001F600\")\n    BINARY_EMOJI = b\"\\xf0\\x9f\\x98\\x80\"\n    def test_ensure_binary_raise_type_error(self):\n        with pytest.raises(TypeError):\n            six.ensure_str(8)\n    def test_errors_and_encoding(self):\n        six.ensure_binary(self.UNICODE_EMOJI, encoding='latin-1', errors='ignore')\n        with pytest.raises(UnicodeEncodeError):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_add_doc",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_add_doc():\n    def f():\n        \"\"\"Icky doc\"\"\"\n        pass\n    six._add_doc(f, \"\"\"New doc\"\"\")\n    assert f.__doc__ == \"New doc\"\ndef test_import_module():\n    from logging import handlers\n    m = six._import_module(\"logging.handlers\")\n    assert m is handlers",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_import_module",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_import_module():\n    from logging import handlers\n    m = six._import_module(\"logging.handlers\")\n    assert m is handlers\ndef test_integer_types():\n    assert isinstance(1, six.integer_types)\n    assert isinstance(-1, six.integer_types)\n    assert isinstance(six.MAXSIZE + 23, six.integer_types)\n    assert not isinstance(.1, six.integer_types)\ndef test_string_types():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_integer_types",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_integer_types():\n    assert isinstance(1, six.integer_types)\n    assert isinstance(-1, six.integer_types)\n    assert isinstance(six.MAXSIZE + 23, six.integer_types)\n    assert not isinstance(.1, six.integer_types)\ndef test_string_types():\n    assert isinstance(\"hi\", six.string_types)\n    assert isinstance(six.u(\"hi\"), six.string_types)\n    assert issubclass(six.text_type, six.string_types)\ndef test_class_types():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_string_types",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_string_types():\n    assert isinstance(\"hi\", six.string_types)\n    assert isinstance(six.u(\"hi\"), six.string_types)\n    assert issubclass(six.text_type, six.string_types)\ndef test_class_types():\n    class X:\n        pass\n    class Y(object):\n        pass\n    assert isinstance(X, six.class_types)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_class_types",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_class_types():\n    class X:\n        pass\n    class Y(object):\n        pass\n    assert isinstance(X, six.class_types)\n    assert isinstance(Y, six.class_types)\n    assert not isinstance(X(), six.class_types)\ndef test_text_type():\n    assert type(six.u(\"hi\")) is six.text_type",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_text_type",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_text_type():\n    assert type(six.u(\"hi\")) is six.text_type\ndef test_binary_type():\n    assert type(six.b(\"hi\")) is six.binary_type\ndef test_MAXSIZE():\n    try:\n        # This shouldn't raise an overflow error.\n        six.MAXSIZE.__index__()\n    except AttributeError:\n        # Before Python 2.6.",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_binary_type",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_binary_type():\n    assert type(six.b(\"hi\")) is six.binary_type\ndef test_MAXSIZE():\n    try:\n        # This shouldn't raise an overflow error.\n        six.MAXSIZE.__index__()\n    except AttributeError:\n        # Before Python 2.6.\n        pass\n    pytest.raises(",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_MAXSIZE",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_MAXSIZE():\n    try:\n        # This shouldn't raise an overflow error.\n        six.MAXSIZE.__index__()\n    except AttributeError:\n        # Before Python 2.6.\n        pass\n    pytest.raises(\n        (ValueError, OverflowError),\n        operator.mul, [None], six.MAXSIZE + 1)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_lazy",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_lazy():\n    if six.PY3:\n        html_name = \"html.parser\"\n    else:\n        html_name = \"HTMLParser\"\n    assert html_name not in sys.modules\n    mod = six.moves.html_parser\n    assert sys.modules[html_name] is mod\n    assert \"htmlparser\" not in six._MovedItems.__dict__\ntry:",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_move_items",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_move_items(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    try:\n        item = getattr(six.moves, item_name)\n        if isinstance(item, types.ModuleType):\n            __import__(\"six.moves.\" + item_name)\n    except ImportError:\n        if item_name == \"winreg\" and not sys.platform.startswith(\"win\"):\n            pytest.skip(\"Windows only module\")\n        if item_name.startswith(\"tkinter\"):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_move_items_urllib_parse",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_move_items_urllib_parse(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.parse)\n    getattr(six.moves.urllib.parse, item_name)\n@pytest.mark.parametrize(\"item_name\",\n                          [item.name for item in six._urllib_error_moved_attributes])\ndef test_move_items_urllib_error(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.error)\n    getattr(six.moves.urllib.error, item_name)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_move_items_urllib_error",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_move_items_urllib_error(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.error)\n    getattr(six.moves.urllib.error, item_name)\n@pytest.mark.parametrize(\"item_name\",\n                          [item.name for item in six._urllib_request_moved_attributes])\ndef test_move_items_urllib_request(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.request)\n    getattr(six.moves.urllib.request, item_name)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_move_items_urllib_request",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_move_items_urllib_request(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.request)\n    getattr(six.moves.urllib.request, item_name)\n@pytest.mark.parametrize(\"item_name\",\n                          [item.name for item in six._urllib_response_moved_attributes])\ndef test_move_items_urllib_response(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.response)\n    getattr(six.moves.urllib.response, item_name)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_move_items_urllib_response",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_move_items_urllib_response(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.response)\n    getattr(six.moves.urllib.response, item_name)\n@pytest.mark.parametrize(\"item_name\",\n                          [item.name for item in six._urllib_robotparser_moved_attributes])\ndef test_move_items_urllib_robotparser(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.robotparser)\n    getattr(six.moves.urllib.robotparser, item_name)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_move_items_urllib_robotparser",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_move_items_urllib_robotparser(item_name):\n    \"\"\"Ensure that everything loads correctly.\"\"\"\n    assert item_name in dir(six.moves.urllib.robotparser)\n    getattr(six.moves.urllib.robotparser, item_name)\ndef test_import_moves_error_1():\n    from six.moves.urllib.parse import urljoin\n    from six import moves\n    # In 1.4.1: AttributeError: 'Module_six_moves_urllib_parse' object has no attribute 'urljoin'\n    assert moves.urllib.parse.urljoin\ndef test_import_moves_error_2():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_import_moves_error_1",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_import_moves_error_1():\n    from six.moves.urllib.parse import urljoin\n    from six import moves\n    # In 1.4.1: AttributeError: 'Module_six_moves_urllib_parse' object has no attribute 'urljoin'\n    assert moves.urllib.parse.urljoin\ndef test_import_moves_error_2():\n    from six import moves\n    assert moves.urllib.parse.urljoin\n    # In 1.4.1: ImportError: cannot import name urljoin\n    from six.moves.urllib.parse import urljoin",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_import_moves_error_2",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_import_moves_error_2():\n    from six import moves\n    assert moves.urllib.parse.urljoin\n    # In 1.4.1: ImportError: cannot import name urljoin\n    from six.moves.urllib.parse import urljoin\ndef test_import_moves_error_3():\n    from six.moves.urllib.parse import urljoin\n    # In 1.4.1: ImportError: cannot import name urljoin\n    from six.moves.urllib_parse import urljoin\ndef test_from_imports():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_import_moves_error_3",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_import_moves_error_3():\n    from six.moves.urllib.parse import urljoin\n    # In 1.4.1: ImportError: cannot import name urljoin\n    from six.moves.urllib_parse import urljoin\ndef test_from_imports():\n    from six.moves.queue import Queue\n    assert isinstance(Queue, six.class_types)\n    from six.moves.configparser import ConfigParser\n    assert isinstance(ConfigParser, six.class_types)\ndef test_filter():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_from_imports",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_from_imports():\n    from six.moves.queue import Queue\n    assert isinstance(Queue, six.class_types)\n    from six.moves.configparser import ConfigParser\n    assert isinstance(ConfigParser, six.class_types)\ndef test_filter():\n    from six.moves import filter\n    f = filter(lambda x: x % 2, range(10))\n    assert six.advance_iterator(f) == 1\ndef test_filter_false():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_filter",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_filter():\n    from six.moves import filter\n    f = filter(lambda x: x % 2, range(10))\n    assert six.advance_iterator(f) == 1\ndef test_filter_false():\n    from six.moves import filterfalse\n    f = filterfalse(lambda x: x % 3, range(10))\n    assert six.advance_iterator(f) == 0\n    assert six.advance_iterator(f) == 3\n    assert six.advance_iterator(f) == 6",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_filter_false",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_filter_false():\n    from six.moves import filterfalse\n    f = filterfalse(lambda x: x % 3, range(10))\n    assert six.advance_iterator(f) == 0\n    assert six.advance_iterator(f) == 3\n    assert six.advance_iterator(f) == 6\ndef test_map():\n    from six.moves import map\n    assert six.advance_iterator(map(lambda x: x + 1, range(2))) == 1\ndef test_getoutput():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_map",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_map():\n    from six.moves import map\n    assert six.advance_iterator(map(lambda x: x + 1, range(2))) == 1\ndef test_getoutput():\n    from six.moves import getoutput\n    output = getoutput('echo \"foo\"')\n    assert output == 'foo'\ndef test_zip():\n    from six.moves import zip\n    assert six.advance_iterator(zip(range(2), range(2))) == (0, 0)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_getoutput",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_getoutput():\n    from six.moves import getoutput\n    output = getoutput('echo \"foo\"')\n    assert output == 'foo'\ndef test_zip():\n    from six.moves import zip\n    assert six.advance_iterator(zip(range(2), range(2))) == (0, 0)\ndef test_zip_longest():\n    from six.moves import zip_longest\n    it = zip_longest(range(2), range(1))",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_zip",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_zip():\n    from six.moves import zip\n    assert six.advance_iterator(zip(range(2), range(2))) == (0, 0)\ndef test_zip_longest():\n    from six.moves import zip_longest\n    it = zip_longest(range(2), range(1))\n    assert six.advance_iterator(it) == (0, 0)\n    assert six.advance_iterator(it) == (1, None)\nclass TestCustomizedMoves:\n    def teardown_method(self, meth):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_zip_longest",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_zip_longest():\n    from six.moves import zip_longest\n    it = zip_longest(range(2), range(1))\n    assert six.advance_iterator(it) == (0, 0)\n    assert six.advance_iterator(it) == (1, None)\nclass TestCustomizedMoves:\n    def teardown_method(self, meth):\n        try:\n            del six._MovedItems.spam\n        except AttributeError:",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_get_unbound_function",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_get_unbound_function():\n    class X(object):\n        def m(self):\n            pass\n    assert six.get_unbound_function(X.m) is X.__dict__[\"m\"]\ndef test_get_method_self():\n    class X(object):\n        def m(self):\n            pass\n    x = X()",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_get_method_self",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_get_method_self():\n    class X(object):\n        def m(self):\n            pass\n    x = X()\n    assert six.get_method_self(x.m) is x\n    pytest.raises(AttributeError, six.get_method_self, 42)\ndef test_get_method_function():\n    class X(object):\n        def m(self):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_get_method_function",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_get_method_function():\n    class X(object):\n        def m(self):\n            pass\n    x = X()\n    assert six.get_method_function(x.m) is X.__dict__[\"m\"]\n    pytest.raises(AttributeError, six.get_method_function, hasattr)\ndef test_get_function_closure():\n    def f():\n        x = 42",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_get_function_closure",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_get_function_closure():\n    def f():\n        x = 42\n        def g():\n            return x\n        return g\n    cell = six.get_function_closure(f())[0]\n    assert type(cell).__name__ == \"cell\"\ndef test_get_function_code():\n    def f():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_get_function_code",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_get_function_code():\n    def f():\n        pass\n    assert isinstance(six.get_function_code(f), types.CodeType)\n    if not hasattr(sys, \"pypy_version_info\"):\n        pytest.raises(AttributeError, six.get_function_code, hasattr)\ndef test_get_function_defaults():\n    def f(x, y=3, b=4):\n        pass\n    assert six.get_function_defaults(f) == (3, 4)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_get_function_defaults",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_get_function_defaults():\n    def f(x, y=3, b=4):\n        pass\n    assert six.get_function_defaults(f) == (3, 4)\ndef test_get_function_globals():\n    def f():\n        pass\n    assert six.get_function_globals(f) is globals()\ndef test_dictionary_iterators(monkeypatch):\n    def stock_method_name(iterwhat):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_get_function_globals",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_get_function_globals():\n    def f():\n        pass\n    assert six.get_function_globals(f) is globals()\ndef test_dictionary_iterators(monkeypatch):\n    def stock_method_name(iterwhat):\n        \"\"\"Given a method suffix like \"lists\" or \"values\", return the name\n        of the dict method that delivers those on the version of Python\n        we're running in.\"\"\"\n        if six.PY3:",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_dictionary_iterators",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_dictionary_iterators(monkeypatch):\n    def stock_method_name(iterwhat):\n        \"\"\"Given a method suffix like \"lists\" or \"values\", return the name\n        of the dict method that delivers those on the version of Python\n        we're running in.\"\"\"\n        if six.PY3:\n            return iterwhat\n        return 'iter' + iterwhat\n    class MyDict(dict):\n        if not six.PY3:",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_dictionary_views",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_dictionary_views():\n    d = dict(zip(range(10), (range(11, 20))))\n    for name in \"keys\", \"values\", \"items\":\n        meth = getattr(six, \"view\" + name)\n        view = meth(d)\n        assert set(view) == set(getattr(d, name)())\ndef test_advance_iterator():\n    assert six.next is six.advance_iterator\n    l = [1, 2]\n    it = iter(l)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_advance_iterator",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_advance_iterator():\n    assert six.next is six.advance_iterator\n    l = [1, 2]\n    it = iter(l)\n    assert six.next(it) == 1\n    assert six.next(it) == 2\n    pytest.raises(StopIteration, six.next, it)\n    pytest.raises(StopIteration, six.next, it)\ndef test_iterator():\n    class myiter(six.Iterator):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_iterator",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_iterator():\n    class myiter(six.Iterator):\n        def __next__(self):\n            return 13\n    assert six.advance_iterator(myiter()) == 13\n    class myitersub(myiter):\n        def __next__(self):\n            return 14\n    assert six.advance_iterator(myitersub()) == 14\ndef test_callable():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_callable",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_callable():\n    class X:\n        def __call__(self):\n            pass\n        def method(self):\n            pass\n    assert six.callable(X)\n    assert six.callable(X())\n    assert six.callable(test_callable)\n    assert six.callable(hasattr)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_create_bound_method",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_create_bound_method():\n    class X(object):\n        pass\n    def f(self):\n        return self\n    x = X()\n    b = six.create_bound_method(f, x)\n    assert isinstance(b, types.MethodType)\n    assert b() is x\ndef test_create_unbound_method():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_create_unbound_method",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_create_unbound_method():\n    class X(object):\n        pass\n    def f(self):\n        return self\n    u = six.create_unbound_method(f, X)\n    pytest.raises(TypeError, u)\n    if six.PY2:\n        assert isinstance(u, types.MethodType)\n    x = X()",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_u_escapes",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_u_escapes():\n    s = six.u(\"\\u1234\")\n    assert len(s) == 1\ndef test_unichr():\n    assert six.u(\"\\u1234\") == six.unichr(0x1234)\n    assert type(six.u(\"\\u1234\")) is type(six.unichr(0x1234))\ndef test_int2byte():\n    assert six.int2byte(3) == six.b(\"\\x03\")\n    pytest.raises(Exception, six.int2byte, 256)\ndef test_byte2int():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_unichr",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_unichr():\n    assert six.u(\"\\u1234\") == six.unichr(0x1234)\n    assert type(six.u(\"\\u1234\")) is type(six.unichr(0x1234))\ndef test_int2byte():\n    assert six.int2byte(3) == six.b(\"\\x03\")\n    pytest.raises(Exception, six.int2byte, 256)\ndef test_byte2int():\n    assert six.byte2int(six.b(\"\\x03\")) == 3\n    assert six.byte2int(six.b(\"\\x03\\x04\")) == 3\n    pytest.raises(IndexError, six.byte2int, six.b(\"\"))",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_int2byte",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_int2byte():\n    assert six.int2byte(3) == six.b(\"\\x03\")\n    pytest.raises(Exception, six.int2byte, 256)\ndef test_byte2int():\n    assert six.byte2int(six.b(\"\\x03\")) == 3\n    assert six.byte2int(six.b(\"\\x03\\x04\")) == 3\n    pytest.raises(IndexError, six.byte2int, six.b(\"\"))\ndef test_bytesindex():\n    assert six.indexbytes(six.b(\"hello\"), 3) == ord(\"l\")\ndef test_bytesiter():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_byte2int",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_byte2int():\n    assert six.byte2int(six.b(\"\\x03\")) == 3\n    assert six.byte2int(six.b(\"\\x03\\x04\")) == 3\n    pytest.raises(IndexError, six.byte2int, six.b(\"\"))\ndef test_bytesindex():\n    assert six.indexbytes(six.b(\"hello\"), 3) == ord(\"l\")\ndef test_bytesiter():\n    it = six.iterbytes(six.b(\"hi\"))\n    assert six.next(it) == ord(\"h\")\n    assert six.next(it) == ord(\"i\")",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_bytesindex",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_bytesindex():\n    assert six.indexbytes(six.b(\"hello\"), 3) == ord(\"l\")\ndef test_bytesiter():\n    it = six.iterbytes(six.b(\"hi\"))\n    assert six.next(it) == ord(\"h\")\n    assert six.next(it) == ord(\"i\")\n    pytest.raises(StopIteration, six.next, it)\ndef test_StringIO():\n    fp = six.StringIO()\n    fp.write(six.u(\"hello\"))",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_bytesiter",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_bytesiter():\n    it = six.iterbytes(six.b(\"hi\"))\n    assert six.next(it) == ord(\"h\")\n    assert six.next(it) == ord(\"i\")\n    pytest.raises(StopIteration, six.next, it)\ndef test_StringIO():\n    fp = six.StringIO()\n    fp.write(six.u(\"hello\"))\n    assert fp.getvalue() == six.u(\"hello\")\ndef test_BytesIO():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_StringIO",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_StringIO():\n    fp = six.StringIO()\n    fp.write(six.u(\"hello\"))\n    assert fp.getvalue() == six.u(\"hello\")\ndef test_BytesIO():\n    fp = six.BytesIO()\n    fp.write(six.b(\"hello\"))\n    assert fp.getvalue() == six.b(\"hello\")\ndef test_exec_():\n    def f():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_BytesIO",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_BytesIO():\n    fp = six.BytesIO()\n    fp.write(six.b(\"hello\"))\n    assert fp.getvalue() == six.b(\"hello\")\ndef test_exec_():\n    def f():\n        l = []\n        six.exec_(\"l.append(1)\")\n        assert l == [1]\n    f()",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_exec_",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_exec_():\n    def f():\n        l = []\n        six.exec_(\"l.append(1)\")\n        assert l == [1]\n    f()\n    ns = {}\n    six.exec_(\"x = 42\", ns)\n    assert ns[\"x\"] == 42\n    glob = {}",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_reraise",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_reraise():\n    def get_next(tb):\n        if six.PY3:\n            return tb.tb_next.tb_next\n        else:\n            return tb.tb_next\n    e = Exception(\"blah\")\n    try:\n        raise e\n    except Exception:",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_raise_from",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_raise_from():\n    try:\n        try:\n            raise Exception(\"blah\")\n        except Exception:\n            ctx = sys.exc_info()[1]\n            f = Exception(\"foo\")\n            six.raise_from(f, None)\n    except Exception:\n        tp, val, tb = sys.exc_info()",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_print_",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_print_():\n    save = sys.stdout\n    out = sys.stdout = six.moves.StringIO()\n    try:\n        six.print_(\"Hello,\", \"person!\")\n    finally:\n        sys.stdout = save\n    assert out.getvalue() == \"Hello, person!\\n\"\n    out = six.StringIO()\n    six.print_(\"Hello,\", \"person!\", file=out)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_print_exceptions",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_print_exceptions():\n    pytest.raises(TypeError, six.print_, x=3)\n    pytest.raises(TypeError, six.print_, end=3)\n    pytest.raises(TypeError, six.print_, sep=42)\ndef test_with_metaclass():\n    class Meta(type):\n        pass\n    class X(six.with_metaclass(Meta)):\n        pass\n    assert type(X) is Meta",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_with_metaclass",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_with_metaclass():\n    class Meta(type):\n        pass\n    class X(six.with_metaclass(Meta)):\n        pass\n    assert type(X) is Meta\n    assert issubclass(X, object)\n    class Base(object):\n        pass\n    class X(six.with_metaclass(Meta, Base)):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_with_metaclass_typing",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_with_metaclass_typing():\n    try:\n        import typing\n    except ImportError:\n        pytest.skip(\"typing module required\")\n    class Meta(type):\n        pass\n    if sys.version_info[:2] < (3, 7):\n        # Generics with custom metaclasses were broken on older versions.\n        class Meta(Meta, typing.GenericMeta):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_with_metaclass_pep_560",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_with_metaclass_pep_560():\n    class Meta(type):\n        pass\n    class A:\n        pass\n    class B:\n        pass\n    class Fake:\n        def __mro_entries__(self, bases):\n            return (A, B)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_with_metaclass_prepare",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_with_metaclass_prepare():\n    \"\"\"Test that with_metaclass causes Meta.__prepare__ to be called with the correct arguments.\"\"\"\n    class MyDict(dict):\n        pass\n    class Meta(type):\n        @classmethod\n        def __prepare__(cls, name, bases):\n            namespace = MyDict(super().__prepare__(name, bases), cls=cls, bases=bases)\n            namespace['namespace'] = namespace\n            return namespace",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_wraps",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_wraps():\n    def f(g):\n        @six.wraps(g)\n        def w():\n            return 42\n        return w\n    def k():\n        pass\n    original_k = k\n    k = f(f(k))",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_wraps_raises_on_missing_updated_field_on_wrapper",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_wraps_raises_on_missing_updated_field_on_wrapper():\n    \"\"\"Ensure six.wraps doesn't ignore missing attrs wrapper.\n    Because that's what happens in Py3's functools.update_wrapper.\n    \"\"\"\n    def wrapped():\n        pass\n    def wrapper():\n        pass\n    with pytest.raises(AttributeError, match='has no attribute.*xyzzy'):\n        six.wraps(wrapped, [], ['xyzzy'])(wrapper)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_add_metaclass",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_add_metaclass():\n    class Meta(type):\n        pass\n    class X:\n        \"success\"\n    X = six.add_metaclass(Meta)(X)\n    assert type(X) is Meta\n    assert issubclass(X, object)\n    assert X.__module__ == __name__\n    assert X.__doc__ == \"success\"",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_add_metaclass_nested",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_add_metaclass_nested():\n    # Regression test for https://github.com/benjaminp/six/issues/259\n    class Meta(type):\n        pass\n    class A:\n        class B: pass\n    expected = 'test_add_metaclass_nested.<locals>.A.B'\n    assert A.B.__qualname__ == expected\n    class A:\n        @six.add_metaclass(Meta)",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_assertCountEqual",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_assertCountEqual():\n    class TestAssertCountEqual(unittest.TestCase):\n        def test(self):\n            with self.assertRaises(AssertionError):\n                six.assertCountEqual(self, (1, 2), [3, 4, 5])\n            six.assertCountEqual(self, (1, 2), [2, 1])\n    TestAssertCountEqual('test').test()\ndef test_assertRegex():\n    class TestAssertRegex(unittest.TestCase):\n        def test(self):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_assertRegex",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_assertRegex():\n    class TestAssertRegex(unittest.TestCase):\n        def test(self):\n            with self.assertRaises(AssertionError):\n                six.assertRegex(self, 'test', r'^a')\n            six.assertRegex(self, 'test', r'^t')\n    TestAssertRegex('test').test()\ndef test_assertNotRegex():\n    class TestAssertNotRegex(unittest.TestCase):\n        def test(self):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_assertNotRegex",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_assertNotRegex():\n    class TestAssertNotRegex(unittest.TestCase):\n        def test(self):\n            with self.assertRaises(AssertionError):\n                six.assertNotRegex(self, 'test', r'^t')\n            six.assertNotRegex(self, 'test', r'^a')\n    TestAssertNotRegex('test').test()\ndef test_assertRaisesRegex():\n    class TestAssertRaisesRegex(unittest.TestCase):\n        def test(self):",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_assertRaisesRegex",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_assertRaisesRegex():\n    class TestAssertRaisesRegex(unittest.TestCase):\n        def test(self):\n            with six.assertRaisesRegex(self, AssertionError, '^Foo'):\n                raise AssertionError('Foo')\n            with self.assertRaises(AssertionError):\n                with six.assertRaisesRegex(self, AssertionError, r'^Foo'):\n                    raise AssertionError('Bar')\n    TestAssertRaisesRegex('test').test()\ndef test_python_2_unicode_compatible():",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "test_python_2_unicode_compatible",
        "kind": 2,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "def test_python_2_unicode_compatible():\n    @six.python_2_unicode_compatible\n    class MyTest(object):\n        def __str__(self):\n            return six.u('hello')\n        def __bytes__(self):\n            return six.b('hello')\n    my_test = MyTest()\n    if six.PY2:\n        assert str(my_test) == six.b(\"hello\")",
        "detail": "six.test_six",
        "documentation": {}
    },
    {
        "label": "have_gdbm",
        "kind": 5,
        "importPath": "six.test_six",
        "description": "six.test_six",
        "peekOfCode": "have_gdbm = True\ntry:\n    import gdbm\nexcept ImportError:\n    try:\n        import dbm.gnu\n    except ImportError:\n        have_gdbm = False\n@pytest.mark.parametrize(\"item_name\",\n                          [item.name for item in six._moved_attributes])",
        "detail": "six.test_six",
        "documentation": {}
    }
]